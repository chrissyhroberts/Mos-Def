[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Design, Optimisation, Validation, and Analysis Framework for Multiplex Bead‑Based Biomarker Assays",
    "section": "",
    "text": "1 Overview\nThis resource provides a generalised, platform‑agnostic wet‑lab and in silico framework for the design, optimisation, validation, use and analysis of data from multiplex bead‑based biomarker assays (e.g., Luminex xMAP) .\nThe method is presented through the lens of a novel multimarker immunoassay for evaluating febrile disease, but by using the concepts, methods and code included in this repo, you should be able to create and validate your own multiplexes.\nThese protocols also provide information on how to perform quality assurance experiments and to evaluate performance parameters such as the coefficient of variation. We also provide some analysis protocols which will support you to import, process and perform a quality controlled analysis of data from this or any multiplexed immuno-bead assay created on the MagPix platform.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#about-the-method",
    "href": "index.html#about-the-method",
    "title": "Design, Optimisation, Validation, and Analysis Framework for Multiplex Bead‑Based Biomarker Assays",
    "section": "1.1 About the method",
    "text": "1.1 About the method\nThe assay is a multiplexed sandwich assay designed for use with the Luminex MagPix and related devices. During the assay, analytes are bound to addressable microbeads using bead-bound, analyte-specific antibodies. The analytes bound to the beads then form complexes with analyte-specific biotin-conjugated detection antibodies followed by streptavidin-phycoerythrin (SA-PE) fluorescent reporter. This sandwich assay offers high specificity for the analytes, ensuring that each bead becomes fluorescent only when conjugated with the intended analyte. The level of SA-PE fluorescence serves as a proxy for the quantity of analyte bound to each bead. The addressable signals of the microbeads then allow for the identification of which analyte corresponds to a given SA-PE fluorescence signal. When performed with a plurality of capture-antibody conjugated beads and a corresponding set of biotin conjugated detection antibodies, the platform allows a highly specific estimate of analyte concentration across the 12 targets. To allow full reproduction of our panel of markers for febrile diseases, we provide exhaustive detail in the supplement.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#why-this-method",
    "href": "index.html#why-this-method",
    "title": "Design, Optimisation, Validation, and Analysis Framework for Multiplex Bead‑Based Biomarker Assays",
    "section": "1.2 Why This Method?",
    "text": "1.2 Why This Method?\n\nPlatform‑agnostic – applicable to most bead‑based multiplex immunoassay systems. Tested to work with Luminex MagPix\nGeneralised principles – not tied to a specific disease or biomarker panel.\nReproducible – includes full rationale for each design step.\nCitable – stable DOI for use in publications.\nUpdatable – versioned for traceability and improvements over time.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#method-summary",
    "href": "index.html#method-summary",
    "title": "Design, Optimisation, Validation, and Analysis Framework for Multiplex Bead‑Based Biomarker Assays",
    "section": "1.3 Method Summary",
    "text": "1.3 Method Summary\n\nThis framework guides you through the complete lifecycle of a multiplex bead‑based biomarker assay — from concept and reagent preparation to clinical testing, data analysis, and prognostic evaluation.\n\nProject Overview & Planning\n\nDefine intended use, panel scope, and platform requirements.\nCompile initial marker lists, shopping lists, and resource planning tools.\n\nReagent Preparation\n\nPreparation of buffers and reagents.\nCapture antibody preparation.\nDetection antibody preparation.\nAntigen preparation and storage.\n\nBead Coupling & Verification\n\nCoupling capture antibodies to bead regions.\nConfirmation of coupling efficiency.\n\nAssay Design & Cross‑Reactivity Testing\n\nSelection and pairing of capture/detection antibodies.\nSystematic cross‑reactivity screening.\nMitigation strategies for problematic analytes.\n\nStandard Curve & Calibration\n\nPreparation of assay standards.\nDilution series design and use of calculators.\nStandard curve modelling and performance checks.\n\nInstrument Protocols\n\nLuminex MagPix operating procedures.\nRecommended plate layouts and run settings.\n\nAssay Optimisation & Performance Characterisation\n\nCoefficient of variation (intra‑ and inter‑assay) determination.\nSpike‑and‑recovery testing.\nDilution linearity evaluation.\n\nSpecimen Testing\n\nVolume requirements and handling guidance.\nIntegration of QC samples into every run.\n\nData Analysis\n\nImporting and preprocessing raw MagPix output.\nStandard curve fitting (e.g., 5‑PL) and concentration back‑calculation.\nReplicate handling and quality control flagging.\nBatch effect assessment and correction.\n\nPrognostic and Diagnostic Modelling\n\nStatistical evaluation of biomarker associations with clinical outcomes.\nROC curve generation, AUC, sensitivity, specificity, PPV, NPV.\nDevelopment of predictive models and multi‑marker signatures.\n\nDocumentation, Transparency & Reproducibility\n\nFull reagent and protocol traceability.\nVersion‑controlled code and protocol sharing.\nContributor roles (CRediT taxonomy).\nReferences and further reading.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#citing-this-method",
    "href": "index.html#citing-this-method",
    "title": "Design, Optimisation, Validation, and Analysis Framework for Multiplex Bead‑Based Biomarker Assays",
    "section": "1.4 Citing This Method",
    "text": "1.4 Citing This Method\nIf you use or adapt this protocol in your own work, please cite:\n\nMarlais, T., Drakeley, C. & Roberts, Ch. Design, Optimisation, Validation, and Analysis Framework for Multiplex Bead‑Based Biomarker Assays. London School of Hygiene & Tropical Medicine; 2025. Available from: https://github.com/chrissyhroberts/multiplex-assay-method doi:[DOI to be assigned]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#versioning-doi",
    "href": "index.html#versioning-doi",
    "title": "Design, Optimisation, Validation, and Analysis Framework for Multiplex Bead‑Based Biomarker Assays",
    "section": "1.5 Versioning & DOI",
    "text": "1.5 Versioning & DOI\nThis method will be versioned using GitHub Releases.\nEach public release will be archived in Zenodo, which will assign a permanent DOI.\nThe DOI for this version will be added once minted.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Design, Optimisation, Validation, and Analysis Framework for Multiplex Bead‑Based Biomarker Assays",
    "section": "1.6 License",
    "text": "1.6 License\nThis work is released under the Creative Commons Attribution 4.0 International (CC BY 4.0) license.\nYou are free to share and adapt the method, provided you give appropriate credit.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Design, Optimisation, Validation, and Analysis Framework for Multiplex Bead‑Based Biomarker Assays",
    "section": "1.7 Contact",
    "text": "1.7 Contact\nFor questions, feedback, or collaboration requests:\nDr Chrissy H Roberts\nEmail: Chrissy.Roberts@lshtm.ac.uk\nGitHub: @chrissyhroberts",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "fever.html",
    "href": "fever.html",
    "title": "2  About this exemplar assay",
    "section": "",
    "text": "A 12-plex febrile diseases immunoassay panel\nThis set of methods is demonstrated through an exemplar: multiplexed immunoassay for evaluation of fever outcomes. This exemplar is designed to detect and quantify multiple immune and inflammation markers relevant to the study of febrile illness. It illustrates the complete workflow from marker selection, reagent preparation, and bead couplingthrough to data acquisition, analysis, and simulated prognostic modelling.\nWhile the fever assay is used here as a working example, the concepts, methods, and code in this repository are applicable to the design and implementation of any multiplexed bead‑based immunoassay, for any set of biomarkers or analytes.\nFever has heterogeneous aetiology both within and between populations. With fever as a significant reason for health-seeking globally, understanding how clinical signs, symptoms and measurable factors could be used for prognosis and to establish aetiology could be a valuable tool in directing limited resources to where they are most needed.\nInfectious causes of fever are a significant contributor to the case burden, but are both multitudinous and ecologically diverse. The fraction of fever cases which is attributable to a specific pathogen varies substantially with geography, climate and time; as well as in response to competing/co-endemic species and to human activities (which include public health & clinical interventions). Accurate clinical evaluation of fever cases therefore requires substantial knowledge of local and temporal epidemiological trends.\nFlux in the prevalence of causative infections (i.e. because of seasonality or epidemics) means that the predictive value of any diagnostic algorithm or test is in a similar state of continuous change and is therefore prone to incompletely definable type 1 and type 2 errors. Misdiagnosis can occur because a clinician neither suspected, nor considered, the causative pathogen when making a diagnosis by clinical evaluation, or because of the opposite circumstance.\nIn some settings, the broad availability of laboratory-based or point-of-care tests can provide a more definitive, though still error-prone, diagnosis of specifically targeted (endemic) pathogens. In many settings which lack resources, access to diagnostics may be impossible, impractical or untimely. The complex aetiology of fever potentially requires the use of a plurality of diagnostic tests in each case. The inconsistent availability of such tests means that many or most fever cases ultimately remain undiagnosed and are treated syndromically.\nWhen triaging a patient who presents with fever, one of the physician’s first tasks is likely to be an assessment of whether (in their regard) the patient is more likely to have a self-limiting disease, something severe enough to require hospital admission, or something in-between. The heterogeneity of febrile disease is such that whilst many cases require no treatment, or can be managed through an outpatient clinic; some are potentially fatal or life-changing. A key problem for the clinical triage is that some patients may appear at face-value to be relatively low-risk, but will still go on to die after being sent home to recover.\nImmune markers have previously been used to prognosticate the outcomes of fever cases. Measuring molecules in the blood that are released by immune cells and the vascular endothelium during fever may not identify a specific cause of the fever, but can provide a non-specific measure of fever severity that provides insight into how a patient should be handled. Previous work has shown how such approaches can prognosticate on whether immune dysregulation will lead to a severe or non-severe outcome.\nSignatures of an immune response have obvious potential to support clinical decision making by providing an objective and quantitative measure of disease severity which belies the subjectivity of a clinical assessment.  Being agnostic to the cause of the fever, measures of the severity of the immune response have the potential to act as a ‘catch-all’ triage tool, although the heterogeneous nature of fever causes means that an immune marker which performs well as a prognostic in one population may not be as effective in another population, or at another time.\nThe ability to detect multiple analytes in a single blood sample enables the identification of possible  markers of prognosis or association with particular outcomes or aetiologies. For translation to clinical use, the aim of multiplex analysis can be to screen a panel of severity markers in order to identify a single, best-performing, marker (for that population) that can then be incorporated into a rapid diagnostic test (RDT) or other point-of-care (POC) device.\nBeyond its use as a screening tool, the use of platforms which can detect multiple analytes in parallel can build a more complex picture of the immune response to different pathogens or in different populations; and thus provide an immune ‘profile’. In some diseases and in some settings, these multifactor immune profiles may have synergistic value in discriminating, for instance, between fever cases which are caused by viruses or bacteria.\nThe ideal multiplex assay requires only a very small volume of analyte (in this case blood) to provide a large amount of information. This allows easier, less invasive, unified and cost-effective sampling and diagnostic testing. Dried blood spots (DBS) are a convenient way to sample, transport and store whole blood, particularly in low-resource settings. Other advantages of DBS have been highlighted and these refer to their use being minimally invasive (and as such better for repeated sampling of the same individual), lower cost and with a lower requirement for processing, storage and biosafety measures.\nWhile commercial multiplex immunoassay kits are widely available, they do not necessarily include all analytes of interest (to a specific clinical context such as fever) on the same panel. This can lead to the need to test specimens on multiple panels, which can be very costly and which may not be feasible on very large sample sets due to cost, time or personnel constraints. In addition to this, commercial kits tend not to provide the option to use DBS samples, requiring initial experimentation and optimisation, and due to their proprietary components, can not be easily modified.\nIn this study, we developed and deployed a 12-plex bead-based antigen capture immunoassay on the Luminex MagPix platform. The assay we present uses only ‘off-the-shelf’ reagents and detects the following markers of immune and endothelial activation, selected for their association with fever prognosis, aetiology, or both: angiopoietins 1 and 2 (Ang-1, Ang-2); azurocidin (Azu); chitinase 3-like 1 (CHI3L1); interleukins 6, 8 and 10 (IL-6, IL-8, IL-10); interferon gamma inducible protein 10 (IP-10/CXCL-10); soluble tumour necrosis factor receptor 1 (sTNFR1); myxovirus resistance protein A (MxA); soluble triggering receptor expressed on myeloid cells (sTREM-1); TNF-related apoptosis-inducing ligand (TRAIL)\nFor those wishing to reproduce and use the fever panel, we fully detail reagent suppliers, product codes, laboratory protocols and instructions for optimisation and evaluation. For those wishing to develop their own immunoassays, the methods and code provide a framework on which to base such developments. We also provide an open-source data analysis pipeline (for use in R) which enables replication of our methods and reproduction of the figures and tables presented in the paper. If you want to try the analysis for yourself, you can find the input files in this repo https://github.com/chrissyhroberts/Mos-Def. For those aiming to develop these methods for other contexts and biomarkers, the generalisable workflow is open source and fully adaptable.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>About this exemplar assay</span>"
    ]
  },
  {
    "objectID": "bloodspots.html",
    "href": "bloodspots.html",
    "title": "3  Dried Blood Spots",
    "section": "",
    "text": "3.1 Spiked DBS variations\nRecombinant protein standards were tested for performance when diluted in various diluents and dried onto filter paper disks to see which most closely represented expected antigen levels and human blood samples. The following were tested as diluents: healthy human blood, sheep serum, horse serum, horse blood, PBS buffer and PBS with added washed red blood cells (McDade 2014) from healthy donors",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dried Blood Spots</span>"
    ]
  },
  {
    "objectID": "bloodspots.html#dbs-elution",
    "href": "bloodspots.html#dbs-elution",
    "title": "3  Dried Blood Spots",
    "section": "3.2 DBS elution",
    "text": "3.2 DBS elution\nElution conditions were tested to achieve optimal recovery of antigens while maintaining assay workflow. Final elution conditions were: two DBS of 6 mm diameter each (TropBio, Australia), rehydrated in 100 ul of elution buffer overnight in a sealed low-bind 96 well plate at 4°C. According to the manufacturer, the DBS hold 10 ul of blood each, giving a final dilution factor of whole blood of 1 in 5.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dried Blood Spots</span>"
    ]
  },
  {
    "objectID": "Marker_List.html",
    "href": "Marker_List.html",
    "title": "4  List of Markers",
    "section": "",
    "text": "4.1 Markers included in the exemplar assay",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>List of Markers</span>"
    ]
  },
  {
    "objectID": "Marker_List.html#markers-included-in-the-exemplar-assay",
    "href": "Marker_List.html#markers-included-in-the-exemplar-assay",
    "title": "4  List of Markers",
    "section": "",
    "text": "4.1.1 Angiopoietin-1 (Ang-1)\nConstitutively expressed by pericytes and smooth muscle cells, also stored in platelets (Brouwers et al. 2013). Ang-1 is an agonist binding the TIE2 receptor. It promotes endothelial cell survival and maintains vascular quiescence. Activates or inhibits angiogenesis, depending on the context. Ang-1 mediates blood vessel maturation/stability (Leligdowicz et al. 2018).\n\n\n4.1.2 Angiopoietin-2 (Ang-2)\nExpressed by endothelial cells. Ang-2 binds to TIE2 in competition with Ang-1 but is an antagonist. Increased Ang-2 levels lead to increased vascular leakage, resulting from destabilised vascular endothelium, remodelling, and leakiness (Kim et al. 2016). Ang/Tie2 dysregulation is thought to be “pathogen agnostic” (Leligdowicz et al. 2018).\n\n\n4.1.3 Azurocidin 1 (Azu)\nReleased early in infection from granules in polymorphonuclear leukocytes. Azu acts as a chemo-attractant to several leukocyte types, provokes cytokine secretion, and induces capillary leakage. Azu is directly cytotoxic to certain Gram-negative bacteria (Fisher and Linder 2017).\n\n\n4.1.4 Chitinase 3-like 1 (CHI3L1)\nProduced by many cell types, including immune, epithelial and others. Overexpressed in infectious and non-infectious inflammatory conditions, including sepsis and cancer. Crucial role in protecting against pathogens, antigen- and oxidant-induced injury responses, inflammation, and tissue repair and remodelling. Regulates a range of essential biological processes (Zhao et al. 2020).\n\n\n4.1.5 Interleukin 6 (IL-6)\nProduced by immune and other cell types during chronic and acute inflammation. Triggers acute phase proteins in the liver. Can be pro- and anti-inflammatory. Stimulates B cells to produce antibodies. Links innate to acquired immune response by promoting differentiation of CD4+ T cells. Pyrogenic and pro-coagulative (Tanaka, Narazaki, and Kishimoto 2014), (Kang and Kishimoto 2021).\n\n\n4.1.6 Interleukin 8 (IL-8)\nProduced by many cell types including monocytes, lymphocytes, granulocytes, fibroblasts, endothelial and epithelial cells, hepatocytes, mesangial cells and chondrocytes and is released only under inflammatory conditions. Platelets store IL-8 in their granules and rapidly release IL-8 in inflammation (Matsushima, Yang, and Oppenheim 2022).\n\n\n4.1.7 Interleukin 10 (IL-10)\nA key anti-inflammatory mediator. Regulator of cellular immune response. Produced by various cell types and detected by macrophages and a range of other cell types. Limits antigen presentation and anti-microbial mechanisms such as nitric oxide production (Saraiva, Vieira, and O’Garra 2019).\n\n\n4.1.8 Interferon gamma inducible protein 10 (IP-10)\nA chemokine released from various immune cells in response to IFNg and other cytokines. Activates and recruits lymphocytes. Elevated in viral and HIV infection, particularly acute HIV (Lei et al. 2019),(Hayney et al. 2017). Associated with disease progression.\n\n\n4.1.9 Myxovirus resistance protein A (MxA)\nCytoplasmic GTPase with activity against Influenza A and a range of other viruses. Inhibits viral gene transcription by binding to the viral nucleoprotein. MxA is activated by type I and type III interferons (Haller and Kochs 2019).\n\n\n4.1.10 Soluble Tumor necrosis factor receptor 1 (sTNFR1)\nThe soluble form of TNFR1 is a competitive inhibitor for circulating TNF, thereby reducing signalling through TNFR1 (an endogenous pyrogen), that can promote a wide range of functions from cell death, tissue damage and subsequent inflammation, to cell proliferation and immune modulation (Ruiz et al. 2021), (Bemelmans, Tits, and Buurman 2017), (Al-Lamki and Mayadas 2015)\n\n\n4.1.11 Soluble Triggering receptor expressed on myeloid cells 1 (sTREM-1)\nSoluble form of TREM‐1 shed from the membrane of activated phagocytes in response to bacterial and fungal infections. sTREM-1 contains an immunoglobulin-like domain that recognises ligands including those connected to bacterial-derived molecules. sTREM-1 possibly originates from the activation of TREM-1 by an infection, being at very low levels in healthy controls. sTREM-1 may also competitively bind TREM-1 ligands and be anti-inflammatory (Theobald et al. 2024)\n\n\n4.1.12 TNF-related apoptosis-inducing ligand (TRAIL)\nTRAIL is consitutively expressed in various tissues, and by various immune cells including natural killer (NK) cells, activated T cells, natural killer T cells (NKT cells), dendritic cells and monocyte/macrophages. Elevated in viral infections and possibly downregulated in bacterial infections. Viruses may stimulate TRAIL expression in host or immune cells, and may also sensitize host cells to TRAIL-mediated induction of apoptosis (Gyurkovska and Ivanovska 2016).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>List of Markers</span>"
    ]
  },
  {
    "objectID": "Marker_List.html#markers-which-were-screened-but-which-failed-assay-quality-tests",
    "href": "Marker_List.html#markers-which-were-screened-but-which-failed-assay-quality-tests",
    "title": "4  List of Markers",
    "section": "4.2 Markers which were screened, but which failed assay quality tests",
    "text": "4.2 Markers which were screened, but which failed assay quality tests\n\n4.2.1 Procalcitonin (PCT)\nProduced in the thyroid, but also in all parenchymal tissues during bacterial infection. PCT is secreted in response to bacterial endotoxins, lipopolysaccharides, and inflammatory cytokines. It is inhibited by IFN-gamma during the response to viral infections (Davies 2015)\nThe PCT assay was screened out of our multiplex due to difficulty in finding a working pair of antibodies that did not cross-react with other antigens in the multiplex, particularly azurocidin.\n\n\n4.2.2 C-Reactive Protein (CRP)\nAn acute phase component of the innate immune response, decreasing within hours once the stimulus is removed. CRP is produced by hepatocytes and several other cell types in response to IL-6 in combination with other stimuli. Serum levels can rise by up to 1000-fold. CRP acts by triggering complement, and activates the cellular response by binding to the Fc portion of IgG (Sproston and Ashworth 2018).\nThe CRP assay was dropped from the multiplex because a reliable standard curve could not be obtained and, crucially, because of the need for much higher sample dilution than the other markers.\n\n\n4.2.3 Soluble FEMS-like tyrosine kinase 1 (sFlt-1)\nFlt-1, also known as VEGF Receptor 1, is primarily active in the vascular endothelium. The soluble form, sFlt-1, binds to circulating VEGF, reducing the effect of VEGF which normally induces neovascularisation. sFlt-1 is elevated in endothelial dysfunction, such as sepsis (Ugalde et al. 2024), (Wazan, Widhibrata, and Liu 2024), (Greco et al. 2018).\nThe sFlt-1 assay was removed from the multiplex due to difficulty in finding a working antibody pair and respective recombinant protein. All screened options gave little or no signal.\n\n\n\n\nAl-Lamki, Rafia S., and Tanya N. Mayadas. 2015. “TNF Receptors: Signaling Pathways and Contribution to Renal Dysfunction.” Kidney International 87 (2): 281–96. https://doi.org/10.1038/ki.2014.285.\n\n\nBemelmans, M. H. A., L. J. H. van Tits, and W. A. Buurman. 2017. “Tumor Necrosis Factor: Function, Release and Clearance.” Critical Reviews in Immunology 37 (2–6): 249–59. https://doi.org/10.1615/critrevimmunol.v37.i2-6.50.\n\n\nBrouwers, Judith, Rintis Noviyanti, Rob Fijnheer, Philip G. de Groot, Leily Trianty, Siti Mudaliana, Mark Roest, Din Syafruddin, Andre van der Ven, and Quirijn de Mast. 2013. “Platelet Activation Determines Angiopoietin-1 and VEGF Levels in Malaria: Implications for Their Use as Biomarkers.” Edited by Ana Paula Arez. PLoS ONE 8 (6): e64850. https://doi.org/10.1371/journal.pone.0064850.\n\n\nDavies, Julie. 2015. “Procalcitonin.” Journal of Clinical Pathology 68 (9): 675–79. https://doi.org/10.1136/jclinpath-2014-202807.\n\n\nFisher, J., and A. Linder. 2017. “Heparin-Binding Protein: A Key Player in the Pathophysiology of Organ Dysfunction in Sepsis.” Journal of Internal Medicine 281 (6): 562–74. https://doi.org/10.1111/joim.12604.\n\n\nGreco, Marilena, Claudio Palumbo, Fernando Sicuro, and Giambattista Lobreglio. 2018. “Soluble Fms-Like Tyrosine Kinase-1 Is a Marker of Endothelial Dysfunction During Sepsis.” Journal of Clinical Medicine Research 10 (9): 700–706. https://doi.org/10.14740/jocmr3505w.\n\n\nGyurkovska, Valeriya, and Nina Ivanovska. 2016. “Distinct Roles of TNF-Related Apoptosis-Inducing Ligand (TRAIL) in Viral and Bacterial Infections: From Pathogenesis to Pathogen Clearance.” Inflammation Research 65 (6): 427–37. https://doi.org/10.1007/s00011-016-0934-1.\n\n\nHaller, Otto, and Georg Kochs. 2019. “Mx Genes: Host Determinants Controlling Influenza Virus Infection and Trans-Species Transmission.” Human Genetics 139 (6–7): 695–705. https://doi.org/10.1007/s00439-019-02092-8.\n\n\nHayney, Mary S., Kelsey M. Henriquez, Jodi H. Barnet, Tola Ewers, Heather M. Champion, Sean Flannery, and Bruce Barrett. 2017. “Serum IFN-γ-Induced Protein 10 (IP-10) as a Biomarker for Severity of Acute Respiratory Infection in Healthy Adults.” Journal of Clinical Virology 90 (May): 32–37. https://doi.org/10.1016/j.jcv.2017.03.003.\n\n\nKang, Sujin, and Tadamitsu Kishimoto. 2021. “Interplay Between Interleukin-6 Signaling and the Vascular Endothelium in Cytokine Storms.” Experimental &Amp; Molecular Medicine 53 (7): 1116–23. https://doi.org/10.1038/s12276-021-00649-0.\n\n\nKim, Minah, Breanna Allen, Emilia A. Korhonen, Maximilian Nitschké, Hee Won Yang, Peter Baluk, Pipsa Saharinen, et al. 2016. “Opposing Actions of Angiopoietin-2 on Tie2 Signaling and FOXO1 Activation.” Journal of Clinical Investigation 126 (9): 3511–25. https://doi.org/10.1172/jci84871.\n\n\nLei, Jie, Xiaowan Yin, Hong Shang, and Yongjun Jiang. 2019. “IP-10 Is Highly Involved in HIV Infection.” Cytokine 115 (March): 97–103. https://doi.org/10.1016/j.cyto.2018.11.018.\n\n\nLeligdowicz, Aleksandra, Melissa Richard-Greenblatt, Julie Wright, Valerie M. Crowley, and Kevin C. Kain. 2018. “Endothelial Activation: The Ang/Tie Axis in Sepsis.” Frontiers in Immunology 9 (April). https://doi.org/10.3389/fimmu.2018.00838.\n\n\nMatsushima, Kouji, De Yang, and Joost J. Oppenheim. 2022. “Interleukin-8: An Evolving Chemokine.” Cytokine 153 (May): 155828. https://doi.org/10.1016/j.cyto.2022.155828.\n\n\nRuiz, Andy, Yadira Palacios, Irene Garcia, and Leslie Chavez-Galan. 2021. “Transmembrane TNF and Its Receptors TNFR1 and TNFR2 in Mycobacterial Infections.” International Journal of Molecular Sciences 22 (11): 5461. https://doi.org/10.3390/ijms22115461.\n\n\nSaraiva, Margarida, Paulo Vieira, and Anne O’Garra. 2019. “Biology and Therapeutic Potential of Interleukin-10.” Journal of Experimental Medicine 217 (1). https://doi.org/10.1084/jem.20190418.\n\n\nSproston, Nicola R., and Jason J. Ashworth. 2018. “Role of c-Reactive Protein at Sites of Inflammation and Infection.” Frontiers in Immunology 9 (April). https://doi.org/10.3389/fimmu.2018.00754.\n\n\nTanaka, T., M. Narazaki, and T. Kishimoto. 2014. “IL-6 in Inflammation, Immunity, and Disease.” Cold Spring Harbor Perspectives in Biology 6 (10): a016295–95. https://doi.org/10.1101/cshperspect.a016295.\n\n\nTheobald, Vivienne, Felix Carl Fabian Schmitt, Chiara Simone Middel, Lena Gaissmaier, Thorsten Brenner, and Markus Alexander Weigand. 2024. “Triggering Receptor Expressed on Myeloid Cells-1 in Sepsis, and Current Insights into Clinical Studies.” Critical Care 28 (1). https://doi.org/10.1186/s13054-024-04798-2.\n\n\nUgalde, Miguel Javier, Alberto Caballero, Marta Martín Fernández, Eduardo Tamayo, and Olga de la Varga-Martínez. 2024. “Valor Del Biomarcador Tirosina Quinasa 1 Soluble Tipo Fms (sFLT-1) En El Diagnóstico y Pronóstico de La Sepsis: Una Revisión Sistemática.” Medicina Clínica 163 (5): 224–31. https://doi.org/10.1016/j.medcli.2024.03.027.\n\n\nWazan, Layal EI, Ariel Widhibrata, and Guei-Sheung Liu. 2024. “Soluble FLT-1 in Angiogenesis: Pathophysiological Roles and Therapeutic Implications.” Angiogenesis 27 (4): 641–61. https://doi.org/10.1007/s10456-024-09942-8.\n\n\nZhao, Ting, Zhongping Su, Yingchang Li, Xiaoren Zhang, and Qiang You. 2020. “Chitinase-3 Like-Protein-1 Function and Its Role in Diseases.” Signal Transduction and Targeted Therapy 5 (1). https://doi.org/10.1038/s41392-020-00303-7.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>List of Markers</span>"
    ]
  },
  {
    "objectID": "Buffers_and_Reagents.html",
    "href": "Buffers_and_Reagents.html",
    "title": "5  Buffers & Reagents",
    "section": "",
    "text": "5.1 Buffers for general assay procedures",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Buffers & Reagents</span>"
    ]
  },
  {
    "objectID": "Buffers_and_Reagents.html#reagents",
    "href": "Buffers_and_Reagents.html#reagents",
    "title": "5  Buffers & Reagents",
    "section": "5.2 Reagents",
    "text": "5.2 Reagents\nThe following reagents are needed\n\n\n\n\n\n\n\n\n\nPRODUCT DESCRIPTION\nManufacturer\nPart No.\nPack size\n\n\n\n\nPBS tablets\nSigma\nP4417-100TAB\n100 tablets\n\n\nProtease inhibitor (for DBS samples only)\nRoche\n11697498001\n20 tabs\n\n\nBSA\nSigma\nA4503-100G\n100 g\n\n\nEDC\nSigma\n11851335\n5 g\n\n\nNHS\nSigma\n10391314\n500 mg\n\n\nMES\nSigma\nM3671\n50 g\n\n\nSodium phosphate monobasic\nSigma\nS8282\n500 g\n\n\nTween 20\nSigma\nP1379-100ML\n100 ml\n\n\nNaOH (sodium hydroxide)\nSigma\nS5881-500G\n500 g\n\n\n\n\n5.2.1 Deionised water (dH2O)\nFilter 50 mL of deionised water through a 0.2 µm filter into a sterile container.\n\n\n5.2.2 PBS\n1 tablet (Sigma; P4417) per 200 mL deionised water.\nFilter through 0.2 µm filter into one or more sterile containers.\n\n\n5.2.3 PBST (wash buffer)\nPBS + 0.5 mL/L (0.05% v/v) Tween 20\nMake fresh every week.\n\n\n5.2.4 PBS-TBN (blocking/storage/assay buffer)\nPBST + 10 mg/mL BSA + 0.5 mg/mL sodium azide\nPer 100 mL PBST, add:\n\n1 g BSA\n500 µL of 10% (100 mg/mL) sodium azide solution in deionised water\n\n*CAUTION* - use appropriate PPE and safety measures when handling solid and liquids with sodium azide.\n\n\nFilter through 0.2 µm filter and store in fridge until use.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Buffers & Reagents</span>"
    ]
  },
  {
    "objectID": "Buffers_and_Reagents.html#buffers-for-bead-coupling",
    "href": "Buffers_and_Reagents.html#buffers-for-bead-coupling",
    "title": "5  Buffers & Reagents",
    "section": "5.3 Buffers for bead coupling",
    "text": "5.3 Buffers for bead coupling\n\n5.3.1 Activation buffer\n0.1 M sodium phosphate monobasic, pH 6.2\n\n1.19 g NaH2PO4 (Sigma, S8282)\n100 mL dH2O\nAdjust pH to 6.2 with 5 or 10 M NaOH. Filter through 0.2 µm filter and store in the fridge or freeze aliquots until use.\n\n\n\n5.3.2 Coupling buffer\n50 mM MES, pH 5.0\n\n0.976 g MES (Sigma, M3671)\n100 mL dH2O\nAdjust pH to 5 with 5 or 10 M NaOH. Filter through 0.2 µm filter and store in the fridge or freeze aliquots until use.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Buffers & Reagents</span>"
    ]
  },
  {
    "objectID": "Capture_Antibody_Prep.html",
    "href": "Capture_Antibody_Prep.html",
    "title": "6  Capture Antibody Preparation",
    "section": "",
    "text": "6.1 Capture Antibodies",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Capture Antibody Preparation</span>"
    ]
  },
  {
    "objectID": "Capture_Antibody_Prep.html#capture-antibodies",
    "href": "Capture_Antibody_Prep.html#capture-antibodies",
    "title": "6  Capture Antibody Preparation",
    "section": "",
    "text": "Manufacturer\nPart No.\nPack size\nPRODUCT DESCRIPTION\nComponent\n\n\n\n\nbio-techne\nH00054210-M04\n100 µg\nTREM1 Antibody (2E2)\nCapture\n\n\nbio-techne\nMAB206-100\n100 µg\nHuman/Primate IL-6 MAb (Clone 6708)\nCapture\n\n\nbio-techne\nMAB2172-100\n100 µg\nHuman IL-10 MAb (Clone 127107)\nCapture\n\n\nbio-techne\nMAB225-100\n100 µg\nHuman TNF RI/TNFRSF1A MAb (Clone 16803)\nCapture\n\n\nbio-techne\nMAB25991-100\n100 µg\nHuman/Primate Chitinase 3-like 1 MAb (Clone 384327)\nCapture\n\n\nbio-techne\nMAB266-100\n100 µg\nHuman CXCL10/IP-10/CRG-2 MAb (Clone 33036)\nCapture\n\n\nbio-techne\nMAB375-100\n100 µg\nHuman TRAIL/TNFSF10 MAb (Clone 75411)\nCapture\n\n\nbio-techne\nMAB9231-100\n100 µg\nHuman Angiopoietin-1 MAb (Clone 171733)\nCapture\n\n\nbio-techne\nNB110-85467\n100 µg\nAngiopoietin-2 Antibody (MM0020-1F29)\nCapture\n\n\nbio-techne\nNBP2-12045\n100 µg\nAzurocidin/CAP37/HBP Antibody (MM0099-7F31)\nCapture\n\n\nThermo\nM801\n500 µg\nAnti IL-8 (clone 3IL8-H10)\nCapture\n\n\nThermo\nMA5-24914\n100 µg\nAnti MxA\nCapture",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Capture Antibody Preparation</span>"
    ]
  },
  {
    "objectID": "Capture_Antibody_Prep.html#equipment-consumables",
    "href": "Capture_Antibody_Prep.html#equipment-consumables",
    "title": "6  Capture Antibody Preparation",
    "section": "6.2 Equipment & Consumables",
    "text": "6.2 Equipment & Consumables\n\n\n\n\n\n\n\n\nItem\nSupplier\nCatalogue Number\n\n\n\n\nPipettes and tips for 100-200 µL\nAny suitable\n\n\n\n0.2 µm syringe filter or bottle filter unit\nAny suitable\n\n\n\nSyringe, 50 mL, sterile\nAny suitable\n\n\n\n50 mL tube, sterile\nAny suitable\n\n\n\nProtein low-bind microtubes\nEppendorf\n0030108116\n\n\nLabels or permanent marker pen\nAny suitable\n\n\n\nPhosphate buffered saline (PBS)\nSigma\nP4417",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Capture Antibody Preparation</span>"
    ]
  },
  {
    "objectID": "Capture_Antibody_Prep.html#protocol",
    "href": "Capture_Antibody_Prep.html#protocol",
    "title": "6  Capture Antibody Preparation",
    "section": "6.3 Protocol",
    "text": "6.3 Protocol\n\nMake up PBS as per the Buffers and Reagents protocol.\nSet out and label 10 microtubes per capture antibody.\nRemove antibodies from freezer storage.\nAdd 100 µL of the PBS to each lyophilised antibody (anti IL-8 and anti MxA are already liquid at 1 mg/ml so do not need any liquid adding).\nAllow to rehydrate for a few minutes, vortex gently then spin liquid down briefly.\nAliquot all antibodies into 10 µL volumes, or 50 µl volumes for IL-8.\nStore at -20°C or below.\n\nAll capture antibodies are now at the same stock concentration of 1 mg/mL.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Capture Antibody Preparation</span>"
    ]
  },
  {
    "objectID": "Bead_Coupling.html",
    "href": "Bead_Coupling.html",
    "title": "7  Bead Coupling",
    "section": "",
    "text": "7.1 Assay-specific reagents\nTable 1. Assay-specific reagents needed for bead coupling.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bead Coupling</span>"
    ]
  },
  {
    "objectID": "Bead_Coupling.html#assay-specific-reagents",
    "href": "Bead_Coupling.html#assay-specific-reagents",
    "title": "7  Bead Coupling",
    "section": "",
    "text": "Marker\nComponent\nCatalogue #\nSupplier\nBead region\nµg antibody/million beads\n\n\n\n\nAng-1\nBeads\nMC10018-01\nLuminex\n18\n5\n\n\nAng-2\nBeads\nMC10015-01\nLuminex\n15\n5\n\n\nAzu\nBeads\nMC10027-01\nLuminex\n27\n7\n\n\nCHI3L1\nBeads\nMC10030-01\nLuminex\n30\n4.5\n\n\nIL-6\nBeads\nMC10021-01\nLuminex\n21\n5\n\n\nIL-8\nBeads\nMC10022-01\nLuminex\n22\n5\n\n\nIL-10\nBeads\nMC10026-01\nLuminex\n26\n4\n\n\nIP-10\nBeads\nMC10029-01\nLuminex\n29\n5\n\n\nMxA\nBeads\nMC10028-01\nLuminex\n28\n6\n\n\nsTNFR1\nBeads\nMC10020-01\nLuminex\n20\n6\n\n\nsTREM-1\nBeads\nMC10014-01\nLuminex\n14\n6\n\n\nTRAIL\nBeads\nMC10025-01\nLuminex\n25\n6\n\n\nAng-1\nCapture antibody\nMAB9231\nBio-techne\n18\n5\n\n\nAng-2\nCapture antibody\nNB110-85467\nBio-techne\n15\n5\n\n\nAzu\nCapture antibody\nNBP2-12045\nBio-techne\n27\n7\n\n\nCHI3L1\nCapture antibody\nMAB25991\nBio-techne\n30\n4.5\n\n\nIL-6\nCapture antibody\nMAB206\nBio-techne\n21\n5\n\n\nIL-8\nCapture antibody\nM801\nThermo\n22\n5\n\n\nIL-10\nCapture antibody\nMAB2172\nBio-techne\n26\n4\n\n\nIP-10\nCapture antibody\nMAB266\nBio-techne\n29\n5\n\n\nMxA\nCapture antibody\nMA5-24914\nBio-techne\n28\n6\n\n\nsTNFR1\nCapture antibody\nMAB225\nBio-techne\n20\n6\n\n\nsTREM-1\nCapture antibody\nH00054210-M04\nBio-techne\n14\n6\n\n\nTRAIL\nCapture antibody\nMAB375\nBio-techne\n25\n6",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bead Coupling</span>"
    ]
  },
  {
    "objectID": "Bead_Coupling.html#other-consumables-reagents-and-equipment-needed.",
    "href": "Bead_Coupling.html#other-consumables-reagents-and-equipment-needed.",
    "title": "7  Bead Coupling",
    "section": "7.2 Other consumables, reagents and equipment needed.",
    "text": "7.2 Other consumables, reagents and equipment needed.\nTable 2. Other materials needed for bead coupling.\n\n\n\n\n\n\n\n\nItem\nSupplier\nCatalogue number\n\n\n\n\nSodium phosphate monobasic (NaH2PO4)\nSigma\nS8282\n\n\nSodium hydroxide (NaOH)\nSigma\nS5881\n\n\nPhosphate buffered saline (PBS)\nSigma\nP4417\n\n\nSulfo-NHS\nThermo\n24510\n\n\nEDC\nThermo\n22980\n\n\nProtein low-bind microtubes, 1 per coupling\nEppendorf\n0030108116 or 0030108132\n\n\nPipettes and tips for 10 µL, 200 µL, 1 mL\nAny suitable\n\n\n\n0.2 µm syringe filters\nAny suitable\n\n\n\nSyringe, 50 mL, sterile\nAny suitable\n\n\n\n50 mL tube, sterile\nAny suitable\n\n\n\nMagnetic tube rack\nInvitrogen\n12321D\n\n\nEnd-over-end rotating mixer\nAny suitable\n\n\n\nFine balance\nAny suitable\n\n\n\npH meter\nAny suitable\n\n\n\nSonicating waterbath\nVWR\n142-6044",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bead Coupling</span>"
    ]
  },
  {
    "objectID": "Bead_Coupling.html#preparation",
    "href": "Bead_Coupling.html#preparation",
    "title": "7  Bead Coupling",
    "section": "7.3 Preparation",
    "text": "7.3 Preparation\nThis protocol uses EDC [1-ethyl-3-(3-dimethylaminopropyl)-carbodiimide hydrochloride]. EDC absorbs moisture from the air. It is helpful to aliquot it into 50 mg, single-use, amounts in screw cap tubes on receipt and to store these in individual ziplock bags with desiccant, at -20° C.\nFor quality assurance processes, we recommend keeping note of the lot numbers and expiry dates of both beads and capture antibodies. The diagnostic performance of beads changes with time, see bead validity information elsewhere in this paper for individual bead validity, however all beads are useable for 3 months.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bead Coupling</span>"
    ]
  },
  {
    "objectID": "Bead_Coupling.html#protocol-a---coupling-beads-for-8-plates",
    "href": "Bead_Coupling.html#protocol-a---coupling-beads-for-8-plates",
    "title": "7  Bead Coupling",
    "section": "7.4 Protocol A - Coupling beads for 8 plates",
    "text": "7.4 Protocol A - Coupling beads for 8 plates\n⌚ Timing: 2 hours, then 2 hours incubation, 1h45m to finish. Total approx. 5h45m.\nThis protocol takes place at ambient temperature. All incubations are at ambient temperature.\nTip: Protect beads from light with a foil cover when they are not being manipulated such as during incubations.\n\nPrepare the General Buffers and Buffers for Bead Coupling, as detailed in the Buffers and Reagents file.\nRetrieve capture antibodies: consult Table 3 below for the required number of aliquots of each capture antibody (prepared as detailed in Capture Antibody Prep), and place these in the fridge to thaw.\nLabel microtubes (Eppendorf, protein lo-bind) one for each coupling, with at least antigen name and bead region.\nVortex and sonicate the bead stocks for ~60 seconds of each. Vortex some more immediately before pipetting.\nTransfer 120 µL of bead stock (1.5 x 106 beads for 8 full plates) into each respective tube.\nPut tubes in magnet rack for 60 s.\nRemove supernatant without disturbing beads.\nWash beads: Remove tubes from magnet rack. Add 100 µL dH2O. Vortex & sonicate for ~20 s of each.\nInsert tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nActivate beads: Remove tube from magnet rack. Add 80 µL Activation buffer. Vortex & sonicate, ~20 s each.\nIn two separate tubes, make up 50 mg/mL sulfo-NHS and 50 mg/mL EDC in Activation buffer. 25 mg in 500 µL is sufficient for 12 bead couplings. These should always be made fresh during the protocol immediately before use, and not stored.\nAdd 10 µL of the sulfo-NHS solution to the beads. Vortex.\nAdd 10 µL of the EDC solution to the beads. Vortex.\nIncubate 10 mins @ room temp. Vortex. Incubate for further 10 mins.\nDuring the incubation, set up new 1.5 mL tubes for antibody dilution in MES buffer, one tube per bead region.\nDispense 400 µL MES to each tube.\nRemove the MES volume indicated for each antibody in Table 3, column 5 (so that when antibody is added, the volume is restored to 400 µL in each case).\nAdd in the required volume of each antibody (Table 3, column 5):\n\nTable 3. Capture antibody for 1.5 x 106 beads, for 8 plates.\n\n\n\n\n\n\n\n\n\n\n\nAntibody on bead\n\n\nAb catalogue number (bio-techne unless stated)\n\n\nAntibody amount (µg) per million beads\n\n\nNumber of 10 ul aliquots of capture Ab needed\n\n\nVolume of capture antibody needed for 1.5e6 beads (µL)\n\n\n\n\n\nAng-1\nMAB9231\n5\n1\n7.5\n\n\nAng-2\nNB110-85467\n5\n1\n7.5\n\n\nAzu\nNBP2-12045\n7\n2\n10.5\n\n\nCHI3L1\nMAB25991\n4.5\n1\n6.8\n\n\nIL-6\nMAB206\n5\n1\n7.5\n\n\nIL-8\nM801 (Thermo)\n5\n1\n7.5\n\n\nIL-10\nMAB2172\n4\n1\n6.0\n\n\nIP-10\nMAB266\n5\n1\n7.5\n\n\nMxA\nMA5-24914 (Thermo)\n6\n1\n9.0\n\n\nsTNF-R1\nMAB225\n6\n1\n9.0\n\n\nsTREM1\nH00054210-M04\n6\n1\n9.0\n\n\nTRAIL\nMAB375\n6\n1\n9.0\n\n\n\n\nSet these antibody tubes aside and continue with the beads.\nInsert bead tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nMES wash 1: Remove tube from magnet rack. Add 250 µL MES buffer. Vortex & sonicate for ~ 20 s each.\nInsert tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nMES wash 2: Remove tube from magnet rack. Add 250 µL MES buffer. Vortex & sonicate for ~ 20 s each.\nInsert tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nAdd 100 µL MES buffer to each bead tube.\nTransfer all 400 µL of each antibody dilution into the respective bead tubes and vortex. (So that the antibody amount is eventually diluted in 0.5 mL of MES by the time it is incubated with the beads, as per Luminex scale-up table).\nIncubate 2 hours on rotating mixer at room temp. Record start time ______________\nInsert tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nRemove tube from magnet rack. Add 500 µL PBS-TBN. Vortex & sonicate for ~20 s.\nInsert tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nPBS-TBN wash 1: Remove tube from magnet rack. Add 1 mL PBS-TBN. Vortex & sonicate for ~20 s.\nInsert tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nPBS-TBN wash 2: Remove tube from magnet rack. Add 1 mL PBS-TBN. Vortex & sonicate for ~20 s.\nInsert tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nRemove tube from magnet rack. Resuspend coupled beads in 200 µL PBS-TBN. Vortex. This is 1.66x the original volume (120 µL) to give a theoretical count of 7.5 x 106 beads/mL.\nEnsure newly coupled bead tubes are fully labelled with at least: assay, bead region, date.\nStore the coupled beads at +4°C and protect from light.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bead Coupling</span>"
    ]
  },
  {
    "objectID": "Bead_Coupling.html#protocol-b---coupling-beads-for-52-plates",
    "href": "Bead_Coupling.html#protocol-b---coupling-beads-for-52-plates",
    "title": "7  Bead Coupling",
    "section": "7.5 Protocol B - Coupling beads for 52 plates",
    "text": "7.5 Protocol B - Coupling beads for 52 plates\n⌚ Timing: 2 hours, then 2 hours incubation, 1h45m to finish. Total approx. 5h45m.\nThe protocol takes place at ambient temperature. All incubations are at ambient temperature.\n\nPrepare the General Buffers and Buffers for Bead Coupling, as detailed in the Buffers and Reagents file.\nRetrieve capture antibodies: consult Table 2 below for the required number of aliquots of each capture antibody (prepared as detailed in Capture Antibody Prep), and place these in the fridge to thaw.\nLabel microtubes (Eppendorf, protein lo-bind) one for each coupling, with at least antigen name and bead region.\nVortex and sonicate the bead stocks for ~60 seconds of each. Vortex some more immediately before pipetting.\nTransfer 500 µL of bead stock (6.25 x 106 beads for ~52 full plates) into each respective tube.\nPut tube in magnet rack for 60 s.\nRemove supernatant without disturbing beads.\nWash beads: Remove tubes from magnet rack. Add 100 µL dH2O. Vortex & sonicate for ~20 s of each.\nInsert tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nActivate beads: Remove tube from magnet rack. Add 80 µL Activation buffer. Vortex & sonicate, ~20 s each.\nIn two separate tubes, make up 50 mg/mL sulfo-NHS and 50 mg/mL EDC in Activation buffer. 25 mg in 500 µL is sufficient for 12 bead couplings. These should always be made fresh during the protocol immediately before use, and not stored.\nAdd 10 µL of the sulfo-NHS solution to the beads. Vortex.\nAdd 10 µL of the EDC solution to the beads. Vortex.\nIncubate 10 mins @ room temp. Vortex. Incubate for further 10 mins.\nDuring the incubation, set up new 1.5 mL tubes for antibody dilution in MES buffer, one tube per bead region.\nDispense 400 µL MES to each tube.\nRemove the MES volume indicated for each antibody in Table 4, column 5 (so that when antibody is added, the volume is restored to 400 µL in each case).\nAdd in the required volume of each antibody (Table 4, column 5):\nTable 4. Capture antibody for 6.25 x 106 beads, for approx. 52 plates.\n\n\n\n\n\n\n\n\n\n\n\n\nAntibody on bead\n\n\nAb catalogue number (bio-techne unless stated)\n\n\nAntibody amount per million beads\n\n\nNumber of 10 µL aliquots of capture Ab needed\n\n\nVolume of capture antibody needed for 1.5e6 beads (µL)\n\n\n\n\n\nAng-1\nMAB9231\n5\n4\n31.3\n\n\nAng-2\nNB110-85467\n5\n4\n31.3\n\n\nAzu\nNBP2-12045\n7\n5\n43.8\n\n\nCH3L1\nMAB25991\n4.5\n3\n28.1\n\n\nIL-6\nMAB206\n5\n4\n31.3\n\n\nIL-8\nM801 (Thermo)\n5\n4 (1 if 50 µL aliquot)\n31.3\n\n\nIL-10\nMAB2172\n4\n3\n25.0\n\n\nIP-10\nMAB266\n5\n4\n31.3\n\n\nMxA\nMA5-24914 (Thermo)\n6\n4\n37.5\n\n\nsTNF-R1\nMAB225\n6\n4\n37.5\n\n\nsTREM1\nH00054210-M04\n6\n4\n37.5\n\n\nTRAIL\nMAB375\n6\n4\n37.5\n\n\n\n\nSet these antibody tubes aside and continue with the beads.\nInsert bead tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nMES wash 1: Remove tube from magnet rack. Add 500 µL MES buffer. Vortex & sonicate for ~ 20 s each.\nInsert tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nMES wash 2: Remove tube from magnet rack. Add 500 µL MES buffer. Vortex & sonicate for ~ 20 s each.\nInsert tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nAdd 100 µL MES buffer to beads.\nTransfer all 400 µL of each antibody dilution into the respective bead tubes and vortex. (So that the antibody amount is eventually diluted in 0.5 mL of MES by the time it is incubated with the beads, as per Luminex scale-up table).\nIncubate 2 hours on rotating mixer at room temp. Record start time ______________\nInsert tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nRemove tube from magnet rack. Add 500 µL PBS-TBN. Vortex & sonicate for ~20 s.\nInsert tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nPBS-TBN wash 1: Remove tube from magnet rack. Add 1 mL PBS-TBN. Vortex & sonicate for ~20 s.\nInsert tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nPBS-TBN wash 2: Remove tube from magnet rack. Add 1 mL PBS-TBN. Vortex & sonicate for ~20 s.\nInsert tube into magnet rack, 60 s.\nRemove supernatant without disturbing beads.\nRemove tube from magnet rack. Resuspend coupled beads in 830 µL PBS-TBN. Vortex. This is 1.66x the original volume (500 µL) to give a theoretical count of 7.5 x 106 beads/mL.\nEnsure newly coupled bead tubes are fully labelled with at least: assay, bead region, date.\nStore the coupled beads at +4°C and protect from light.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bead Coupling</span>"
    ]
  },
  {
    "objectID": "Coupling_Confirmation.html",
    "href": "Coupling_Confirmation.html",
    "title": "8  Coupling Confirmation",
    "section": "",
    "text": "8.1 Overview\nThis protocol can be used to confirm that antibodies have been correctly conjugated to beads. It works by using anti-species antibodies. Anti mouse-biotin is diluted in a series and reacted with the newly coupled beads which are coupled to mouse and rat antibodies.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Coupling Confirmation</span>"
    ]
  },
  {
    "objectID": "Coupling_Confirmation.html#reagents-consumables-equipment",
    "href": "Coupling_Confirmation.html#reagents-consumables-equipment",
    "title": "8  Coupling Confirmation",
    "section": "8.2 Reagents, consumables & equipment",
    "text": "8.2 Reagents, consumables & equipment\n\n\n\nItem\nManufacturer\nCatalogue number\n\n\n\n\nAnti mouse-biotin antibody\nBio-techne\nBAF018\n\n\nPhosphate buffered saline (PBS)\nSee buffers & reagents section\n\n\n\nPBS-TBN\nSee buffers & reagents section\n\n\n\nStreptavidin-R-Phycoerythrin (SA-PE, 1 mg/mL)\nThermo\nS806\n\n\nAntibody-coupled beads\nSee bead coupling section\n\n\n\nProtein low-bind microtubes 1.5 or 2 mL\nEppendorf\n\n\n\nBlack 96-well plate\nBio-Rad\n\n\n\nPipettes and tips for 1-200 µL\nany suitable\n\n\n\n0.2 µm syringe filters\nany suitable\n\n\n\nSyringe, 50 mL\nany suitable\n\n\n\nSterile 50 mL tube\nany suitable\n\n\n\nMagPix machine\nLuminex",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Coupling Confirmation</span>"
    ]
  },
  {
    "objectID": "Coupling_Confirmation.html#protocol",
    "href": "Coupling_Confirmation.html#protocol",
    "title": "8  Coupling Confirmation",
    "section": "8.3 Protocol",
    "text": "8.3 Protocol\n⌚ Timing: about 3 hours.\n\nOn first use of the anti mouse-biotin, rehydrate it to be 0.2 mg/mL and aliquot into small volumes for freezer storage to minimise freeze-thaw cycles.\nThaw an aliquot of anti mouse-biotin, 3 µL is required for running two columns on a plate.\nAdd 900 µL of PBS-TBN to a tube for diluting the beads.\nGet the newly coupled beads, vortex then sonicate for 20 s of each.\nAdd 2.4 µL of each newly-coupled bead to the 900 µL and vortex mix. (To give a theoretical 20,000 beads/mL, or 1000 beads/well, assuming 7.5x106 beads/mL stock).\nLabel 7 tubes (1-7) for the anti mouse-biotin dilutions, corresponding to concentrations: 2, 1, 0.5, 0.25, 0.125, 0.063, 0.031 µg/mL.\nDispense PBS-TBN diluent into each tube in the volumes indicated in the bottom row of Figure 1.\nSerially dilute anti mouse-biotin in PBS-TBN by adding 3 µL of the 0.2 mg/mL stock into Tube 1 (297 µL PBS-TBN) and transferring 150 µL of this into 150 µL PBS-TBN sequentially until Tube 7, vortex mixing between pipetting (Figure 1).\n\n\n\n\nFigure 1. Dilution series of anti mouse biotin.\n\n\n\nDispense 50 µL/well of the diluted beads into two columns of a black plate as per plate layout below.\nWash beads once: Put plate on magnet, wait 60 s, invert plate on magnet to empty the liquid. Add 100 µL/well PBST, removing from the magnet when adding wash buffer. Replace plate on magnet for 60 s and remove liquid as before, dabbing gently on tissue before adding the next reagent.\nAdd 50 µL/well of the anti mouse-biotin dilutions (1-7) in duplicate, and 50 µL PBS-TBN as the blank, as per plate layout:\n\n\n\n\n\n1\n2\n\n\n\n\nA\n2.00 µg/mL\n2.00 µg/mL\n\n\nB\n1.00 µg/mL\n1.00 µg/mL\n\n\nC\n0.50 µg/mL\n0.50 µg/mL\n\n\nD\n0.25 µg/mL\n0.25 µg/mL\n\n\nE\n0.125 µg/mL\n0.125 µg/mL\n\n\nF\n0.063 µg/mL\n0.063 µg/mL\n\n\nG\n0.031 µg/mL\n0.031 µg/mL\n\n\nH\nBlank 0 µg/mL\nBlank 0 µg/mL\n\n\n\n\nCover and incubate on shaker for 45 mins at ambient temperature.\nDuring the incubation, dilute SA-PE to 3 µg/mL by adding 2.7 µL of SA-PE to 900 µL PBS-TBN. Store this in the fridge until use.\nWash plate 3 times as before with 100 uL/well PBST.\nAdd 50 µL/well of diluted SA-PE to the plate.\nCover & incubate on shaker for 45 mins.\nWash plate 3 times as before with 100 µL/well PBST.\nAdd 100 µL PBS-TBN to each well and read on MagPix the same day using the 12-plex protocol.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Coupling Confirmation</span>"
    ]
  },
  {
    "objectID": "Coupling_Confirmation.html#analysis-interpretation-of-results",
    "href": "Coupling_Confirmation.html#analysis-interpretation-of-results",
    "title": "8  Coupling Confirmation",
    "section": "8.4 Analysis & interpretation of results",
    "text": "8.4 Analysis & interpretation of results\nWe performed a series of coupling confirmations. The MagPix output file is provided in data/coupling_confirmation/Bead_Coupling_Data.csv\nFor this analysis, we use only the median fluorescence data and only need to include the rows of the mfi data which relate to the experiments where a biotinylated, anti-mouse antibody was directed against the assay specific, antibody-coupled microbeads.\nThe basic steps include\n\nLoading the csv file, renaming problematic columns\nRemoving headers from the MagPix output file\nFiltering the data to include only MFI data\nFiltering the MFI data to include only the relevant lines of data\nPivoting the data in to a tidy format\nCharting the data\n\n\nlibrary(tidyverse)\n# read data in to df\n\ndf&lt;-suppressMessages(read_csv(\"data/coupling_confirmation/Bead_Coupling_Data.csv\",skip = 41,na = c(\"\",\"NA\",\"NaN\"),show_col_types = F))%&gt;%\n                setNames(tolower(gsub(\"-\",\"_\",names(.)))) %&gt;%\n                mutate(sample= fct_explicit_na(sample)) %&gt;%\n                select_if(!names(.) %in% c('...16','...17', 'location', 'total events')) %&gt;%\n                rename_at(vars(matches(\"^CH3L1$\")), function(x) \"CHI3L1\")\n\n#remove extraneous lines and keep only mfi data for anti-mouse biotinylated detection antibodies.\ndf &lt;- df[49:64,]\n\n#pivot data\ndf &lt;- df %&gt;% pivot_longer(cols=(-sample),names_to = \"marker\",values_to = \"mfi\") %&gt;% \n  separate(col = sample,into = c(\"sample\",\"dilution\"),sep = \"biotin \") %&gt;% \n  mutate(dilution = as.numeric(dilution))\n\nggplot(df,aes(as.numeric(dilution),as.numeric(mfi)))+\n  geom_smooth(method = 'loess',formula = 'y ~ x')+\n  geom_point()+\n  facet_wrap(.~marker,scales = \"free\")+\n  xlab(\"Dilution Series\")+\n  ylab(\"mfi\")+\n  ggtitle(\"Absolute mfi [free y axis] of antibody conjugated microbeads\")\n\n\n\n\n\n\n\n\nThe chart above confirms that these microbeads (a) have successfully coupled to the assay specific mouse and rat antibodies and (b) that the MFI response varies in response to serial dilution of the biotinylated anti-mouse secondary antibody.\n\nggplot(df,aes(as.numeric(dilution),as.numeric(mfi)))+\n  geom_smooth(method = \"loess\",formula = \"y~x\")+\n  geom_point()+\n  facet_wrap(.~marker,scales = \"fixed\")+\n  xlab(\"Dilution Series\")+\n  ylab(\"mfi\")+\n  ggtitle(\"Absolute mfi [fixed y axis] of antibody conjugated microbeads\")\n\n\n\n\n\n\n\n\nWhen charted on a fixed y axis, it becomes clearer that some markers (i.e. CHI3L1 and MxA) have a much lower MFI across the full range of dilutions. This could be explained by lower avidity or affinity between the primary and secondary antibodies. This is likely the case for the CHI3L1 antibody which is from rat and exhibits low reactivity with the anti mouse-biotin. Low signal could also indicate steric effects, or experimental issues and failure to couple efficiently which may indicate that the beads are not useable.\nNote that whilst both MxA and CHI3L1 both had lower MFI values than other markers, they still exhibited a dose-response curve that seems appropriate for experimental use. Assays such as MxA and CHI3L1 which both had low dose:response ratios with the anti mouse coupling confirmation are potentially usable because the response with the specific antigen standards may differ and would determine their true utility in the assay.\nWe would reject a bead-set where there was either (a) no, or unexpectedly low fluorescence response or (b) no dose-response, in the coupling confirmation.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Coupling Confirmation</span>"
    ]
  },
  {
    "objectID": "Detection_Antibody_Prep.html",
    "href": "Detection_Antibody_Prep.html",
    "title": "9  Detection Antibody Prep",
    "section": "",
    "text": "9.1 Reagents and materials\nTable 1. Specific reagents needed. Quantity of each item should be obtained from the Shopping List document for your number of samples.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Detection Antibody Prep</span>"
    ]
  },
  {
    "objectID": "Detection_Antibody_Prep.html#reagents-and-materials",
    "href": "Detection_Antibody_Prep.html#reagents-and-materials",
    "title": "9  Detection Antibody Prep",
    "section": "",
    "text": "Make PBS and PBS-TBN as per the Buffers and Reagents protocol.\n\n\n\n\n\n\n\n\n\n\n\nManufacturer\nPart No.\nPack size\nPRODUCT DESCRIPTION\n\n\n\n\nbio-techne\n370-0010\n3\nLightning-Link (R) Rapid Type A Biotin Antibody Labeling Kit\n\n\nbio-techne\nAF2200\n100 ug\nHuman Azurocidin/CAP37/HBP Affinity Purified Polyclonal Ab\n\n\nbio-techne\nAF7946\n100 ug\nHuman MxA/Mx1 Affinity Purified Polyclonal Ab\n\n\nbio-techne\nBAF1278\n50 ug\nHuman TREM-1 Biotinylated Affinity Purified PAb\n\n\nbio-techne\nBAF206\n50 ug\nHuman/Primate IL-6 Biotinylated Affinity Purified PAb\n\n\nbio-techne\nBAF208\n50 ug\nHuman IL-8/CXCL8 Biotinylated Affinity Purified PAb\n\n\nbio-techne\nBAF217\n100 ug\nHuman IL-10 Biotinylated Affinity Purified PAb\n\n\nbio-techne\nBAF225\n50 ug\nHuman TNF RI/TNFRSF1A Biotinylated Affinity Purified PAb\n\n\nbio-techne\nBAF2599\n50 ug\nHuman/Primate Chitinase 3-like 1 Biotinylated Aff Pur PAb\n\n\nbio-techne\nBAF266\n50 ug\nHuman CXCL10/IP-10 Biotinylated Affinity Purified PAb\n\n\nbio-techne\nBAF375\n50 ug\nHuman/Primate TRAIL/TNFSF10 Biotinylated Aff Pur PAb\n\n\nbio-techne\nBAF623\n50 ug\nHuman Angiopoietin-2 Biotinylated Affinity Purified PAb\n\n\nbio-techne\nBAF923\n50 ug\nHuman Angiopoietin-1 Biotinylated Affinity Purified PAb",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Detection Antibody Prep</span>"
    ]
  },
  {
    "objectID": "Detection_Antibody_Prep.html#protocol",
    "href": "Detection_Antibody_Prep.html#protocol",
    "title": "9  Detection Antibody Prep",
    "section": "9.2 Protocol",
    "text": "9.2 Protocol\n\n9.2.0.1 Biotinylation of un-labelled detection antibodies for Azu & MxA\nTiming: about 30-40 mins, with optional overnight alternative.\n1. From LightningLink(LL)-biotin kits, thaw LL-Modifier and LL-Quencher reagents and retrieve as many biotin vials as needed, one for each antibody to be conjugated.\n2. Label the LL glass vials with ‘Azu’ or ‘MxA’, date, ‘0.833 µg/mL’.\n3. Vortex and briefly spin down the LL-Modifier and LL-Quencher tubes.\n4. Rehydrate Anti Azu (AF2200) and Anti MxA (AF7946) each with 100 µL of filtered PBS to give 1 mg/mL. Allow 60 sec for the antibody to rehydrate then vortex gently and spin down briefly.\n5. Add 10 µL of LL-Modifier from the LL kit to each of the antibody vials and mix by pipetting up and down gently.\n6. Transfer all 110 µL to the respective glass vial and ensure that the lyophilised biotin is rehydrated by gently pipetting up and down once or twice.\n7. Incubate for at least 15 mins at room temp. Can be left even overnight if more convenient.\n8. Add 10 µL of LL-Quencher to each glass vial and pipette gently to mix.\n9. Leave for 5 mins before use.\n10. Store the biotinylated antibodies in the fridge. Expiry is 18 months from conjugation date.\n\n\n9.2.0.2 Rehydration of already biotin-labelled antibodies\nAll other detection antibodies are already biotinylated- they need to be rehydrated to achieve their respective stock concentrations.\nRehydration concentrations have been calculated so that equal volumes of each of the biotin antibodies is added during running the assay (Table 2). This makes the process quicker and less error-prone.\nNote that this does NOT apply to MxA and Azu which are biotin labelled as above using Lightning Link kits and will be used at different volumes on assay day.\nTable 2. Lab worksheet to record lot numbers of detection antibody stocks during rehydration.\n\n\n\n\n\n\n\n\n\n\nAssay\nCat. no\n(bio-techne)\nRecord lot number(s)\nRehydrate each vial with this volume of PBS (ul)\nWhich will give this stock conc (ug/ml)\n\n\nAng2\nBAF623\n\n221.52\n225.7\n\n\nIL-6\nBAF206\n\n221.52\n225.7\n\n\nTRAIL\nBAF375\n\n221.52\n225.7\n\n\nIP-10\nBAF266\n\n221.52\n225.7\n\n\nCHI3L1\nBAF2599\n\n221.52\n225.7\n\n\nAng1\nBAF923\n\n147.68\n338.6\n\n\nTNFR1\nBAF225\n\n147.68\n338.6\n\n\nIL-8\nBAF208\n\n147.68\n338.6\n\n\nIL-10\nBAF217\n\n295.36\n338.6\n\n\nTREM1\nBAF1278\n\n110.76\n451.4\n\n\n\n\n\n9.2.0.3 Aliquotting of detection antibodies into single-use aliquots for storage\n\nTo make per-plate aliquots of detection antibodies, aliquot each one into tubes at the volume given in column 2 of Table 3 below i.e. for single plate aliquots, dispense 14 ul of each antibody into separate tubes. Antibodies should be kept separate at this stage. Store aliquots at -20.\nNOTE that this does NOT apply to MxA and Azu which are stored refigerated and added only upon mixing.\n\n\n\n9.2.0.4 Mixing of detection antibodies into ready-to-use volumes\n\nTo make detection antibody mix on day of use, add PBS-TBN to a tube for the number of plates being run, as per column 4, Table 3.\nThen use this volume to recover the antibody in each aliquot and re-combine them i.e. add 100 ul of PBS-TBN to each aliquot tube, vortex mix, spin down, then transfer all of it back to the main tube. This is because the amount aliquotted is exactly as much as needed, so this ensures that all of it is recovered.\nFinally, add the volumes of MxA and Azu to the mixture from their glass stock vials (columns 5 & 6).\n\nTable 3. Volumes for making Detection Antibody mix on assay day.\n\n\n\n\n\n\n\n\n\n\n\n\nNumber of plates\n\n\nVolume of each Ab (NOT MxA or Azu) (ul)\n\n\nTotal (ul)\n(allowing 3.16 ml per plate which allows almost 10% excess)\n\n\nVolume of PBS-TBN (ul)\n\n\nMxA antibody volume (ul)\n\n\nAzu antibdy volume (ul)\n\n\n\n1\n14\n3,160\n3,010.6\n3.8\n5.6\n\n\n2\n28\n6,320\n6,021.2\n7.6\n11.2\n\n\n3\n42\n9,480\n9,031.8\n11.4\n16.8\n\n\n4\n56\n12,640\n12,042.4\n15.2\n22.4\n\n\n5\n70\n15,800\n15,053.0\n19.0\n28.0\n\n\n6\n84\n18,960\n18,063.6\n22.8\n33.6\n\n\n7\n98\n22,120\n21,074.2\n26.6\n39.2\n\n\n8\n112\n25,280\n24,084.8\n30.4\n44.8\n\n\n9\n126\n28,440\n27,095.4\n34.2\n50.4\n\n\n10\n140\n31,600\n30,106.0\n38.0\n56.0\n\n\n\nTick as you add each Ab:\n\n\n\n\n\n\n\n\n        TNFR1\n        IL6\n        IL8\n        MxA ***\n        Ang1\n        Ang2\n        TRAIL\n        Azu ***\n        IL10\n        TREM\n        IP-10\n        CHI3L1\n\n\n\n\nAfter use in your assay, any remaining antibody mixture can be stored frozen for incidental use. Note that we have not directly compared performance of detection antibodies that have been stored long-term as a mixture versus those stored individually as in this protocol.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Detection Antibody Prep</span>"
    ]
  },
  {
    "objectID": "antigens.html",
    "href": "antigens.html",
    "title": "10  Antigens",
    "section": "",
    "text": "10.1 Protocol\n⌚ Timing: ~3 hours, but can be split into shorter periods if needed (see Tip 2).\nThis protocol takes place at ambient temperature. All incubations are at ambient temperature.\nTip: Keep the proteins as cold as possible, for as long as possible, to avoid degradation. Work with tubes on ice or in chilled racks. Likewise, thaw proteins that are in solution on ice.\nTip 2: If time is limited, prepare a smaller number of proteins at one time, completing the full process of rehydration, aliquotting and storage for these, and return another time to complete the next batch.\nTable 1. Recombinant antigen stock aliquotting.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Antigens</span>"
    ]
  },
  {
    "objectID": "antigens.html#protocol",
    "href": "antigens.html#protocol",
    "title": "10  Antigens",
    "section": "",
    "text": "Prepare filter-sterlised PBS as per Buffers and Reagents protocol.\nLabel protein lo-bind tubes with antigen name, catalogue number, concentration, volume and expiry date. The approximate number of tubes needed for each antigen is shown in column 6 in Table 1 below.\nRehydrate lyophylised antigens using the volumes of PBS listed in column 2 of Table 1.\nNOTE: MxA comes in solution and does not need rehydrating. See manufacturer’s data sheet for concentration.\nLeave vials to sit for 60 seconds to rehydrate, then vortex gently and spin down.\nAliquot into the volumes and number of tubes indicated in columns 5 and 6 of Table 1.\nStore aliquots at -70 or below immediately.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAntigen\n\n\nPBS to add to vial to make stock (ul)\n\n\nStock concentration (ug/ml)\n\n\nVolume needed each time (ul)\n\n\nAliquot size (ul)\n\n\nNumber of aliquots\n\n\n\nAng1\n250\n100\n6\n27\n9\n\n\nAng2\n250\n100\n12\n20\n9\n\n\nAzu\n250\n200\n12\n26\n9\n\n\nCHI3L1\n250\n200\n6\n27\n9\n\n\nIL-6\n100\n100\n4\n10\n9\n\n\nIL-8\n100\n100\n4\n10\n9\n\n\nIL-10\n100\n100\n4\n10\n9\n\n\nIP-10\n100\n100\n4\n10\n9\n\n\nMxA\nnone (already liquid)\nSee data sheet\nDepends on stock conc.\ne.g. 13\ne.g. 4\n\n\nsTNFR1\n250\n100\n4\n10\n9\n\n\nTRAIL\n100\n100\n4\n10\n9\n\n\nTREM1\n500\n100\n4\n54\n9",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Antigens</span>"
    ]
  },
  {
    "objectID": "antibody_pairs.html",
    "href": "antibody_pairs.html",
    "title": "11  Antibody pair screening",
    "section": "",
    "text": "11.1 Overview\nThe following tables provide information on how capture and detection antibodies are paired in the assay. A relatively large number of pairs were tested and we continued to screen pairs until we identified a pair for each marker which met the following quality criteria.\nIn some cases, different sources for recombinant protein analyte were also screened, where the first option was not detected successfully.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Antibody pair screening</span>"
    ]
  },
  {
    "objectID": "antibody_pairs.html#overview",
    "href": "antibody_pairs.html#overview",
    "title": "11  Antibody pair screening",
    "section": "",
    "text": "Absence of cross-reactivity with other analytes or antibodies in the multiplex.\nA working detection range of the target analyte within the physiologically expected range.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Antibody pair screening</span>"
    ]
  },
  {
    "objectID": "antibody_pairs.html#antibody-pairs-and-analytes-screened-and-selected-for-the-final-assay",
    "href": "antibody_pairs.html#antibody-pairs-and-analytes-screened-and-selected-for-the-final-assay",
    "title": "11  Antibody pair screening",
    "section": "11.2 Antibody pairs and analytes screened and selected for the final assay",
    "text": "11.2 Antibody pairs and analytes screened and selected for the final assay\nTable 1. Antibody combinations and recombinant antigens screened and reason for failure, or if passed screening and included in final multiplex. Reagents and catalogue numbers are from bio-techne unless specified otherwise. Product codes beginning AF relate to antigen-affinity-purified polyclonal antibodies and BAF to biotinylated versions of the same. MAB are monoclonal antibodies and BAM are biotinylated monoclonal antibodies. Clone numbers are given for monoclonal antibodies. Reagents and markers in bold were included in the final 12-plex.\n\n\n\n\n\n\n\n\n\n\nMarker\nCapture antibody\nRecombinant antigen\nDetection antibody\nIncluded in final assay (Pass), or reason for failure\n\n\n\n\nAng-1\nMAB9231 (clone 171733)\n923-AN\nBAF923\nPass\n\n\nAng-2\nMAB098 (clone 85816)\n623-AN\nBAM0981 (clone 85834)\nCross-reaction with Ang-1\n\n\n\nMAB0983 (clone 180102)\n623-AN\nBAM0981 (clone 85834)\nWidespread cross-reactivity in multiplex\n\n\n\nNB110-85467 (clone MM0020-1F29)\n623-AN\nBAF623\nPass\n\n\nAzu\nMAB2200 (clone 246322)\n2200-SE\nAF2200*\nPoor sensitivity\n\n\n\nNBP2-12045\n2200-SE\nAF2200*\nPass\n\n\nCHI3L1\nMAB25991\n2599-CH\nBAF2599\nPass\n\n\nCRP\nMAB17071 (clone 232007)\n1707-CR\nBAM17072 (clone 232024)\nCross-reactivity with Azu antigen\n\n\n\nMAB17071 (clone 232007)\n1707-CR\nMA1-10323 (Thermo, clone C7)\nAssay removed from multiplex due to sample dilution needed and unreliable standard curve.\n\n\nIL-6\nMAB206 (clone 6708)\n206-IL\nBAF206\nPass\n\n\nIL-8\nMAB208 (clone 6217)\n208-IL\nBAF208\nPoor sensitivity\n\n\n\nM801 (Thermo, clone 3IL8-H10)\n208-IL\nBAF208\nPass\n\n\nIL-10\nMAB2172 (clone 127107)\n1064-IL\nBAF217\nPass\n\n\nIP-10\nMAB266 (clone 33036)\n266-IP\nBAF266\nPass\n\n\nMxA\nAF7946\nTP307418 (OriGene)\nAF7946*\nCross-reactivity with other antigens (ELISA screen)\n\n\n\nMA5-24914 (Thermo, clone OTI2G12)\nNBP2-51838\nAF7946*\nLower signal than OriGene antigen\n\n\n\nMA5-24914 (Thermo, clone OTI2G12)\nTP307418 (OriGene)\nAF7946*\nPass\n\n\nPCT\nMAB83501 (clone 944002)\n9607-PN\nMAB8350* (clone 919510)\nGeneral cross-reactivity in multiplex\n\n\n\nMAB83502 (clone 95123)\n9607-PN\nMAB8350* (clone 919510)\nGeneral cross-reactivity in multiplex\n\n\n\nMAB8350 (clone 919510)\n9607-PN\nMAB83502* (clone 95123)\nNo signal (ELISA screen)\n\n\n\nAF8350\n9607-PN\nAF8350*\nGeneral cross-reactivity in multiplex. This assay was dropped due to high cross-reactivity or poor performance of all screened antibody combinations.\n\n\nsFlt-1\nMAB321 (clone 49560)\n321-FL\nBAF321\nNo signal (multiplex)\n\n\n\nNBP2-34619 (clone FLT1/659)\n321-FL\nMAB321* (clone 49560)\nPoor sensitivity (ELISA screen)\n\n\n\nAF321\n321-FL\nBAF321\nPoor sensitivity (ELISA screen)\n\n\n\nAF321\n321-FL\nMAB321* (clone 49560)\nOk in singleplex (ELISA screen). Very low sensitivity in multiplex\n\n\n\nAF321\nRP-75748 (Thermo)\nMAB321* (clone 49560)\nNo signal (multiplex). This assay was dropped due to difficulty in finding a working antibody pair and recombinant antigen standard.\n\n\nsTNF-R1\nMAB625 (clone 16805)\n636-R1\nBAF225\nPoor sensitivity\n\n\n\nMAB6251 (clone 925224)\n636-R1\nBAF225\nNo signal\n\n\n\nMAB225 (clone 16803)\n636-R1\nBAF225\nPass\n\n\nsTREM-1\nAF1278\n1278-TR\nBAF1278\nHigh background\n\n\n\nMAB1278 (clone 193015)\n1278-TR\nBAF1278\nPoor sensitivity and cross-reaction with MxA antigen\n\n\n\nH00054210-M01 (clone 2E2)\n1278-TR\nBAF1278\nPass\n\n\nTRAIL\nMAB3751 (clone 124723)\n375-TL\nBAF375\nPoor sensitivity\n\n\n\nMAB375 (clone 75411)\n375-TL\nBAF375\nPass\n\n\n\n*These detection antibodies were biotinylated using a Lightning Link kit.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Antibody pair screening</span>"
    ]
  },
  {
    "objectID": "Cross_Reactivity.html",
    "href": "Cross_Reactivity.html",
    "title": "12  Cross-reactivity Testing",
    "section": "",
    "text": "12.1 Intro\nCross-reactivity would occur if an analyte triggered a measurable response in an assay other than that which was intended, for instance if an assay based on detection antibodies intended to be specific for MxA were reactive to purified sTNFR1 antigen. Cross-reactive antibody pairs cannot be trusted to provide specific and accurate estimates of analyte concentration.\nTo establish whether any assays were cross-reactive, we tested each assay against a standard curve of purified antigens for both its target analyte (which should be reactive) and all other analytes. Note that this approach cannot rule out assay cross-reactivity to analytes in the blood (or other sample) that were not directly tested here.\nThe illustrative data presented here include 13 antigens; those on the final 12-plex list of markers, plus C-Reactive Protein (CRP), which was part of our initial screening process.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Cross-reactivity Testing</span>"
    ]
  },
  {
    "objectID": "Cross_Reactivity.html#protocol",
    "href": "Cross_Reactivity.html#protocol",
    "title": "12  Cross-reactivity Testing",
    "section": "12.2 Protocol",
    "text": "12.2 Protocol\nThe protocol is initiated by making 12X stocks of the pure recombinant protein standards (12X because it is a 12-plex). Equal volumes of the 12X analytes were then mixed to achieve a multi-analyte pool in which each of the 12 analytes was at 1X concentrations. Separately, each 12X antigen is also diluted 1 in 12 to achieve a 1X concentration standard curve of that antigen alone. This is so that each standard curve, either multi- or single-plex, originates from the same dilutions series, thus minimising variability.\nThe cross-reactivity assessment can be conducted for any level of multiplex (N-plex) by generating initial protein standards at N times the 1X concentrations. This cross-reactivity assessment should be repeated if any changes are made to the antibodies or antigens in the assay i.e. if an additional assay were to be added to the multiplex, or a specific antibody or recombinant antigen replaced with another.\n\n12.2.1 Preparation needed prior to running the Cross-Reactivity protocol\n\nPrepare buffers for general assay procedures as per the Buffers and Reagents protocol.\nPrepare recombinant protein antigen stock aliquots as per the Antigens protocol.\nPrepare coupled beads as per the bead coupling protocol and coupling confirmation protocols.\nPrepare biotin detection antibodies as per the Detection_Antibody_Prep protocol.\nEnsure that your MagPix is ready for use.\n\n\n\n12.2.2 Prepare analytes\n⌚ Timing: 1-2 hours set-up, 2 hr + 1 hr + 45 min incubations. Total approx. 6h.\nAll incubations are at ambient temperature.\nTip: Handle recombinant proteins on ice at all times to minimise degradation.\nNOTE: All 12 antibody-coupled beads and all 12 biotin-conjugated detection antibodies are present in all assays. Only the antigens differ between wells.\n\nGet coupled beads from fridge, bring to ambient temperature, vortex and sonicate for 30 sec of each.\nPut aliquots of the recombinant protein stocks on ice to thaw.\nIn a protein lo-bind 96-well plate, or tubes laid out in this format, prepare 4-fold analyte dilutions of each antigen separately (i.e. one column per antigen) in PBS-TBN at 12X the final required concentration. Label the plate to know which order the antigens are in. Some analytes may need an initial pre-dilution in a separate tube.\ne.g. make 100 µL of dilution 1 in row 1, then serially transfer 25 µL into subsequent wells with 75 µL of PBS-TBN, pipetting up and down to mix well between transfers. The standard_dilutions_calculator Excel document (Standard_dilutions_calculator.xlsx) can also be adjusted for the number of analytes in the multiplex and for the final volume needed.\nIn a second lo-bind plate, for the multiplex standards (‘12-plex’), combine equal volumes (e.g. 10 µL) of each of the 12X analyte stocks. i.e. 10 ul of each standard 1 will be transferred into well A1 to make 120 µL total, 10 ul of each standard 2 into well A2, etc. Again mixing well by pipetting up and down carefully several times. If a plate well capacity is not going to be enough, microtubes can be used instead.\nInto subsequent columns of the second lo-bind plate, perform a 1 in N-plex dilution, in this case, add 110 µL of PBS-TBN and transfer 10 µL of each 12X standard to achieve 1X standards of each antigen, pipetting up and down to mix well.\n12.2.3 Prepare beads\n\nPrepare beads for all wells, plus 10% volume surplus. The aim is to get 20,000 beads/mL [ie 1000 beads/well] based on stock of 7.5x106 beads/mL:\nAdd 11.074 ml of PBS-TBN to a Universal (20 mL capacity tube) i.e. 11,440 µL final wanted volume - (30.5 µL of 12 bead regions = 366 µL total bead volume) = 11,074 µL. Total final volume after addition of beads, will be 11.44 mL which allows the 10% surplus volume.\nVortex bead stocks again as you add 30.5 µL of each bead to the tube.\nLabel black plates (“assay plates”) with date, plate number, etc.\nAdd 50 µL of the mixed, diluted, beads to all 96 wells of 2 plates, plus columns 01 and 02 of a third plate.\nWash beads once: put plates on magnet for 60 s, discard liquid, remove from magnet and add 100 µL PBST, replace on magnet for 60 s, discard liquid, dab gently on tissue to remove excess liquid. Cover plates until addition of antigens to prevent drying.\nTransfer the multiplex and single-plex standards to the assay plates into duplicate wells of 30 µL each, as per the plate layouts below.\nCover and incubate the plates on a shaker at ~200 rpm for 2 hours.\n\n\nTables. Plate layouts for cross-reactivity assessment assay. Each well contains all capture antibodies (beads) and all detection antibodies, but either all antigens (12-plex) or each antigen alone (where named).\n\n\n\n\n\n\n\n\n\n\n\n\nPlate 1\n12-plex\nCHI3L1\nIL-8\nsTNFR1\nIL-6\nAng-2\n\n\n\n\nColumns\n01-02\n03-04\n05-06\n07-08\n09-10\n11-12\n\n\nRow A\nStandard 1\nStandard 1\nStandard 1\nStandard 1\nStandard 1\nStandard 1\n\n\nRow B\nStandard 2\nStandard 2\nStandard 2\nStandard 2\nStandard 2\nStandard 2\n\n\nRow C\nStandard 3\nStandard 3\nStandard 3\nStandard 3\nStandard 3\nStandard 3\n\n\nRow D\nStandard 4\nStandard 4\nStandard 4\nStandard 4\nStandard 4\nStandard 4\n\n\nRow E\nStandard 5\nStandard 5\nStandard 5\nStandard 5\nStandard 5\nStandard 5\n\n\nRow F\nStandard 6\nStandard 6\nStandard 6\nStandard 6\nStandard 6\nStandard 6\n\n\nRow G\nStandard 7\nStandard 7\nStandard 7\nStandard 7\nStandard 7\nStandard 7\n\n\nRow H\nBlank\nBlank\nBlank\nBlank\nBlank\nBlank\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlate 2\nAng-1\nAzu\nMxA\nTRAIL\nIL-10\nIP-10\n\n\n\n\nColumns\n01-02\n03-04\n05-06\n07-08\n09-10\n11-12\n\n\nRow A\nStandard 1\nStandard 1\nStandard 1\nStandard 1\nStandard 1\nStandard 1\n\n\nRow B\nStandard 2\nStandard 2\nStandard 2\nStandard 2\nStandard 2\nStandard 2\n\n\nRow C\nStandard 3\nStandard 3\nStandard 3\nStandard 3\nStandard 3\nStandard 3\n\n\nRow D\nStandard 4\nStandard 4\nStandard 4\nStandard 4\nStandard 4\nStandard 4\n\n\nRow E\nStandard 5\nStandard 5\nStandard 5\nStandard 5\nStandard 5\nStandard 5\n\n\nRow F\nStandard 6\nStandard 6\nStandard 6\nStandard 6\nStandard 6\nStandard 6\n\n\nRow G\nStandard 7\nStandard 7\nStandard 7\nStandard 7\nStandard 7\nStandard 7\n\n\nRow H\nBlank\nBlank\nBlank\nBlank\nBlank\nBlank\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlate 3\nsTREM1\nEmpty\nEmpty\nEmpty\nEmpty\nEmpty\n\n\n\n\nColumns\n01-02\n03-04\n05-06\n07-08\n09-10\n11-12\n\n\nRow A\nStandard 1\n\n\n\n\n\n\n\nRow B\nStandard 2\n\n\n\n\n\n\n\nRow C\nStandard 3\n\n\n\n\n\n\n\nRow D\nStandard 4\n\n\n\n\n\n\n\nRow E\nStandard 5\n\n\n\n\n\n\n\nRow F\nStandard 6\n\n\n\n\n\n\n\nRow G\nStandard 7\n\n\n\n\n\n\n\nRow H\nBlank\n\n\n\n\n\n\n\n\n12. During the incubation, prepare biotin detection antibodies for 3 plates. The excess can be stored frozen for future use.\n\nWash the plates 3 times with PBST as before.\nAdd 30 µL per well of the detection antibody mix to all used wells.\nCover and incubate, shaking, for 1 hour.\nDuring incubation, prepare SA-PE at 3 µg/mL by adding 20.7 µL of SA-PE stock (1 mg/mL) into 6.9 mL PBS-TBN.\nWash plates 3 times with PBST as before.\nAdd 30 µL per well of the diluted SA-PE to all used wells.\nCover and incubate, shaking, for 45 minutes.\nWash plates 3 times with PBST as before.\nAdd 100 µL PBS-TBN to each well, cover and refrigerate overnight.\nRead plates on MagPix first thing the next day.\n\nExample data analysis using real data are given below.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Cross-reactivity Testing</span>"
    ]
  },
  {
    "objectID": "Cross_Reactivity.html#results-analysis",
    "href": "Cross_Reactivity.html#results-analysis",
    "title": "12  Cross-reactivity Testing",
    "section": "12.3 Results & Analysis",
    "text": "12.3 Results & Analysis\nThe raw data are in long format in the file data/crossreactivity_data/crossreactivity_data_long.csv\nEach line represents a well of the Luminex plate in which there was…\n\nAn analyte at one of 8 concentrations\nDetection antibodies for one of the 13 individual assays (as there were 13 at the time of performing this cross-reactivity assessment).\n\n\n12.3.1 Load libraries\n\n\n12.3.2 Read in the data from the cross-reactivity experiments.\n\n\n\n\n\nLocation\nanalyte\nmfi\nplate\nassay\nwell\nrow\nrep\nstandard\n\n\n\n\n1(1,A1)\nAng.1\n6665.5\n1\n13plex\n1\nA\n1\n1\n\n\n2(1,B1)\nAng.1\n2104.0\n1\n13plex\n2\nB\n1\n2\n\n\n3(1,C1)\nAng.1\n489.5\n1\n13plex\n3\nC\n1\n3\n\n\n4(1,D1)\nAng.1\n168.0\n1\n13plex\n4\nD\n1\n4\n\n\n5(1,E1)\nAng.1\n83.0\n1\n13plex\n5\nE\n1\n5\n\n\n6(1,F1)\nAng.1\n78.5\n1\n13plex\n6\nF\n1\n6\n\n\n7(1,G1)\nAng.1\n75.0\n1\n13plex\n7\nG\n1\n7\n\n\n8(1,H1)\nAng.1\n71.5\n1\n13plex\n8\nH\n1\n8\n\n\n9(1,A2)\nAng.1\n7102.0\n1\n13plex\n9\nA\n2\n1\n\n\n10(1,B2)\nAng.1\n2283.0\n1\n13plex\n10\nB\n2\n2\n\n\n\n\n\n\n\n12.3.3 Create counterfactuals and bind to data\nThe counterfactuals are used in the charts below to show the response curves when the assay is tested against its own analyte. These are shown as grey bars in the charts.\n\ncounterfactuals = filter(mfi_allplates,assay==analyte) %&gt;% \n  select(\n    assay,\n    standard,\n    rep,\n    mfi\n  ) %&gt;% \n  rename(mfi.cf = mfi)\n\nmfi_allplates &lt;- left_join(mfi_allplates,counterfactuals)\n\n\n\n12.3.4 Show results for individual analytes against all assays\nEach experiment was repeated and charts below show the results of experiments 1 & 2.\nDefine a function to plot each analyte.\n\nassay.plot&lt;-function(showanalyte){\nggplot(filter(mfi_allplates,analyte==showanalyte,assay!=\"13plex\"))+\n  geom_bar(stat = \"identity\",aes(standard,mfi.cf),fill=\"grey\",alpha=0.5)+\n  geom_bar(stat = \"identity\",aes(standard,mfi),fill=\"black\")+\n  \n  facet_grid(analyte~assay) +\n  xlab(\"Assay & Standard being tested\") +\n  ylab(\"Analyte Response (MFI)\")\n}\n\n\n12.3.4.1 Ang-1\n\nassay.plot(showanalyte = \"Ang.1\")\n\n\n\n\n\n\n\n\n\n\n12.3.4.2 Ang-2\n\nassay.plot(showanalyte = \"Ang.2\")\n\n\n\n\n\n\n\n\n\n\n12.3.4.3 Azu\n\nassay.plot(showanalyte = \"Azu\")\n\n\n\n\n\n\n\n\n\n\n12.3.4.4 CHI3L1\n\nassay.plot(showanalyte = \"CHI3L1\")\n\n\n\n\n\n\n\n\n\n\n12.3.4.5 CRP\n\nassay.plot(showanalyte = \"CRP\")\n\n\n\n\n\n\n\n\n\n\n12.3.4.6 IL-10\n\nassay.plot(showanalyte = \"IL.10\")\n\n\n\n\n\n\n\n\n\n\n12.3.4.7 IL-6\n\nassay.plot(showanalyte = \"IL.6\")\n\n\n\n\n\n\n\n\n\n\n12.3.4.8 IL-8\n\nassay.plot(showanalyte = \"IL.8\")\n\n\n\n\n\n\n\n\n\n\n12.3.4.9 IP-10\n\nassay.plot(showanalyte = \"IP.10\")\n\n\n\n\n\n\n\n\n\n\n12.3.4.10 MxA\n\nassay.plot(showanalyte = \"MxA\")\n\n\n\n\n\n\n\n\n\n\n12.3.4.11 sTNF-R1\n\nassay.plot(showanalyte = \"sTNFR.1\")\n\n\n\n\n\n\n\n\n\n\n12.3.4.12 sTREM-1\n\nassay.plot(showanalyte = \"sTREM.1\")\n\n\n\n\n\n\n\n\n\n\n12.3.4.13 TRAIL\n\nassay.plot(showanalyte = \"TRAIL\")\n\n\n\n\n\n\n\n\n\n\n12.3.4.14 Show 13-plex results\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(readr)\n\n# Load the data\nmfi_allplates = read_csv(\"data/crossreactivity_data/crossreactivity_data_long.csv\", show_col_types = FALSE)\n\n# Create the plot with rotated facet labels and reduced y-axis ticks\nmyplot &lt;- ggplot(filter(mfi_allplates, assay != \"13plex\")) +\n  geom_bar(stat = \"identity\", aes(standard, mfi), fill = \"black\") +\n  facet_grid(analyte ~ assay,scales = \"free_y\") +\n  xlab(\"Assay & Standard being tested\") +\n  ylab(\"Analyte Response (MFI)\") +\n  theme(\n    strip.text.x = element_text(angle = 90, hjust = 0),\n    strip.text.y = element_text(angle = 0)\n  )\n\nmyplot",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Cross-reactivity Testing</span>"
    ]
  },
  {
    "objectID": "Standards_Prep.html",
    "href": "Standards_Prep.html",
    "title": "13  Standard curves",
    "section": "",
    "text": "13.1 Overview\nThis protocol will support you to create a set of standard curves against which experimental fluorescence measurements from clinical specimens will be calibrated, normalised, and converted in to analyte concentration estimates.\nThe standards are made as a multiplexed pool of the recombinant antigens for the various bead-conjugated sandwich assays (see bead coupling and antibody pairs) in the test. This pool is diluted seven times, and the dilution series, along with an antigen free ‘buffer blank’, are included on every plate that is run on the MagPix device. This allows the user to normalise fluorescence signal variation between plates, and to establish a dose-response curve for each antigen on each plate. The dose-response curve is later used to convert the fluorescence signals from the multiplexed testing of clinical specimens in to estimates of the concentration of each analyte (see Analysis).",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Standard curves</span>"
    ]
  },
  {
    "objectID": "Standards_Prep.html#recommendations",
    "href": "Standards_Prep.html#recommendations",
    "title": "13  Standard curves",
    "section": "13.2 Recommendations",
    "text": "13.2 Recommendations\n\nLabel all vials with with expiry date (as per data sheet, but rule of thumb 3 months)\nHandle all protein on ice or in chilled racks.\nAliquot standards into single-use volumes and store at -70°C.\nAliquot of protein stocks should be thawed on ice and marked for each freeze-thaw cycle, but ideally this should be minimised or avoided.\nMake substantial volumes of standards for homogeneity. Ideally you should synthesise enough standards for all of your test plates using a single batch of standards. If you have 100 plates to run, you will need 100 * 70 µL = 7 mL per standard. You should make at least 20% extra to account for liquid handling errors and the need to occasionally repeat runs.\nStandards degrade with time and are best used within 2-3 months. You should aim to process all of your plates in the shortest time-frame possible.\nTest new standards side-by-side with older formulations, to assess conformity and uniformity",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Standard curves</span>"
    ]
  },
  {
    "objectID": "Standards_Prep.html#protocol",
    "href": "Standards_Prep.html#protocol",
    "title": "13  Standard curves",
    "section": "13.3 Protocol",
    "text": "13.3 Protocol\n\nPrepare antigen stocks as per the Antigens protocol.\nPrepare PBS-TBN as per the Buffers and Reagents protocol.\nYou will aim to create a multiplexed top-standard by mixing volumes of the recombinant antigen stocks together in PBS-TBN and then serially diluting, to make a series of 7, 4-fold, multiplex dilutions. A blank (Standard 8) consists only of PBS-TBN buffer.\nThese are then aliquotted as 7 separate standards into volumes for running different numbers of plates so that each aliquot is single-use.\nSee Standard_dilutions_calculator Excel document for the step-by-step printable protocol\n\nThe final concentrations of the recombinant protein in the standards are shown in Table 1.\nTable 1. Concentration of recombinant protein analytes in the 7 standards (ng/ml).\n\n\n\nAnalyte\n1\n2\n3\n4\n5\n6\n7\n\n\nAng-1\n50.0\n12.50\n3.13\n0.781\n0.195\n0.0488\n0.0122\n\n\nAng-2\n100.0\n25.00\n6.25\n1.563\n0.391\n0.0977\n0.0244\n\n\nAzu\n200.0\n50.00\n12.50\n3.125\n0.781\n0.1953\n0.0488\n\n\nCHI3L1\n100.0\n25.00\n6.25\n1.563\n0.391\n0.0977\n0.0244\n\n\nIL-6\n10.0\n2.50\n0.63\n0.156\n0.039\n0.0098\n0.0024\n\n\nIL-8\n2.5\n0.63\n0.16\n0.039\n0.010\n0.0024\n0.0006\n\n\nIL-10\n4.0\n1.00\n0.25\n0.063\n0.016\n0.0039\n0.0010\n\n\nIP-10\n10.0\n2.50\n0.63\n0.156\n0.039\n0.0098\n0.0024\n\n\nMxA\n300.0\n75.00\n18.75\n4.688\n1.172\n0.2930\n0.0732\n\n\nsTREM1\n10.0\n2.50\n0.63\n0.156\n0.039\n0.0098\n0.0024\n\n\nTNFR1\n2.5\n0.63\n0.16\n0.039\n0.010\n0.0024\n0.0006\n\n\nTRAIL\n10.0\n2.50\n0.63\n0.156\n0.039\n0.0098\n0.0024",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Standard curves</span>"
    ]
  },
  {
    "objectID": "Magpix_Protocol.html",
    "href": "Magpix_Protocol.html",
    "title": "14  MagPix Protocol",
    "section": "",
    "text": "14.1 Overview\nThis protocol will support you to set up a run on the xPONENT software, as was performed for this study. This protocol is used to test specimens with the final 12-plex assay on the MagPix machine, as well as to carry out the confirmations of bead conjugation and the cross-reactivity tests,\nPlease note that this protocol does not detail basic operations, routine maintenance and calibration of the MagPix. Please refer to the manufacturer’s guidance on this.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>MagPix Protocol</span>"
    ]
  },
  {
    "objectID": "Magpix_Protocol.html#setup",
    "href": "Magpix_Protocol.html#setup",
    "title": "14  MagPix Protocol",
    "section": "14.2 Setup",
    "text": "14.2 Setup\n\nIn the xPONENT software, go to ‘Protocols’ &gt; ‘Create new Protocol’.\nEnter a name for the protocol e.g. “12-plex Biomarker” and select the appropriate plate type from the drop-down menu.\nSet the sample volume to 50 µL. Click ‘Next’.\nSelect and label the required bead regions with their coupled antibodies so that the table on screen maps to the table below:\n\n\n\n\nName\nAnalysis\nUnits\nCount\nRegion\n\n\n\n\nsTREM1\nNo Analysis\n\n50\n14\n\n\nAng2\nNo Analysis\n\n50\n15\n\n\nAng1\nNo Analysis\n\n50\n18\n\n\nsTNFR1\nNo Analysis\n\n50\n20\n\n\nIL6\nNo Analysis\n\n50\n21\n\n\nIL8\nNo Analysis\n\n50\n22\n\n\nTRAIL\nNo Analysis\n\n50\n25\n\n\nIL10\nNo Analysis\n\n50\n26\n\n\nAzu\nNo Analysis\n\n50\n27\n\n\nMxA\nNo Analysis\n\n50\n28\n\n\nIP10\nNo Analysis\n\n50\n29\n\n\nCHI3L1\nNo Analysis\n\n50\n30\n\n\n\n\nClick ‘Next’",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>MagPix Protocol</span>"
    ]
  },
  {
    "objectID": "Magpix_Protocol.html#plate-layout",
    "href": "Magpix_Protocol.html#plate-layout",
    "title": "14  MagPix Protocol",
    "section": "14.3 Plate Layout",
    "text": "14.3 Plate Layout\n\nHighlight all wells and select ‘Unknown’ so that the whole plate is yellow.\nEnsure that ‘Direction’ is the left-hand option for vertical reading order.\nAdd a ‘Post-Batch Routine’ under ‘Commands and Routines’.\nClick ‘Save’.\n\nThe protocol is ready to use and can now be found under ‘Protocols’.\nWe have used this uniform plate layout for all plates, but it is also possible to add standards with their concentrations, and blanks, to the layout if this is desirable.\nWe recommend uploading or adding sample (or well) IDs to each plate (‘batch’) before running a plate so that raw data contains sample IDs.\nNOTE - Adding standards to the plate layout may cause the output csv file to have additional rows and produce errors if used with our R analysis script. The analysis script should be modified in the relevant places to accommodate this change if you wish to add standards.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>MagPix Protocol</span>"
    ]
  },
  {
    "objectID": "Coefficients_of_Variation.html",
    "href": "Coefficients_of_Variation.html",
    "title": "15  Coefficients of Variation",
    "section": "",
    "text": "15.1 Overview\nThis protocol can be used to calculate the inter- and intra-assay variation. It can be performed repeatedly on different days or by different operators to provide a measure of variation.\nThis protocol measures how consistent an assay’s results are:\nBy performing the assay repeatedly under these conditions, you can quantify both types of variation, usually as a coefficient of variation (CV%) to confirm reliability. CV measures percentage variation in the estimate of the analyte concentration compared to the mean of all results.\n\\[\n\\mathrm{CV\\%} = \\frac{\\sigma}{\\mu} \\times 100\\quad\\text{where}\\quad\\sigma = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\mu)^2}{n - 1}}, \\;\\mu = \\frac{\\sum_{i=1}^n x_i}{n}\n\\]\nThe protocol was run here using anonymous DBS samples and recombinant protein standards.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Coefficients of Variation</span>"
    ]
  },
  {
    "objectID": "Coefficients_of_Variation.html#overview",
    "href": "Coefficients_of_Variation.html#overview",
    "title": "15  Coefficients of Variation",
    "section": "",
    "text": "Intra-assay variation is variation within the same run\n\n(e.g., running the same samples multiple times in one experiment).\nThis tells you the precision of the assay in a single test session.\n\nInter-assay variation is variation between different runs\n\n(e.g., same samples tested on different days or by different people).\nThis tells you the reproducibility across time and operators.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Coefficients of Variation</span>"
    ]
  },
  {
    "objectID": "Coefficients_of_Variation.html#reagents-consumables-equipment",
    "href": "Coefficients_of_Variation.html#reagents-consumables-equipment",
    "title": "15  Coefficients of Variation",
    "section": "15.2 Reagents, consumables & equipment",
    "text": "15.2 Reagents, consumables & equipment\n\nGeneral Assay Buffers as per buffers & reagents section.\nCapture and detection antibodies and recombinant protein standards as per the respective protocols.\nCoupled and confirmed beads as per the respective protocols.\n\nTable 1. Lab worksheet to record batch dates and reagents. Supplier is bio-techne unless specified.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAntibody on bead\nBead Ab conc (µg/millionbeads)\nBead region\nDate beads coupled\nAntigen\nDetection Ab\nDetection Ab (µg/mL)\n\n\nCRP\nMAB17071\n5\n12\nn/a\n1707-CR\nBAM17072\n1\n\n\nIL8\nM801 (Thermo)\n5\n22\n\n208-IL\nBAF208\n1.5\n\n\nsTNF-R1\nMAB225\n6\n20\n\n636-R1\nBAF225\n1.5\n\n\nIL6\nMAB206\n5\n21\n\n206-IL\nBAF206\n1\n\n\nAng2\nNB110-85467\n5\n15\n\n623-AN\nBAF623\n1\n\n\nAng1\nMAB9231\n5\n18\n\n923-AN\nBAF923\n1.5\n\n\nTRAIL\nMAB375\n6\n25\n\n375-TL\nBAF375\n1\n\n\nIL10\nMAB2172\n4\n26\n\n1064-IL\nBAF217\n1.5\n\n\nsTREM1\nH00054210-M04\n6\n14\n\n1278-TR\nBAF1278\n2\n\n\nIP-10\nMAB266\n5\n29\n\n266-IP\nBAF266\n1\n\n\nAzu\nNBP2-12045\n7\n27\n\n2200-SE\nAF2200+B\n1.5\n\n\nMxA\nMA5-24914 (Thermo)\n6\n28\n\nTP307418 (OriGene)\nAF7946+B\n1\n\n\nCHI3L1\nMAB25991\n4.5\n30\n\n2599-CH\nBAF2599\n1\n\n\n\n\n15.2.1 Samples\n\nDBS samples 1-4 from 4 different individuals\n\nDBS1, DBS2, DBS3, DBS4\n\nSpiked DBS made with healthy human blood spiked with the recombinant protein antigens at high, medium, low and zero levels\n\nHigh DBS, Med DBS, Low DBS, Blank DBS\n\nspiked analyte activity identical to standards 1, 3, 6 and 8, respectively.\n\n\nRecombinant protein standards 1-8 in PBS-TBN\n\nStd1, Std2, Std3, Std4, Std5, Std6, Std7, Std8\n\n\n\n\n15.2.2 Experimental Design : Intra-assay CV\n\nTwelve within-plate repeats of pooled DBS eluate (DBS1-DBS4) were run on plate 1\nTwelve within-plate repeats of the spiked DBS (High DBS, Med DBS etc) were run on plate 1\nTwelve within-plate repeats of the protein standards (Std1-Std8) were run on plate 2\nN.B. This protocol was carried out when the CRP assay was still part of the multiplex. It has since been removed.\n15.2.2.1 Plate 1 Layout (Intra-assay)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\nA\nDBS1\nDBS1\nDBS1\nDBS1\nDBS1\nDBS1\nDBS1\nDBS1\nDBS1\nDBS1\nDBS1\nDBS1\n\n\nB\nDBS2\nDBS2\nDBS2\nDBS2\nDBS2\nDBS2\nDBS2\nDBS2\nDBS2\nDBS2\nDBS2\nDBS2\n\n\nC\nDBS3\nDBS3\nDBS3\nDBS3\nDBS3\nDBS3\nDBS3\nDBS3\nDBS3\nDBS3\nDBS3\nDBS3\n\n\nD\nDBS4\nDBS4\nDBS4\nDBS4\nDBS4\nDBS4\nDBS4\nDBS4\nDBS4\nDBS4\nDBS4\nDBS4\n\n\nE\nHigh DBS\nHigh DBS\nHigh DBS\nHigh DBS\nHigh DBS\nHigh DBS\nHigh DBS\nHigh DBS\nHigh DBS\nHigh DBS\nHigh DBS\nHigh DBS\n\n\nF\nMed DBS\nMed DBS\nMed DBS\nMed DBS\nMed DBS\nMed DBS\nMed DBS\nMed DBS\nMed DBS\nMed DBS\nMed DBS\nMed DBS\n\n\nG\nLow DBS\nLow DBS\nLow DBS\nLow DBS\nLow DBS\nLow DBS\nLow DBS\nLow DBS\nLow DBS\nLow DBS\nLow DBS\nLow DBS\n\n\nH\nBlank DBS\nBlank DBS\nBlank DBS\nBlank DBS\nBlank DBS\nBlank DBS\nBlank DBS\nBlank DBS\nBlank DBS\nBlank DBS\nBlank DBS\nBlank DBS\n\n\n\n\n15.2.2.2 Plate 2 Layout (Intra-assay)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\nA\nStd1\nStd1\nStd1\nStd1\nStd1\nStd1\nStd1\nStd1\nStd1\nStd1\nStd1\nStd1\n\n\nB\nStd2\nStd2\nStd2\nStd2\nStd2\nStd2\nStd2\nStd2\nStd2\nStd2\nStd2\nStd2\n\n\nC\nStd3\nStd3\nStd3\nStd3\nStd3\nStd3\nStd3\nStd3\nStd3\nStd3\nStd3\nStd3\n\n\nD\nStd4\nStd4\nStd4\nStd4\nStd4\nStd4\nStd4\nStd4\nStd4\nStd4\nStd4\nStd4\n\n\nE\nStd5\nStd5\nStd5\nStd5\nStd5\nStd5\nStd5\nStd5\nStd5\nStd5\nStd5\nStd5\n\n\nF\nStd6\nStd6\nStd6\nStd6\nStd6\nStd6\nStd6\nStd6\nStd6\nStd6\nStd6\nStd6\n\n\nG\nStd7\nStd7\nStd7\nStd7\nStd7\nStd7\nStd7\nStd7\nStd7\nStd7\nStd7\nStd7\n\n\nH\nStd8\nStd8\nStd8\nStd8\nStd8\nStd8\nStd8\nStd8\nStd8\nStd8\nStd8\nStd8",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Coefficients of Variation</span>"
    ]
  },
  {
    "objectID": "Coefficients_of_Variation.html#experimental-design-inter-assay-cv",
    "href": "Coefficients_of_Variation.html#experimental-design-inter-assay-cv",
    "title": "15  Coefficients of Variation",
    "section": "15.3 Experimental Design : Inter-assay CV",
    "text": "15.3 Experimental Design : Inter-assay CV\n\nOn each of six plates, single replicates of all specimens (Pooled DBS, Spiked DBS, Standards)\n\n\n15.3.0.1 Plate 3-8 Layout (Interassay)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\nA\nDBS1\nStd1\n\n\n\n\n\n\n\n\n\n\n\n\nB\nDBS2\nStd2\n\n\n\n\n\n\n\n\n\n\n\n\nC\nDBS3\nStd3\n\n\n\n\n\n\n\n\n\n\n\n\nD\nDBS4\nStd4\n\n\n\n\n\n\n\n\n\n\n\n\nE\nHigh DBS\nStd5\n\n\n\n\n\n\n\n\n\n\n\n\nF\nMed DBS\nStd6\n\n\n\n\n\n\n\n\n\n\n\n\nG\nLow DBS\nStd7\n\n\n\n\n\n\n\n\n\n\n\n\nH\nBlank DBS\nStd8",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Coefficients of Variation</span>"
    ]
  },
  {
    "objectID": "Coefficients_of_Variation.html#protocol",
    "href": "Coefficients_of_Variation.html#protocol",
    "title": "15  Coefficients of Variation",
    "section": "15.4 Protocol",
    "text": "15.4 Protocol\n⌚ Timing: 1-2 hours to prepare prior to assay day, about 6-7 hours on assay day, including incubations.\n\nEluting DBS samples: The day before assay day, prepare elution buffer with 1 mL of 25X protease inhibitor plus 24 mL PBS-TBN. In 8 x 5 mL tubes, add 20 DBS to each tube of the individual donor and spiked DBS. Add 1 mL elution buffer to each tube and incubate overnight at 4C.\n\n\n\nOn assay day, get coupled beads from fridge, vortex and sonicate for 30 sec of each.\nDilute beads: add 14.183 mL of PBS-TBN to a universal. Total final volume after addition of beads, will be 14.7 mL. (14.7 mL minus 517.4 µL) (288 wells, 3 plates’ worth x 50 ul = 14.4 mL)\nVortex bead stocks again immediately before pipetting and add ____ µL of each bead to the tube (to get 20k beads/mL [ie 1000 beads/well] based on stock of ____x106 beads/mL). Tick as you add the beads:\n\n\n\n\n\n\n\n\n\nAng1\nAng2\nAzu\nIL-6\nIL-8\nIL-10\nIP-10\nCHI3L1\nMxA\nsTREM1\nsTNFR1\nTRAIL\n\n\n\nLabel 8 black plates with plate number, date, etc.\nAdd 50 µL of diluted beads to all required wells, as per plate layouts:\nWash the beads once: put plate on magnet, wait 60 sec, flick out liquid, remove from magnet, add 100 µL PBST to each well, back on magnet 60 sec, flick out liquid, bang gently on tissue.\nVortex the eluted DBS samples.\nThaw, vortex & pool the buffer standards. Mix again before dispensing.\nAdd 30 µL/well of standards and RBC-DBS eluate to respective wells.\nAdd 30 µL/well of PBS-TBN+pi as standard 8.\nCover and incubate on gentle shaker for 120 mins. Record start time:______________\nDuring the incubation, prepare biotin detection antibodies for 3 plates. The excess can be stored frozen for future use.\nWash the plates 3 times with PBST as before.\nAdd 30 µL per well of the detection antibody mix to all used wells.\nCover and incubate, shaking, for 1 hour.\nDuring incubation, prepare SA-PE at 3 µg/mL by adding ___TBC___ µL of SA-PE stock (1 mg/mL) into ___ TBC__mL PBS-TBN.\nWash plates 3 times with PBST as before.\nAdd 30 µL per well of the diluted SA-PE to all used wells.\nCover and incubate, shaking, for 45 minutes.\nWash plates 3 times with PBST as before.\nAdd 100 µL PBS-TBN to each well, cover and refrigerate overnight.\nRead plates on MagPix first thing the next day.\nExample data analysis using real data is given below.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Coefficients of Variation</span>"
    ]
  },
  {
    "objectID": "Coefficients_of_Variation.html#analysis-interpretation-of-results",
    "href": "Coefficients_of_Variation.html#analysis-interpretation-of-results",
    "title": "15  Coefficients of Variation",
    "section": "15.5 Analysis & interpretation of results",
    "text": "15.5 Analysis & interpretation of results\n\n15.5.1 Libraries\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(reshape2)\nlibrary(flextable)\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n\n\n15.5.2 Intra-assay CV Estimation\n\n# Helper function to calculate CV table for a given data frame\ncalc_cv &lt;- function(data, keep = NULL) {\n  if (!is.null(keep)) data &lt;- data[keep, ]\n  \n  data %&gt;%\n    group_by(Sample, Assay) %&gt;%\n    summarise(\n      n = n(),\n      mean = mean(MFI, na.rm = TRUE),\n      sd = sd(MFI, na.rm = TRUE),\n      CV = 100 * (sd / mean),\n      .groups = \"drop\"\n    ) %&gt;%\n    group_by(Assay) %&gt;%\n    summarise(CV = mean(CV, na.rm = TRUE), .groups = \"drop\")\n}\n\n# Read and reshape a plate CSV\nread_plate &lt;- function(file, assay_cols) {\n  read_csv(file, skip = 41, show_col_types = FALSE,name_repair = \"universal\") %&gt;%\n    slice(1:96) %&gt;%\n    mutate(across(3:16, as.numeric)) %&gt;%\n    pivot_longer(\n      cols = {{ assay_cols }},\n      names_to = \"Assay\",\n      values_to = \"MFI\"\n    )\n}\n\n# Process plates\np1 &lt;- read_plate(\"data/cv/INTRAASSAY_CV_plate_01.csv\", CRP:CH3L1)\np2 &lt;- read_plate(\"data/cv/INTRAASSAY_CV_plate_02.csv\", Ang.1:TRAIL)\n\n# Calculate CVs\n# Works without NSE issues:\npooled_dbs_results &lt;- calc_cv(p1, str_starts(p1$Sample, \"DBS\")) %&gt;% rename(\"Intra_CV_Pooled_DBS\"=CV )\nspiked_dbs_results &lt;- calc_cv(p1, !str_starts(p1$Sample, \"DBS\")) %&gt;% rename(\"Intra_CV_Spiked_DBS\"=CV )\nrecombinant_results &lt;- calc_cv(p2)  %&gt;% rename(\"Intra_CV_Standards\"=CV ) # no filter\n\n# Combine into one table\nCV_table_intra_assay &lt;- pooled_dbs_results %&gt;%\n  left_join(spiked_dbs_results, by = \"Assay\") %&gt;%\n  left_join(recombinant_results, by = \"Assay\")\n\n# Display\nkable(CV_table_intra_assay,digits = 2)\n\n\n\n\nAssay\nIntra_CV_Pooled_DBS\nIntra_CV_Spiked_DBS\nIntra_CV_Standards\n\n\n\n\nAng.1\n6.82\n5.48\n12.59\n\n\nAng.2\n5.53\n6.32\n9.38\n\n\nAzu\n3.75\n4.31\n7.50\n\n\nCH3L1\n5.41\n2.62\n4.21\n\n\nCRP\n4.72\n1.75\n8.96\n\n\nIL.10\n5.84\n4.60\n8.06\n\n\nIL.6\n4.28\n6.33\n6.41\n\n\nIL.8\n5.55\n8.32\n7.89\n\n\nIP.10\n6.38\n6.80\n7.56\n\n\nMxA\n4.50\n5.18\n5.84\n\n\nTRAIL\n5.87\n5.87\n11.20\n\n\nsTNF.R1\n3.36\n5.26\n12.38\n\n\nsTREM1\n6.94\n6.26\n25.28\n\n\n\n\n\n\n\n15.5.3 interpretation\n1. All CVs are comfortably low\n\nGenerally, intra-assay CVs under 10% are considered very good for immunoassays, and under 15% is acceptable for most biomarker work.\nThe pooled DBS and spiked DBS samples are all well under 10%, which suggests that the assay reproducibility is strong.\nThe recombinant standards are a little higher for a few assays (12–25%), but still mostly within acceptable bounds except for sTREM1.\n\n2. sTREM1 might be the one to watch\n\n25% CV in recombinant standards is high.\nThis might be due to:\n\nLow signal strength near the detection limit.\nPipetting or bead-count variability.\nPoor stability in recombinant form.\n\nWorth checking raw MFI values to see if it’s just noise from low readings.\nAlso worth remembering this when looking at clinical data.\n\n3. Recombinant standards tend to have higher CVs than DBS\n\nFor example, Ang.1 is 6.8% (pooled DBS) vs. 12.6% (standards).\nThis pattern might be due to:\n\nMatrix mismatch. The recombinant standards are in buffer rather than a complex matrix like DBS.\nBead performance differences when analytes are spiked into clean buffer.\n\nThis isn’t unusual, but it’s worth noting if you ever compare results directly between recombinant standards and real samples.\n\n5. No obvious systematic matrix-specific instability\n\nThere’s no assay where the pooled DBS CV is high but standards are low, meaning that the DBS format doesn’t seem to be introducing extra noise.\nThat’s a good sign for assay robustness in the intended sample type.\n\n\n\n15.5.4 Inter-assay CV\n\n# Vector of plate numbers\nplates &lt;- sprintf(\"P%d\", 1:6)\n\n# Read and combine without ...17 column that R creates on read\ndf2 &lt;- map_dfr(plates, function(plate) {\n  file &lt;- sprintf(\"data/cv/INTERASSAY_CV_plate_%02d.csv\", as.integer(sub(\"P\", \"\", plate)))\n  \n  read_csv(file, skip = 41, show_col_types = FALSE) %&gt;%\n    slice(1:16) %&gt;%\n    select(-starts_with(\"...\")) %&gt;%  # drop those unnamed columns\n    mutate(plate = plate)\n})\n\n\n# Convert assay columns to numeric\ndf2_num &lt;- df2 %&gt;%\n  mutate(across(\n    c(`CRP`:`CH3L1`), # all your assay columns in order\n    as.numeric\n  ))\n\n# Pivot longer like p1/p2\ndf2 &lt;- df2_num %&gt;%\n  pivot_longer(\n    cols = CRP:CH3L1,  # all assay columns\n    names_to = \"Assay\",\n    values_to = \"MFI\"\n  )\n\n# 1. Pooled DBS\ninter_pooled_dbs &lt;- calc_cv(\n  df2, \n  str_starts(df2$Sample, \"DBS\")\n) %&gt;%\n  rename(inter_CV_pooled_DBS = CV)\n\n# 2. Spiked DBS (but not starting with \"DBS\")\ninter_spiked_dbs &lt;- calc_cv(\n  df2, \n  !str_starts(df2$Sample, \"DBS\")\n) %&gt;%\n  rename(inter_CV_spiked_DBS = CV)\n\n# 3. Recombinant standards\n#    If recombinant standards are in a separate pattern like \"Rec\" or \"Std\", filter accordingly\n#    Here, I'll assume they're *everything* in df2_long (same as your recombinant p2 case)\ninter_recombinant &lt;- calc_cv(\n  df2,str_starts(df2$Sample,\"Std\")\n) %&gt;%\n  rename(inter_CV_recombinant = CV)\n\n# ---- Join into one table ----\ninter_assay_table &lt;- inter_pooled_dbs %&gt;%\n  left_join(inter_spiked_dbs, by = \"Assay\") %&gt;%\n  left_join(inter_recombinant, by = \"Assay\")\n\nkable(inter_assay_table,digits = 2)\n\n\n\n\n\n\n\n\n\n\nAssay\ninter_CV_pooled_DBS\ninter_CV_spiked_DBS\ninter_CV_recombinant\n\n\n\n\nAng-1\n4.19\n5.92\n7.12\n\n\nAng-2\n5.42\n6.22\n6.41\n\n\nAzu\n3.29\n4.53\n5.46\n\n\nCH3L1\n2.82\n2.96\n3.45\n\n\nCRP\n2.42\n4.09\n4.82\n\n\nIL-10\n4.69\n5.41\n6.23\n\n\nIL-6\n5.26\n4.14\n3.90\n\n\nIL-8\n3.81\n7.16\n6.75\n\n\nIP-10\n3.97\n5.65\n5.66\n\n\nMxA\n4.62\n4.14\n3.89\n\n\nTRAIL\n3.70\n6.17\n7.04\n\n\nsTNF-R1\n2.89\n6.37\n7.27\n\n\nsTREM1\n3.47\n6.07\n6.52\n\n\n\n\n\n\n\n15.5.5 Interpretation\n1. All inter-assay CVs are comfortably low\n\nEverything is below ~8%, which is excellent for inter-assay reproducibility.\nIn biomarker assays, inter-assay CVs under 10% are considered very strong; you’re well under that threshold across the board.\n\n2. Pooled DBS vs. Spiked DBS vs. Recombinant\n\nPooled DBS CVs are consistently lowest for most analytes.\n\nSuggests that the pooled DBS specimens are very stable and reproducible across plates.\n\nSpiked DBS sometimes slightly higher\n\ne.g., IL-8 jumps to 7.16% from 3.81% in pooled DBS.\nThis could be due to pipetting variability or how spikes integrate into the DBS matrix.\n\nRecombinant CVs are generally a little higher than pooled DBS but not alarmingly so (e.g., CRP: 2.42% → 4.82%).\n\nThis is common because recombinant standards are often in a clean buffer and don’t always mimic real sample matrix behavior.\n\n\n3. No major outliers\n\nThe worst CV is IL-8 in spiked DBS (7.16%), but this is still well within the “good” range.\nNo single assay looks unstable across all sample types.\nSome analytes (e.g., MxA, IL-6) have slightly higher pooled DBS CVs than recombinants, but the differences are small (&lt;1–2%).",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Coefficients of Variation</span>"
    ]
  },
  {
    "objectID": "Coefficients_of_Variation.html#summary",
    "href": "Coefficients_of_Variation.html#summary",
    "title": "15  Coefficients of Variation",
    "section": "15.6 Summary",
    "text": "15.6 Summary\nThe intra- and inter-assay precision results indicate that the multiplex immunoassay is performing with strong reproducibility across sample types.\n\nReliable performance in DBS format – Both pooled and spiked DBS specimens showed consistently low intra- and inter-assay CVs, all well below the commonly accepted 10% threshold for high-quality immunoassays. This supports the use of DBS as a stable and reproducible matrix for these analytes.\nRecombinant standards less precise but acceptable – CVs for recombinant standards were generally higher than for DBS, particularly for a few analytes such as sTREM1. This is likely due to matrix differences (buffer vs. DBS), lower signal levels, or inherent instability of some recombinant proteins. While still mostly within acceptable limits, this should be considered when interpreting calibration and QC data.\nsTREM1 warrants monitoring – Elevated CV (~25%) in recombinant standards suggests potential instability or variability in this assay. This should be monitored in future runs, and raw signal data reviewed to confirm whether variability is due to low-level signal noise or other technical factors.\nNo evidence of matrix-specific instability – The lack of any assay showing high CVs in DBS but low CVs in standards suggests the DBS format itself is not introducing additional variability.\n\nOverall, these findings provide confidence in the robustness of the assay system for use with DBS samples, while highlighting the importance of monitoring recombinant standard performance, particularly for sTREM1.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Coefficients of Variation</span>"
    ]
  },
  {
    "objectID": "Specimen_Testing.html",
    "href": "Specimen_Testing.html",
    "title": "16  Specimen Testing",
    "section": "",
    "text": "17 Testing DBS samples with the biomarker assay\nReagents and materials needed\n\nAll materials on the Shopping List.\nVortex mixer, sonicating waterbath, shaking platform, microfuge, pipettes and reservoirs.\nPBS and PBS-TBN as per Buffers and Reagents protocol.\nCoupled beads as per Bead Coupling protocol.\nDetection antibodies as per Detection Antibody Prep.\n\n\n17.0.1 Lab worksheet protocol\nAssay date __________________________ done by _____________________________\nAim\nTo measure 12 immune markers in dried blood spot samples.\nImportant notes\nDBS rehydrated 2 x 6 mm spots in 100 ul PBS-TBN+pi overnight.\nAll samples, standards & detection antibodies are 30 ul per well volume.\nConduct your own Risk Assessment for the risks associated with your samples and handle accordingly.\nRecord date that standards were diluted and frozen on _______________\nSample plate IDs: ……………………………………………………………………………….\nAssay overview and timings\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12 beads coupled with capture antibodies\n1 wash\nDBS eluate & previously frozen buffer standards\n2 hour incubation\n3 washes\n12 biotin-conjugated detection Abs.\n1 hour incubation\n3 washes\nSA-PE @ 3 ug/ml\n45 min incubation\n3 washes\nPBS-TBN\nMagPix read\n\n\n\nSummary of assay reagents (bio-techne unless specified)\nComplete columns to record bead coupling date and biotin antibody expiry date:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssay\nCapture antibody on bead\nBead Ab conc (ug/million)\nBead region\nDate beads coupled\nAntigen\nBiotin detection Ab\nBiotin detection Ab expiry\ndetection Ab (ug/ml)\n\n\nIL8\nM801 (Thermo)\n5\n22\n\n208-IL\nBAF208\n\n1.5\n\n\nsTNF-R1\nMAB225\n6\n20\n\n636-R1\nBAF225\n\n1.5\n\n\nIL6\nMAB206\n5\n21\n\n206-IL\nBAF206\n\n1\n\n\nAng2\nNB110-85467\n5\n15\n\n623-AN\nBAF623\n\n1\n\n\nAng1\nMAB9231\n5\n18\n\n923-AN\nBAF923\n\n1.5\n\n\nTRAIL\nMAB375\n6\n25\n\n375-TL\nBAF375\n\n1\n\n\nIL10\nMAB2172\n4\n26\n\n1064-IL\nBAF217\n\n1.5\n\n\nsTREM1\nH00054210-M04\n6\n14\n\n1278-TR\nBAF1278\n\n2\n\n\nIP-10\nMAB266\n5\n29\n\n266-IP\nBAF266\n\n1\n\n\nAzu\nNBP2-12045\n7\n27\n\n2200-SE\nAF2200+B\n\n1.5\n\n\nMxA\nMA5-24914 (Thermo)\n6\n28\n\nTP307418\n(OriGene)\nAF7946+B\n\n1\n\n\nCHI3L1\nMAB25991\n4.5\n30\n\n2599-CH\nBAF2599\n\n1\n\n\n\nSample preparation in advance\n\nDispense DBS samples into elution plates and record sample ID electronically to correspond with plate name and layout. Dispensed DBS can be sealed and stored as per the original sample storage so that they are ready to be tested in larger batches.\n\nDay before assay day\n\nCheck that MagPix machine is in working order and that calibration & verification kits and drive fluid are available.\nPrepare DBS elution buffer fresh on day of use:\n\nProtease inhibitor: dissolve 1 tablet per 2 ml PBS to give 25X (Sigma, cOmplete, 04693116001)\n\nCombine PBS-TBN with 25X protease inhibitor solution for the number of plates to be run on the day:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumber of plates\nPBS-TBN volume (ul)\nTotal volume (ul)\n25X Protease inhibitor (ul)\nThis many tablets\nNumber of plates\nPBS-TBN volume (ul)\nTotal volume (ul)\n25X Protease inhibitor (ul)\nThis many tablets\n\n\n1\n8,448\n8,800\n352\n1\n6\n50,688\n52,800\n2,112\n2\n\n\n2\n16,896\n17,600\n704\n1\n7\n59,136\n61,600\n2,464\n2\n\n\n3\n25,344\n26,400\n1,056\n1\n8\n67,584\n70,400\n2,816\n2\n\n\n4\n33,792\n35,200\n1,408\n1\n9\n76,032\n79,200\n3,168\n2\n\n\n5\n42,240\n44,000\n1,760\n1\n10\n84,480\n88,000\n3,520\n2\n\n\n\n\nLabel black plate(s) with date & plate ID.\nAdd 100 ul/well of elution buffer to DBS in the low-bind plate that they are in.\nSeal with sticky plate cover, label, and place in fridge overnight. Time put in fridge ______________\n\nAssay running day\n\nGet a box of wet ice, if available.\nRetrieve standards from -80 freezer and put on ice or in fridge to thaw.\n\nTip: Do not re-freeze standards. Use a new aliquot each day.\n\nBring eluted sample plates to ambient temperature & put on a shaker until ready to use. Start time ___________\nPrepare beads: get coupled beads from fridge, vortex and sonicate for 30 sec of each.\nAdd the volume of PBS-TBN to a single tube for the number of plates being run on the day. This allows 7% surplus.\n\n\n\n\n\n\n\n\n\n\nPlates\nPBS-TBN volume (uL)\nTotal needed (ul)\nBead volume of each bead (ul)\n\n\n1\n\n5,136\n8.3\n\n\n2\n\n10,272\n16.6\n\n\n3\n\n15,408\n24.9\n\n\n4\n\n20,544\n33.1\n\n\n5\n\n25,680\n41.4\n\n\n6\n\n30,816\n49.7\n\n\n7\n\n35,952\n58.0\n\n\n8\n\n41,088\n66.3\n\n\n9\n\n46,224\n74.6\n\n\n10\n50,060.4\n51,360\n82.8\n\n\n\n\nVortex bead stocks again & add volume of each bead to the tube.\n\n(calculated to get 20k beads/ml [ie 1000 beads/well). Tick as you add the beads:\n\n\n\n\n\n\n\n\n\n\n\nsTNFR1\nMxA\nAng1\nAng2\nIL-10\nsTREM1\nIL-6\nIL-8\nTRAIL\nAzu\nIP-10\nCHI3L1\n\n\n\n\nAdd 50 ul of mixed beads to each well.\nWash the beads: put plate on magnet, wait 60 sec, with the plate still firmly on the magent flick out the liquid. Remove plate from magnet to add 100 ul PBST to each well. Return plate to magnet for 60 sec, flick out wash liquid as before, dab firmly but gently on tissue to remove excess liquid.\nVortex & spin down the standards.\nAdd 30 ul per well of each sample to the black plate.\nAdd 30 ul per well of each standard in duplicate to the black plate.\nCover plates with black cover or foil & incubate on shaker at room temp for 2 hours. Start _______ Ended ________\nDuring the incubation, prepare biotin detection antibodies:\nDetection Abs: Get aliquots of appropriate size from the freezer, depending on number of plates being run. Fill in expiry dates on table at the start of this protocol.\nCombine detection antibodies as per Detection Antibody Prep protocol.\n\nBack to the plate when incubation is over….\n\n3 WASHES with 100 ul PBST to each well as before. NOTE that you should follow your Risk Assessment when disposing of samples.\nAdd 30 ul/well of the preopared detection antibody mixture.\nCover plates & inclubate on shaker for 60 mins. Start time __________ Ended ___________\nDuring the incubation, prepare SA-PE to be 3 ug/ml from the 1 mg/ml stock. (This includes 10% extra volume to allow multichannel pipetting):\n\n\n\n\n\n\n\n\n\n\nPlates\nPBS-TBN volume (ml)\nTotal needed (ml)\nSA-PE volume (ul)\n\n\n1\n3.151\n3.160\n9.5\n\n\n2\n6.301\n6.320\n19.0\n\n\n3\n9.452\n9.480\n28.4\n\n\n4\n12.602\n12.640\n37.9\n\n\n5\n15.753\n15.800\n47.4\n\n\n6\n18.903\n18.960\n56.9\n\n\n7\n22.054\n22.120\n66.4\n\n\n8\n25.204\n25.280\n75.8\n\n\n9\n28.355\n28.440\n85.3\n\n\n10\n31.505\n31.600\n94.8\n\n\n\n\n3 WASHES: wash plate 3 times with 100 ul PBST to each well as before.\nAdd 30 ul/well of SA-PE dilution across the plate.\nCover & incubate for 45 mins on shaker. Start time ___________ Ended ___________\n3 WASHES: wash 3 times with 100 ul PBST to each well well as before.\nAdd 100 ul/well of PBS-TBN.\nCover plate and store plate in fridge if reading the next day, or read immediately.\nOn day of reading: mix plate on gentle shaker before putting in the MagPix machine.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Specimen Testing</span>"
    ]
  },
  {
    "objectID": "Analysis_02.html",
    "href": "Analysis_02.html",
    "title": "17  Data Analysis",
    "section": "",
    "text": "17.1 Functions and tutorial for working with multiplexed immunoassay data",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Analysis</span>"
    ]
  },
  {
    "objectID": "Analysis_02.html#introduction",
    "href": "Analysis_02.html#introduction",
    "title": "17  Data Analysis",
    "section": "17.2 Introduction",
    "text": "17.2 Introduction\nThis script processes and analyses Luminex immunoassay data to evaluate the predictive performance of multiple biomarkers. It begins with a quality-assured workflow that includes standardisation, background correction, and intra-/inter-plate normalisation. Raw MFI (median fluorescence intensity) values are log-transformed and fitted to 4-parameter logistic (4PL) models to derive concentration estimates from standard curves. The script implements automated checks for model convergence and excludes poor-quality fits where needed.\nA suite of custom functions supports downstream analysis, including ROC curve generation (overall and subgroup-conditioned), PPV/NPV curve plotting, and confusion matrix-based statistics. The script outputs both tabular summaries and visual diagnostics to support biomarker evaluation, predictive threshold selection, and rule-based classification. It also includes exploratory and multivariate approaches such as feature selection, dimensionality reduction, and metamodel development.\nMajor analysis components:\n\nStandard curve fitting using 4-parameter logistic models (4PL)\nConverts raw MFI values to estimated concentrations for each biomarker on each plate.\nQuality assurance checks and log transformation\nRemoves background standards (e.g., S8), filters invalid values, and applies log10 transformation to MFI and concentration data.\nNormalisation of concentration values (z-scores)\nStandardises biomarker concentrations within each analyte using z-transformation to allow plate-agnostic comparisons.\nReceiver Operating Characteristic (ROC) analysis\nAssesses discriminatory ability of individual biomarkers via AUC, sensitivity, specificity, and confidence intervals.\nStratified ROC plotting\nVisualises ROC performance within subgroups (e.g., by viral-status or demographic category etc) to evaluate consistency.\nPredictive value curve plotting (PPV/NPV)\nExamines clinical utility of biomarkers across decision thresholds using derived PPV and NPV.\nConfusion matrix analysis at arbitrary thresholds\nQuantifies classification accuracy, sensitivity, specificity, PPV, NPV, and more based on rule-based cutoffs.\nAdjusted PPV estimation\nModels a counterfactual scenario for high-risk inpatients using outpatient mortality to adjust apparent predictive value.\nVariable selection using Boruta\nRanks and selects relevant biomarkers using a random forest wrapper that tests importance against shadow features.\nRecursive Feature Elimination (RFE)\nIteratively removes less informative variables to identify minimal predictive sets optimised for classification.\nPrincipal Component Analysis (PCA)\nPerforms unsupervised dimensionality reduction to summarise structure in the data and explore separation of outcome groups.\nConfirmatory Generalised Linear Models (GLMs)\nTests combinations of selected biomarkers in multivariable logistic regression to evaluate adjusted predictive power.\n\nKey functions:\n\nluminex.process.data(): Imports raw Luminex CSV output, performs reshaping, and applies background correction and metadata integration.\nluminex_standard_curve_estimator(): Fits 4PL curves on each plate-assay pair; log-transforms MFI and concentration values; checks model fit.\napply_luminex_standard_curve(): Iterates over all unique plate-assay combinations to estimate specimen concentrations.\nROCit_plot(): Computes and plots ROC curves with bootstrapped AUC confidence intervals.\nROCit_plot_conditioned(): Generates ROC curves stratified by subgroup (e.g. HIV Positive Vs HIV Negative).\ngenerate_roc_tables(): Produces AUC summaries across multiple biomarkers in tabular format.\nplot_ppv(): Plots PPV and NPV curves across thresholds to support classifier cut-off selection.\ncompute_conf_matrix_stats(): Calculates classification metrics (e.g. sensitivity, specificity, PPV, NPV, accuracy) from binary rules.\ncompute_adjusted_biomarker_stats(): Computes subgroup-specific performance metrics and adjusted PPV accounting for admission bias.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Analysis</span>"
    ]
  },
  {
    "objectID": "Analysis_02.html#libraries",
    "href": "Analysis_02.html#libraries",
    "title": "17  Data Analysis",
    "section": "17.3 Libraries",
    "text": "17.3 Libraries\nLoad the libraries used in this analysis and set a seed so that this is fully reproducible.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Analysis</span>"
    ]
  },
  {
    "objectID": "Analysis_02.html#define-functions",
    "href": "Analysis_02.html#define-functions",
    "title": "17  Data Analysis",
    "section": "17.4 Define Functions",
    "text": "17.4 Define Functions\n\n17.4.1 Function to Read and analyse Luminex Plates\nThis function imports and tidies raw Luminex assay data from one or more specified .csv file. It extracts and reshapes MFI and bead count data, assigns unique identifiers, filters out poor-quality measurements, and merges the assay data with known standard concentrations. The output is a clean, annotated dataframe ready for downstream quantification and analysis.\n\n# Function to process raw Luminex assay data from a given file and return a tidy dataframe\nluminex.process.data &lt;- function(file, standards.file = \"data/MOSDEF_Standard_Concs.csv\") {\n\n  ####### Load and clean Luminex data file #######\n  df &lt;- read_csv(file, skip = 41, na = c(\"\", \"NA\", \"NaN\"), show_col_types = FALSE) %&gt;%\n    setNames(tolower(gsub(\"-\", \"_\", names(.)))) %&gt;%    # Convert column names to lowercase and replace hyphens with underscores\n    mutate(sample = fct_na_value_to_level(sample)) %&gt;% # Convert NA levels in 'sample' column to an explicit factor level\n    select_if(!names(.) %in% c('...17', 'location', 'total events'))  # Drop unused or noisy columns\n\n  # Ensure CRP column exists even if missing\n  if (!'crp' %in% names(df)) df$crp &lt;- NA\n\n  ####### Assign unique IDs to samples #######\n  randomid &lt;- function(n = 1) {\n    # Generates a random alphanumeric ID of the form 'ABCDE1234Z'\n    a &lt;- do.call(paste0, replicate(5, sample(LETTERS, n, TRUE), FALSE))\n    paste0(a, sprintf(\"%04d\", sample(9999, n, TRUE)), sample(LETTERS, n, TRUE))\n  }\n\n  ####### Extract and reshape Net MFI values #######\n  MFI.medians &lt;- df[1:(which(str_detect(string = df$sample, pattern = \"Net MFI\"))[1] - 1), ] %&gt;%\n    mutate(test.id = randomid(n = nrow(.))) %&gt;%\n    pivot_longer(cols = 2:14, names_to = \"assay\", values_to = \"mfi\")  # Reshape to long format\n\n  ####### Extract and reshape bead count values #######\n  MFI.counts &lt;- df[\n    (which(str_detect(string = df$sample, pattern = \"Count\"))[1] + 2):\n    (which(str_detect(string = df$sample, pattern = \"Avg Net MFI\"))[1] - 1),\n  ] %&gt;%\n    pivot_longer(cols = 2:14, names_to = \"assay\", values_to = \"bead.count\") %&gt;%\n    mutate(test.id = MFI.medians$test.id)  # Align by test ID\n\n  ####### Merge MFI and bead count data, clean and filter #######\n  df &lt;- full_join(MFI.medians, MFI.counts) %&gt;%\n    mutate(\n      mfi = as.numeric(as.character(mfi)),                 # Ensure MFI is numeric\n      bead.count = as.numeric(as.character(bead.count))    # Ensure bead count is numeric\n    ) %&gt;%\n    filter(\n      sample != \"(Missing)\",      # Remove missing samples\n      bead.count &gt; 15,            # Minimum quality threshold for bead count\n      !is.na(mfi)                 # Remove rows with missing MFI values\n    )\n\n  ####### Read and tidy standard concentrations #######\n  standards &lt;- read_csv(standards.file, show_col_types = FALSE) %&gt;%\n    pivot_longer(cols = S1:S8, names_to = \"sample\", values_to = \"conc\") %&gt;%\n    mutate(\n      conc = as.numeric(\n        case_when(\n          unit == 'ng_ml' ~ conc * 1000,  # Convert concentration to pg/mL if needed\n          TRUE ~ conc\n        )\n      ),\n      assay = tolower(assay),                         # Normalise assay names\n      assay = gsub(x = assay, pattern = \"-\", replacement = \"_\")  # Standardise naming\n    ) %&gt;%\n    dplyr::select(-unit) %&gt;%         # Drop unit column after conversion\n    mutate(class = \"standard\")       # Tag as standard samples\n\n  ####### Merge standards with assay data #######\n  df &lt;- left_join(df, standards)           # Add known concentrations to matching samples\n  df$class[is.na(df$class)] &lt;- \"specimen\"  # Tag unmatched rows as experimental specimens\n\n  ####### Derive plate name from filename #######\n  plate &lt;- str_replace(string = file, pattern = \"data_in//\", replacement = \"\")  # Clean path\n  plate &lt;- str_replace(string = plate, pattern = \".csv\", replacement = \"\")      # Remove extension\n  df$plate &lt;- plate                        # Store plate label in output\n\n  return(df)  # Return tidy, annotated dataset\n}\n\n\n\n17.4.2 Function to draw ROC chart in ggplot\nThis function generates a receiver operating characteristic (ROC) curve from a given dataset, comparing a continuous biomarker score to a binary outcome (e.g. alive vs dead). It supports output as a ggplot2 figure or a tabulated set of performance metrics, and includes optional colour and style customisation.\n\n####### Function to draw ROC chart in ggplot #######\n\nROCit_plot &lt;- function(data, score_col, class_col, failcode = NULL, title = \"ROC Curve\",\n                       negate_score = FALSE, lty = \"solid\", color = NULL, output = \"chart\") {\n\n  # Load required libraries\n  library(ggplot2)       # Plotting system\n  library(dplyr)         # Data manipulation\n  library(tibble)        # Tidy tibble data frames\n  library(RColorBrewer)  # Color palettes\n  library(ROCit)         # ROC curve and AUC computation\n\n  # Use a colorblind-friendly palette if no color is provided\n  if (is.null(color)) {\n    colors &lt;- brewer.pal(n = 8, \"Dark2\")              # Load Dark2 palette\n    curve_color &lt;- if (negate_score) colors[2] else colors[1]  # Use different colors depending on score polarity\n  } else {\n    curve_color &lt;- color  # Use custom user-defined color\n  }\n\n  # Determine which class is considered the \"positive\" (i.e. fail) class\n  class_levels &lt;- levels(factor(data[[class_col]]))  # Get levels of classification variable\n  if (!is.null(failcode) && failcode %in% class_levels) {\n    pos_class &lt;- failcode                                # Use user-defined failcode\n  } else {\n    pos_class &lt;- class_levels[2]                # Default to second level if not specified\n  }\n\n  # Convert class column to binary: 1 = positive class, 0 = negative\n  data$outcome_binary &lt;- as.numeric(data[[class_col]] == pos_class)\n\n  # Conditionally negate scores (some metrics are inversely related to outcome)\n  score_values &lt;- if (negate_score) -data[[score_col]] else data[[score_col]]\n\n  # Compute ROC curve object\n  rocit_obj &lt;- rocit(score = score_values, class = data$outcome_binary)\n\n  # Calculate confidence intervals for AUC using bootstrapping\n  auc_ci &lt;- ciAUC(rocit_obj, method = \"bootstrap\", boot.n = 1000)\n\n  # Extract AUC and its confidence intervals\n  auc_value &lt;- as.numeric(rocit_obj$AUC)\n  auc_lower &lt;- as.numeric(auc_ci$lower)\n  auc_upper &lt;- as.numeric(auc_ci$upper)\n\n  # Count number of positive and negative samples\n  n_neg &lt;- sum(data[[class_col]] != pos_class, na.rm = TRUE)\n  n_pos &lt;- sum(data[[class_col]] == pos_class, na.rm = TRUE)\n\n  # Generate AUC label for display\n  auc_label &lt;- if (is.na(auc_lower) | is.na(auc_upper)) {\n    paste0(\"AUC = \", round(auc_value, 2), \" (CI: N/A)\")\n  } else {\n    paste0(\"AUC = \", round(auc_value, 2), \" (\", round(auc_lower, 2), \"–\", round(auc_upper, 2), \")\")\n  }\n\n  # Optionally return a summary table instead of a plot\n  if (output == \"table\") {\n    summary_table &lt;- tibble(\n      Assay = score_col,\n      Outcome = class_col,\n      Failcode = pos_class,\n      AUC = round(auc_value, 2),\n      CI_Lower = round(auc_lower, 2),\n      CI_Upper = round(auc_upper, 2),\n      n_negative = n_neg,\n      n_positive = n_pos\n    )\n    return(summary_table)\n\n  } else if (output == \"chart\") {\n    # Build a tidy data frame for plotting\n    roc.curve &lt;- tibble(\n      TPR = rocit_obj$TPR,  # True Positive Rate (sensitivity)\n      FPR = rocit_obj$FPR   # False Positive Rate (1 - specificity)\n    )\n\n    # Plot ROC curve using ggplot2\n    p &lt;- ggplot(data = roc.curve, aes(x = FPR, y = TPR)) +\n      geom_line(color = curve_color, size = 1.2, linetype = lty) +  # Draw ROC curve\n      geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"grey50\") +  # Diagonal reference line\n      annotate(\"text\", x = 0.6, y = 0.05, label = auc_label, size = 4, fontface = \"bold\", color = \"black\") +  # AUC annotation\n      labs(title = title, x = \"False Positive Rate (1 - Specificity)\", y = \"True Positive Rate (Sensitivity)\") +\n      theme_minimal(base_size = 14)  # Clean, readable theme\n\n    return(p)  # Return the ggplot object\n  } else {\n    stop(\"Invalid output option. Use 'chart' or 'table'.\")  # Handle incorrect output argument\n  }\n}\n\n\n\n17.4.3 Function to generate ROC tables for multiple biomarkers\nThis function calculates ROC performance metrics (e.g. AUC, sensitivity, specificity) for a list of biomarkers against a binary outcome. It returns a tidy, combined table of ROC statistics for each biomarker, facilitating comparative evaluation and downstream reporting.\n\nAccepts a list of biomarkers.\nApplies ROCit_plot(..., output = \"table\") to each one.\nCollects the AUC results and sample sizes into a single tidy tibble.\n\n\n# Function to generate ROC summary tables for a list of biomarkers\ngenerate_roc_tables &lt;- function(data, biomarkers, class_col = \"dead_or_alive\") {\n  \n  # Inner function that generates a ROC table for a single biomarker\n  generate_roc_table &lt;- function(score_col) {\n    roc_result &lt;- ROCit_plot(\n      data = data,                 # Dataset to be used\n      score_col = score_col,       # Column containing predictor score (biomarker)\n      class_col = class_col,       # Outcome column (default: \"dead_or_alive\")\n      output = \"table\"             # Return summary table instead of plot\n    )\n    \n    # Add biomarker name to the output for easier identification later\n    roc_result %&gt;%\n      mutate(biomarker = score_col)\n  }\n\n  # Apply the ROC table function across all biomarkers and combine the results\n  roc_tables &lt;- map_dfr(biomarkers, generate_roc_table)\n\n  # Return the complete ROC summary table\n  return(roc_tables)\n}\n\n\n\n17.4.4 Function to generate a ROC curve conditioned on a variable\nThis function generates stratified ROC plots for a single biomarker, comparing performance across subgroups defined by a conditioning variable (e.g. inpatient vs outpatient). It computes ROC curves and AUC with confidence intervals for each subgroup and the overall population, and visualises them using a colourblind-friendly ggplot.\n\nPlots ROC curves for a biomarker across different groups (e.g. male vs female).\nAlways includes an “Overall” curve for the full dataset.\nUses AUC with 95% CI to label each group.\nHandles edge cases gracefully (e.g. skips groups with no variation in outcome).\nThe result is a single ggplot object showing comparative diagnostic performance.\n\n\n# Function to draw ROC curves for a biomarker across different subgroups (e.g., by sex or age group)\nROCit_plot_conditioned &lt;- function(data, score_col, class_col, title = \"ROC Curve\", \n                                   negate_score = FALSE, lty = \"solid\", color = NULL, \n                                   conditioning = NULL) {\n  # Load required libraries\n  library(ggplot2)        # For plotting\n  library(dplyr)          # For data manipulation\n  library(tidyr)          # For reshaping data\n  library(RColorBrewer)   # For colour palettes\n  library(ROCit)          # For computing ROC and AUC\n\n  # If a conditioning variable is provided, exclude any rows where that variable is \"indet\"\n  if (!is.null(conditioning)) {\n    data &lt;- filter(data, !!sym(conditioning) != \"indet\")\n  }\n\n  # Set up a colour palette (Dark2 is colourblind-friendly)\n  if (is.null(color)) {\n    colors &lt;- brewer.pal(n = 8, \"Dark2\")\n  }\n\n  # This tibble will store all ROC curve data for plotting\n  roc_data &lt;- tibble()\n\n  # Always compute an overall ROC curve (i.e., across all data)\n  data_list &lt;- list(data)           # Start with one list entry: all data\n  levels &lt;- c(\"Overall\")            # Label this level as \"Overall\"\n\n  # If a conditioning variable is supplied (e.g. sex), add separate subsets for each group\n  if (!is.null(conditioning)) {\n    cond_levels &lt;- unique(as.character(data[[conditioning]]))  # Get unique levels\n    levels &lt;- c(\"Overall\", cond_levels)                        # Label groups for plot\n    # Create a list of data frames split by condition\n    data_list &lt;- c(\n      list(data),\n      lapply(cond_levels, function(level) {\n        filter(data, !!sym(conditioning) == level)\n      })\n    )\n  }\n\n  # Loop over each subset (overall + each subgroup)\n  for (i in seq_along(data_list)) {\n    subset_data &lt;- data_list[[i]]\n\n    # Skip this subset if it doesn't have at least two different outcome values\n    if (length(unique(subset_data[[class_col]])) &lt; 2) {\n      message(\"Skipping level '\", levels[i], \"' because it has fewer than two unique values in '\", class_col, \"'.\")\n      next\n    }\n\n    # Use negative scores if specified (useful when low scores indicate higher risk)\n    score_values &lt;- if (negate_score) -subset_data[[score_col]] else subset_data[[score_col]]\n\n    # Compute ROC curve and AUC\n    rocit_obj &lt;- rocit(score = score_values, class = subset_data[[class_col]])\n    auc_ci &lt;- ciAUC(rocit_obj, method = \"bootstrap\", boot.n = 1000)\n\n    # Extract AUC and confidence intervals\n    auc_value &lt;- as.numeric(rocit_obj$AUC)\n    auc_lower &lt;- as.numeric(auc_ci$lower)\n    auc_upper &lt;- as.numeric(auc_ci$upper)\n\n    # Add results to the plotting data frame with subgroup label and AUC\n    roc_data &lt;- bind_rows(\n      roc_data,\n      tibble(\n        TPR = rocit_obj$TPR,   # True Positive Rate\n        FPR = rocit_obj$FPR,   # False Positive Rate\n        group = paste0(levels[i], \" (AUC: \", round(auc_value, 2),\n                       \" [\", round(auc_lower, 2), \"–\", round(auc_upper, 2), \"])\")\n      )\n    )\n  }\n\n  # Plot ROC curves for all groups\n  p &lt;- ggplot(roc_data, aes(x = FPR, y = TPR, color = group)) +\n    geom_line(size = 1.2, linetype = lty) +                                     # Main ROC curve\n    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"grey50\") +  # Reference line\n    scale_color_manual(values = colors[1:length(unique(roc_data$group))]) +    # Manual color assignment\n    labs(title = title, x = NULL, y = NULL, color = NULL) +                    # Minimal axis labels\n    theme_minimal(base_size = 14) +                                            # Clean theme\n    theme(\n      legend.position = \"right\",\n      legend.key.width = unit(2, \"cm\"),\n      plot.title = element_text(hjust = 0.5)                                   # Centered title\n    )\n\n  return(p)  # Return the ggplot object\n}\n\n\n\n17.4.5 Function to Estimate Luminex Standard Curve and Predict Concentrations for All Plates and Assays\nThis function fits a 4-parameter logistic (4PL) model to Luminex assay standard data for a specific plate and analyte. It uses this model to convert log-transformed MFI values into estimated concentrations for specimens, applying a lower bound to avoid extrapolation below the lowest standard.\n\nUses a subset of assay data from one plate to fit a 4-parameter logistic curve (4PL) relating MFI to known concentrations.\nThen, it predicts log10 concentrations for unknown samples based on their MFI.\nIt avoids extrapolating below the lowest standard but allows extrapolation above the highest.\nIf model fitting fails (e.g. due to bad standards), it exits gracefully and returns the original data.\n\n\n# Function to estimate specimen concentrations on a specific plate and assay using a 4-parameter logistic (4PL) standard curve\nluminex_standard_curve_estimator &lt;- function(data, test_plate, test_assay) {\n\n  # Step 1: Filter dataset for the selected plate and assay\n  x &lt;- filter(data, plate == test_plate, assay == test_assay)\n\n  # Step 2: Extract the minimum and maximum standard concentrations\n  # These are used for bounds and interpretation, based on known standard samples\n  min_standard &lt;- filter(x, class == \"standard\", sample == \"S7\") %&gt;%\n    summarise(min_conc = min(conc, na.rm = TRUE)) %&gt;%\n    pull(min_conc)\n\n  max_standard &lt;- filter(x, class == \"standard\", sample == \"S1\") %&gt;%\n    summarise(max_conc = max(conc, na.rm = TRUE)) %&gt;%\n    pull(max_conc)\n\n  # Step 3: Transform both MFI and concentration to log10 scale\n  # This helps to linearise the central part of the 4PL curve\n  x &lt;- x %&gt;%\n    mutate(\n      log10_mfi = log10(mfi),\n      log10_conc = log10(conc)\n    ) %&gt;%\n    filter(sample != \"S8\")  # Exclude the buffer-only blank sample (S8)\n\n  # Step 4: Split dataset into standard and specimen groups\n  x_standards &lt;- x %&gt;% filter(class == \"standard\", log10_mfi &gt;= 0)  # Keep only valid MFI values\n  x_samples &lt;- x %&gt;% filter(class != \"standard\", log10_mfi &gt;= 0)\n\n  # Step 5: Fit a 4-parameter logistic (4PL) model using standard data\n  # This models the relationship between log10(MFI) and log10(concentration)\n  model1 &lt;- tryCatch(\n    drm(log10_conc ~ log10_mfi,\n        fct = LL.4(names = c(\"Slope\", \"Lower\", \"Upper\", \"ED50\")),\n        data = x_standards),\n    error = function(e) {\n      # Handle cases where the model fails to converge\n      message(\"4PL model fitting failed for plate: \", test_plate, \" assay: \", test_assay)\n      return(NULL)\n    }\n  )\n\n  # Step 6: If model was successful, use it to estimate concentrations for specimens\n  if (!is.null(model1)) {\n    x &lt;- x %&gt;%\n      mutate(\n        Estimate = predict(model1, newdata = data.frame(log10_mfi = log10_mfi)),\n\n        # Apply a lower bound to predictions (avoid values below min standard)\n        # Upper bound is commented out – optionally enforce with: log10(max_standard)\n        Estimate = pmax(Estimate, log10(min_standard))\n      )\n  }\n\n  # Step 7: Return the augmented data frame (with estimates added if available)\n  return(x)\n}\n\n\n\n17.4.6 Function to Apply Standard Curve Estimation Across All Plates and Assays\nThis function applies the luminex_standard_curve_estimator() across all unique plate–assay combinations in the dataset. It returns a single, combined dataframe with estimated concentrations for all analytes on all plates.\n\nLooks at every unique plate and assay pair in your data.\nRuns the 4PL model fitting and prediction for each one.\nReturns a single, tidy dataframe where each row includes the original MFI and the estimated concentration (on a log10 scale).\n\n\n# Function to apply the standard curve estimator across all plate-assay combinations in the dataset\napply_luminex_standard_curve &lt;- function(data) {\n\n  # Step 1: Identify all unique combinations of plate and assay\n  # This assumes that each plate-assay pair has its own standard curve\n  unique_combinations &lt;- distinct(data, plate, assay)\n\n  # Step 2: For each plate-assay combination, estimate concentrations using the luminex_standard_curve_estimator()\n  # - map2_dfr() applies the function across two parallel vectors (plate and assay)\n  # - .x refers to each plate, .y refers to each assay\n  # - _dfr binds all the results into a single dataframe row-wise\n  results &lt;- map2_dfr(unique_combinations$plate, unique_combinations$assay,\n                      ~ luminex_standard_curve_estimator(data, .x, .y))\n\n  # Step 3: Return the combined results with estimated concentrations for all specimens\n  return(results)\n}\n\n\n\n17.4.7 Function to plot Positive Predictive Values\nThis function generates a diagnostic curve showing how the Positive Predictive Value (PPV) and Negative Predictive Value (NPV) of a biomarker vary across different decision thresholds. It uses ROC-derived sensitivity and specificity to compute predictive values and visualises them with ggplot2.\n\nCalculates and plots how PPV (positive predictive value) and NPV (negative predictive value) change across the full range of thresholds for a diagnostic test or biomarker.\nIt does this by first computing a ROC curve and then applying Bayes’ theorem to convert sensitivity/specificity and prevalence into predictive values.\nThe plot shows whether a test becomes more reliable at specific cut-offs, helping guide threshold selection in clinical or diagnostic settings.\n\n\n# Function to plot Positive Predictive Value (PPV) and Negative Predictive Value (NPV) across all thresholds\nplot_ppv &lt;- function(data, outcome, marker, failcode = NULL, title = \"Predictive Value Curve\", colppv = \"#000000\", colnpv = \"#982873\") {\n  \n  # Load necessary libraries\n  library(ggplot2)  # For plotting\n  library(pROC)     # For ROC curve calculation\n\n  # Step 1: Determine the \"positive\" class\n  # If a specific failcode is provided and found in the outcome, use it\n  # Otherwise, default to the second level of the factor as the positive class\n  if (!is.null(failcode) && failcode %in% levels(factor(data[[outcome]]))) {\n    pos_class &lt;- failcode\n  } else {\n    pos_class &lt;- levels(factor(data[[outcome]]))[2]\n  }\n\n  # Step 2: Convert outcome to binary: 1 = positive class, 0 = other\n  data$outcome_binary &lt;- as.numeric(data[[outcome]] == pos_class)\n\n  # Step 3: Generate an ROC curve object\n  # pROC::roc() returns thresholds, sensitivities, and specificities\n  roc_obj &lt;- roc(data$outcome_binary, data[[marker]], direction = \"&lt;\")\n\n  # Step 4: Calculate prevalence (proportion of positive outcomes)\n  prevalence &lt;- mean(data$outcome_binary)\n\n  # Step 5: Extract threshold-dependent sensitivity and specificity\n  thresholds  &lt;- roc_obj$thresholds\n  sensitivity &lt;- roc_obj$sensitivities\n  specificity &lt;- roc_obj$specificities\n\n  # Step 6: Calculate PPV and NPV at each threshold using Bayes' theorem\n  ppv &lt;- (sensitivity * prevalence) / (sensitivity * prevalence + (1 - specificity) * (1 - prevalence))\n  npv &lt;- (specificity * (1 - prevalence)) / (specificity * (1 - prevalence) + (1 - sensitivity) * prevalence)\n\n  # Step 7: Handle divide-by-zero cases by setting NaNs to NA\n  ppv[is.nan(ppv)] &lt;- NA\n  npv[is.nan(npv)] &lt;- NA\n\n  # Step 8: Combine data into a dataframe for plotting\n  roc_data &lt;- data.frame(thresholds, ppv, npv)\n\n  # Step 9: Plot PPV and NPV curves over all thresholds\n  ggplot(roc_data, aes(x = thresholds)) +\n    geom_line(aes(y = ppv, color = colppv), size = 1.2) +     # PPV line\n    geom_line(aes(y = npv, color = colnpv), size = 1.2) +     # NPV line\n    labs(\n      title = title,\n      x = \"Threshold\",\n      y = \"Predictive Value\"\n    ) +\n    theme(legend.position = \"none\") +\n    ylim(0, 1)  # Clamp values to [0, 1] for interpretability\n}\n\n\n\n17.4.8 Function to compute confusion matrix statistics\nThis function evaluates the diagnostic performance of a binary decision rule (e.g. marker &gt; threshold) by computing a full confusion matrix and associated classification statistics including sensitivity, specificity, PPV, NPV, accuracy, balanced accuracy, and McNemar’s test p-value. It returns a tidy summary of these metrics for a given condition.\n\nTakes a logical condition (like marker &gt; 10) and applies it to the dataset to create a synthetic prediction of who will die or survive.\nCompares those predictions to the actual outcome (dead_or_alive) using a confusion matrix.\nThen, calculates a full set of diagnostic performance metrics like:\n\nSensitivity (recall)\nSpecificity\nPPV / NPV\nAccuracy and balanced accuracy\nMcNemar’s test p-value (checks symmetry in prediction errors)\n\nReturns all of this in a tidy, easily interpreted tibble, making it useful for grid search or ROC threshold evaluation.\n\n\n# Function to compute classification metrics based on a logical condition\n# The condition is used to classify rows as \"dead\" or \"alive\" based on any biomarker or rule\n# Returns a tidy summary of sensitivity, specificity, PPV, NPV, accuracy, and confusion matrix counts\n\ncompute_conf_matrix_stats &lt;- function(data, condition, outcome_col = \"dead_or_alive\") {\n  \n  # Load required libraries\n  library(dplyr)      # For data manipulation\n  library(caret)      # For confusionMatrix() and performance metrics\n  library(rlang)      # For parsing string-based logical expressions\n  \n  # Step 1: Apply the user-defined condition to classify predicted outcomes\n  # The string condition is parsed and evaluated row-wise\n  data &lt;- data %&gt;%\n    mutate(\n      synthetic_risk = case_when(\n        !!parse_expr(condition) ~ \"Dead\",  # If the condition is TRUE, classify as \"dead\"\n        TRUE ~ \"Alive\"                     # Otherwise, classify as \"alive\"\n      )\n    )\n\n  # Step 2: Standardise factor levels to ensure they match for comparison\n  # This prevents errors when creating the confusion matrix\n  data &lt;- data %&gt;%\n    mutate(\n      synthetic_risk = factor(synthetic_risk, levels = c(\"Alive\", \"Dead\")),  # Predicted values\n      actual_outcome = factor(!!sym(outcome_col), levels = c(\"Alive\", \"Dead\"))  # Actual outcome\n    )\n\n  # Step 3: Create a 2x2 confusion matrix of predicted vs actual outcomes\n  # Rows = predicted values, columns = actual outcomes\n  conf_matrix &lt;- table(data$synthetic_risk, data$actual_outcome)\n\n  # Step 4: Compute classification performance statistics using caret\n  # Includes sensitivity, specificity, PPV, NPV, accuracy, and McNemar’s test\n  cf &lt;- confusionMatrix(conf_matrix, positive = \"Dead\")  # Specify \"dead\" as the positive class\n\n  # Step 5: Extract metrics and return them in a tidy tibble\n  # This format is easy to combine, filter, or present in a table\n  tibble(\n    condition        = condition,                           # The condition used to classify rows\n    PPV              = cf$byClass[\"Pos Pred Value\"],        # Positive Predictive Value\n    NPV              = cf$byClass[\"Neg Pred Value\"],        # Negative Predictive Value\n    sensitivity      = cf$byClass[\"Sensitivity\"],           # True positive rate\n    specificity      = cf$byClass[\"Specificity\"],           # True negative rate\n    accuracy         = cf$overall[\"Accuracy\"],              # Overall correct classification rate\n    accuracylower    = cf$overall[\"AccuracyLower\"],         # Lower bound of 95% CI for accuracy\n    accuracyupper    = cf$overall[\"AccuracyUpper\"],         # Upper bound of 95% CI for accuracy\n    balancedaccuracy = cf$byClass[\"Balanced Accuracy\"],     # Mean of sensitivity and specificity\n    mcnemarp         = cf$overall[\"McnemarPValue\"],         # McNemar’s test p-value for symmetry\n    true_neg         = cf$table[1],                         # True negatives (pred = alive, actual = alive)\n    false_neg        = cf$table[2],                         # False negatives (pred = alive, actual = dead)\n    false_pos        = cf$table[3],                         # False positives (pred = dead, actual = alive)\n    true_pos         = cf$table[4]                          # True positives (pred = dead, actual = dead)\n  )\n}",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Analysis</span>"
    ]
  },
  {
    "objectID": "Analysis_02.html#plate-setup-and-data-reading",
    "href": "Analysis_02.html#plate-setup-and-data-reading",
    "title": "17  Data Analysis",
    "section": "17.5 Plate Setup and data reading",
    "text": "17.5 Plate Setup and data reading\n\n17.5.1 Setup Plate data\nThis code loads and processes all raw Luminex assay .csv files from the data/luminex_files_zimbabwe/ directory:\n\nFile discovery: list.files() identifies all files in the target folder with full paths.\nFile processing: Each file is passed to the luminex.process.data() function to extract and tidy the MFI and bead count data, merge in standard concentrations, and label metadata.\nRow binding: All resulting data frames are combined into a single df using bind_rows().\nPlate labelling: The plate variable is cleaned by removing the directory path prefix (data/luminex_files_zimbabwe//plate_).\n\n\nc.files &lt;- list.files(\"data/luminex_files_simulated//\", full.names = TRUE)\n\ndf &lt;- suppressMessages(bind_rows(lapply(c.files, function(x) luminex.process.data(file = x, standards.file = \"data/MOSDEF_Standard_Concs.csv\")))) %&gt;% \n  mutate(plate = str_remove(plate,\"data/luminex_files_zimbabwe//plate_\"))\n\n\n\n17.5.2 Standards\nThe main purpose of the standards is to ensure that per-plate and per-assay, the standard curve specimens return MFI values that follow a dose-response curve.\n\nAny assays where this isn’t the case should be removed, or at least adjusted for batch effects.\nThis requires a standards file to be provided (see MOSDEF_Standard_Concs.csv). It should look like the one below. Beware that the names of the assays and the names of the standards both need to match exactly to those in the data sets. Standard 8 is a background control (i.e. buffer blank). You could manually build this if you wanted to with the tibble command.\n\nstandards = read_csv(\"data/MOSDEF_Standard_Concs.csv\",show_col_types = F)\nkable(standards)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nassay\nunit\nS1\nS2\nS3\nS4\nS5\nS6\nS7\nS8\n\n\n\n\nCRP\npg_ml\n10000\n2500.0\n625.000\n156.25000\n39.0625000\n9.7656250\n2.4414062\n0\n\n\nsTREM1\npg_ml\n10000\n2500.0\n625.000\n156.25000\n39.0625000\n9.7656250\n2.4414062\n0\n\n\nAng-2\nng_ml\n100\n25.0\n6.250\n1.56250\n0.3906250\n0.0976562\n0.0244141\n0\n\n\nAng-1\nng_ml\n50\n12.5\n3.125\n0.78125\n0.1953125\n0.0488281\n0.0122070\n0\n\n\nsTNF-R1\npg_ml\n2500\n625.0\n156.250\n39.06250\n9.7656250\n2.4414062\n0.6103516\n0\n\n\nIL-6\npg_ml\n10000\n2500.0\n625.000\n156.25000\n39.0625000\n9.7656250\n2.4414062\n0\n\n\nTRAIL\npg_ml\n10000\n2500.0\n625.000\n156.25000\n39.0625000\n9.7656250\n2.4414062\n0\n\n\nIL-10\npg_ml\n4000\n1000.0\n250.000\n62.50000\n15.6250000\n3.9062500\n0.9765625\n0\n\n\nAzu\nng_ml\n200\n50.0\n12.500\n3.12500\n0.7812500\n0.1953125\n0.0488281\n0\n\n\nMxA\nng_ml\n300\n75.0\n18.750\n4.68750\n1.1718750\n0.2929688\n0.0732422\n0\n\n\nIP-10\npg_ml\n10000\n2500.0\n625.000\n156.25000\n39.0625000\n9.7656250\n2.4414062\n0\n\n\nCH3L1\nng_ml\n100\n25.0\n6.250\n1.56250\n0.3906250\n0.0976562\n0.0244141\n0\n\n\nIL-8\npg_ml\n2500\n625.0\n156.250\n39.06250\n9.7656250\n2.4414062\n0.6103516\n0\n\n\n\n\nrm(standards)\n\nThis code chunk visualises the standard curves for each analyte across all plates to assess for potential batch effects:\n\nFiltering: Extracts only rows classified as \"standard\" from the full dataset (df).\nPlotting: For each analyte (assay), plots log(MFI) against log(concentration) to visualise the relationship.\nFaceting: Uses facet_wrap() to create separate panels per analyte, allowing comparison across assays.\nPurpose: Helps identify inconsistencies, nonlinearities, or batch variation in standard performance across plates before model fitting.\n\n\nstandards&lt;-df %&gt;% filter(class==\"standard\")\n\n# Visualise standards to assess batch effects\nggplot(standards,aes(log(conc),log(mfi)))+geom_point()+geom_smooth()+facet_wrap(.~assay,scales = \"free\")\n\n\n\n\n\n\n\n\nIn this example there appears to be some kind of batch effect in the MxA assay, which leads to two distinct curves. This can be plotted by individual plates in numerical series to see what is going on.\n\n\n17.5.3 Plate-Level MFI Distribution by Assay\nThis plot is used to assess measurement consistency and detect plate-specific anomalies:\n\nInput data: Uses the full dataset df, including both specimen and standard samples.\nAxes:\n\nx = plate: Each plate (from file name) on the x-axis.\ny = log(mfi): Log-transformed median fluorescence intensity.\n\nColor: Points are colored by class (i.e., standard or specimen).\nFaceting: A separate panel is drawn for each assay, allowing per-analyte inspection.\nPoint styling: Uses small, semi-transparent dots to make dense plots readable.\n\nPurpose:\nQuick visual QC for MFI ranges across plates and analytes. Useful for spotting:\n\nDrifts or jumps between plates,\nAssays with unusually high/low values,\nMissing or outlier readings.\n\n\nggplot(df,aes(plate,log(mfi),col=class))+geom_point(size=0.5,alpha=0.5)+facet_wrap(.~assay)\n\n\n\n\n\n\n\n\nEach column shows the raw data from a single plate, and here we can see that non-alignment of the standards (blue dots) suggests a batch effect (i.e. a batch of beads with overall lower fluorescence) in several of the assays – but most obviously in MxA.\nBatch effects can be corrected for (to some degree) by normalisation.\n\n\n17.5.4 Application of Standard Curve to Convert MFI to Concentration\nThis line applies the 4-parameter logistic (4PL) model to convert median fluorescence intensity (MFI) readings into estimated analyte concentrations:\nWhat it does:\n\nCalls apply_luminex_standard_curve(), which:\n\nIdentifies unique (plate, assay) combinations.\nFor each combination, invokes luminex_standard_curve_estimator() to:\n\nFit a 4PL model using the known standard concentrations.\nPredict concentrations for specimens using the fitted curve.\nApply a log10 transformation and a floor limit (based on the lowest standard).\n\n\nCombines all modelled data back into a unified, tidy dataframe.\n\nOutput:\n\nThe returned df includes a new column Estimate, which contains the log10-transformed concentration estimates for valid, non-background specimens.\n\n\ndf&lt;-apply_luminex_standard_curve(df)\n\n\n\n17.5.5 Visualisation of Fitted Concentration Estimates Across Plates\nThis plot shows how the estimated concentrations (from 4PL standard curve fitting) vary by assay and plate:\nPurpose:\n\nTo assess consistency of the estimated concentrations (Estimate) across assay plates.\nTo detect batch effects or anomalies in specimen or standard behaviour.\nHelps verify that the 4PL fitting worked as intended and is not introducing systematic bias between plates or assays.\n\nThis is an important QA diagnostic step to ensure validity and comparability before downstream analysis.\n\nggplot(df,aes(plate,Estimate,col=class))+geom_point(size=0.5,alpha=0.5)+facet_wrap(.~assay)\n\n\n\n\n\n\n\n\n\n\n17.5.6 Remove Standards Before Further Analysis\n\nPurpose: Ensures only experimental (specimen) data are retained for analysis.\nWhy: Standard samples are reference/control values used during calibration and plate-wise normalisation steps (above) and should not be included in the z-score step, which is meant to scale specimens only.\n\n\ndf&lt;-df %&gt;% filter(\n    class != \"standard\"   # Remove standards before normalization\n    )\nrm(standards)\n\n\n\n17.5.7 Pivot Data to wide format\nThis code reshapes your Luminex data into a wide format, suitable for multivariate analyses.\n\ndf_wider &lt;- df %&gt;% \n  pivot_wider(id_cols = c(sample,test.id),names_from = assay,values_from = Estimate \n  )\n\n\n\n17.5.8 Normalise scores for modelling purposes\nThis step normalises each biomarker using z-score transformation, which centers the data (mean = 0) and scales it (SD = 1).\nWhat This Does:\n\nApplies scale() to each biomarker:\n\nSubtracts the mean\nDivides by the standard deviation\n\nAdds new variables (e.g. ang_1_z, il_6_z) representing standardised biomarker values.\n\nWhy It’s Important:\n\nRemoves differences in scale across biomarkers.\nEssential for:\n\nPCA\nClustering\nRegression and classifiers (especially distance-based models)\nFair visual comparisons\n\n\n\ndf_wider &lt;- df_wider %&gt;%\n  mutate(\n    ang_1_z = scale(ang_1)[,1],\n    ang_2_z = scale(ang_2)[,1],\n    azu_z = scale(azu)[,1],\n    ch3l1_z = scale(ch3l1)[,1],\n    il_10_z = scale(il_10)[,1],\n    il_6_z = scale(il_6)[,1],\n    il_8_z = scale(il_8)[,1],\n    ip_10_z = scale(ip_10)[,1],\n    mxa_z = scale(mxa)[,1],\n    stnf_r1_z = scale(stnf_r1)[,1],\n    strem1_z = scale(strem1)[,1],\n    trail_z = scale(trail)[,1]\n  )",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Analysis</span>"
    ]
  },
  {
    "objectID": "Analysis_02.html#create-some-dummy-clinical-data-for-analysis",
    "href": "Analysis_02.html#create-some-dummy-clinical-data-for-analysis",
    "title": "17  Data Analysis",
    "section": "17.6 Create some dummy clinical data for analysis",
    "text": "17.6 Create some dummy clinical data for analysis\nThis block of code generates a simulated outcome variable (dead_or_alive) for testing classification models, using biomarker and HIV status information. This simulates a plausible binary outcome (Alive vs Dead) based on il_8_z (Strong association), MxA (Moderate``association``) and CH3L1 (Moderate``association``) values and a synthetic HIV status (hiv_comb), for downstream ROC and predictive analyses.\n\nAdds a randomly assigned HIV status to each sample (HIV_Negative or HIV_Positive), uniformly distributed.\nCreates a death probability (death_prob) for each individual:\n\nFor HIV-negative, death probability increases sharply with il_8_z (logistic function).\nFor HIV-positive, death probability is flat at 0.5 (i.e., no biomarker effect).\n\nSimulates the actual outcome:\n\nUses runif(n()) &lt; death_prob to probabilistically assign “Dead” or “Alive”.\nForces factor levels to be c(\"Alive\", \"Dead\") so that ROC calculations interpret “Dead” as the positive class.\n\n\n\nset.seed(123)\n\ndf_wider &lt;- df_wider %&gt;%\n  mutate(\n    hiv_comb = as_factor(sample(c(\"HIV_Negative\", \"HIV_Positive\"), \n                                 size = n(), replace = TRUE))\n  ) %&gt;%\n  mutate(\n    death_prob = case_when(\n      # Strong nonlinear IL-8 effect for HIV-negative, plus moderate effects from MxA and CH3L1\n      hiv_comb == \"HIV_Negative\" ~ plogis(3 * il_8_z + 1.0 * mxa_z + 0.6 * ch3l1_z),\n\n      # No IL-8 effect for HIV-positive, but keep moderate effects from MxA and CH3L1\n      hiv_comb == \"HIV_Positive\" ~ plogis(0 + 1.0 * mxa_z + 0.6 * ch3l1_z)\n    ),\n    dead_or_alive = factor(\n      ifelse(runif(n()) &lt; death_prob, \"Dead\", \"Alive\"),\n      levels = c(\"Alive\", \"Dead\")  # ensure ROCit uses \"Dead\" as positive class\n    )\n  )",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Analysis</span>"
    ]
  },
  {
    "objectID": "Analysis_02.html#example-analyses",
    "href": "Analysis_02.html#example-analyses",
    "title": "17  Data Analysis",
    "section": "17.7 Example Analyses",
    "text": "17.7 Example Analyses\n\n17.7.1 ROC Analysis\nThis line of code plots a Receiver Operating Characteristic (ROC) curve for the IL-8 biomarker against the binary outcome dead_or_alive, using the custom ROCit_plot() function.\n\nEvaluates how well IL-8 predicts mortality.\nDisplays a ROC curve and associated AUC.\nVisualises the trade-off between sensitivity and specificity at different thresholds.\n\n\nROCit_plot(data=df_wider,score_col = \"il_8\",class_col = \"dead_or_alive\",color = \"#000000\")+ggtitle(\"IL-8\")\n\n\n\n\n\n\n\n\n\n\n17.7.2 ROC Analysis of more than one marker using patchwork\nThis section compares the performance of IL-8 and IL-10 as mortality predictors using side-by-side ROC plots. By plotting the z-score normalised values, it enables direct visual comparison of biomarkers on the same scale, regardless of their original measurement units or dynamic ranges. This standardisation supports fair interpretation of relative predictive power across different analytes.\n\nROCit_plot(data=df_wider,score_col = \"il_8_z\",class_col = \"dead_or_alive\",color = \"#000000\")+ggtitle(\"IL-8\") +\nROCit_plot(data=df_wider,score_col = \"ch3l1_z\",class_col = \"dead_or_alive\",color = \"#000000\")+ggtitle(\"CH3L1\") +\nROCit_plot(data=df_wider,score_col = \"mxa_z\",class_col = \"dead_or_alive\",color = \"#000000\")+ggtitle(\"MxA\") +\nROCit_plot(data=df_wider,score_col = \"il_10_z\",class_col = \"dead_or_alive\",color = \"#000000\")+ggtitle(\"IL-10\")  \n\n\n\n\n\n\n\n\n\n\n17.7.3 ROC Table\nThis code block computes and displays a table of ROC statistics for one or more biomarkers — IL-8 and IL-10, using their z-score normalised values. Here’s a breakdown:\n\nFunction call: generate_roc_tables() runs ROC analysis on each biomarker and returns a table with AUC, sensitivity, specificity, and thresholds.\nBiomarkers: \"il_8_z\" and \"il_10_z\" are included in this example, but you can add more to the list of biomarkers in the function call.\nSorting: Results are ordered by descending AUC to highlight the stronger predictor.\nAnnotation: A new column Class_Variable = \"Overall\" is added to label this as the non-stratified (overall) analysis. You can modify this if you’re doing complicated sub-analyses.\n\n\nroc_tables_overall &lt;- generate_roc_tables(data = df_wider, biomarkers = c(\"il_8_z\",\"ch3l1_z\",\"mxa_z\",\"il_10_z\"))%&gt;% \n  arrange(-AUC) %&gt;% \n  mutate(Class_Variable = \"Overall\") \n\nkable(roc_tables_overall)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssay\nOutcome\nFailcode\nAUC\nCI_Lower\nCI_Upper\nn_negative\nn_positive\nbiomarker\nClass_Variable\n\n\n\n\nil_8_z\ndead_or_alive\nDead\n0.69\n0.66\n0.71\n800\n720\nil_8_z\nOverall\n\n\nmxa_z\ndead_or_alive\nDead\n0.64\n0.61\n0.67\n800\n720\nmxa_z\nOverall\n\n\nch3l1_z\ndead_or_alive\nDead\n0.63\n0.60\n0.66\n800\n720\nch3l1_z\nOverall\n\n\nil_10_z\ndead_or_alive\nDead\n0.48\n0.45\n0.51\n800\n720\nil_10_z\nOverall\n\n\n\n\n\n\n\n17.7.4 ROC analysis, conditioned by another variable\nThis line generates stratified ROC plots for the biomarker IL-8 (z-score), conditioned on HIV status.\n\nROCit_plot_conditioned() is used to create separate ROC curves by subgroup.\nscore_col = \"il_8_z\": The z-score normalised IL-8 biomarker is the predictor.\nclass_col = \"dead_or_alive\": The binary outcome variable (Alive/Dead).\nconditioning = \"hiv_comb\": ROC curves are generated separately for HIV_Negative and HIV_Positive groups.\n\nStratification reveals whether a biomarker performs differently in subgroups. Using z-scores allows meaningful comparison across subgroups by standardising the measurement scale.\n\nROCit_plot_conditioned(df_wider,score_col = \"il_8_z\",class_col = \"dead_or_alive\",conditioning = \"hiv_comb\")\n\n\n\n\n\n\n\n\n\n\n17.7.5 Metamodel\nA logistic regression model (meta_model_full) is fitted to predict mortality (dead_or_alive) using:\n\n12 z-score standardised biomarkers (e.g., il_8_z, il_10_z, trail_z)\nHIV status (hiv_comb)\n\nThis multivariable model estimates the log-odds of death for each one standard deviation increase in biomarker concentration, controlling for HIV status.\nBy using z-scores:\n\nCoefficients are directly comparable across biomarkers (this is crucially important!)\nEffect sizes are interpretable as change in risk per SD increase.\n\nThis analysis helps identify which biomarkers contribute most independently to predicting mortality.\n\nmeta_model_full &lt;- glm(factor(dead_or_alive) ~ ang_1_z + ang_2_z + azu_z + ch3l1_z + il_10_z + il_6_z + il_8_z + ip_10_z + mxa_z + stnf_r1_z + strem1_z + trail_z + hiv_comb, \n                 data = df_wider, family = binomial, na.action = na.exclude)\n\n\nsummary(meta_model_full)\n\n\nCall:\nglm(formula = factor(dead_or_alive) ~ ang_1_z + ang_2_z + azu_z + \n    ch3l1_z + il_10_z + il_6_z + il_8_z + ip_10_z + mxa_z + stnf_r1_z + \n    strem1_z + trail_z + hiv_comb, family = binomial, data = df_wider, \n    na.action = na.exclude)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)          -0.172417   0.082490  -2.090   0.0366 *  \nang_1_z              -0.093873   0.059177  -1.586   0.1127    \nang_2_z               0.060401   0.060984   0.990   0.3220    \nazu_z                -0.041166   0.058395  -0.705   0.4808    \nch3l1_z               0.536474   0.064624   8.301   &lt;2e-16 ***\nil_10_z               0.009881   0.060369   0.164   0.8700    \nil_6_z                0.001440   0.059054   0.024   0.9805    \nil_8_z                0.853895   0.068121  12.535   &lt;2e-16 ***\nip_10_z               0.028781   0.058821   0.489   0.6246    \nmxa_z                 0.674302   0.066969  10.069   &lt;2e-16 ***\nstnf_r1_z             0.017600   0.059680   0.295   0.7681    \nstrem1_z             -0.126021   0.061325  -2.055   0.0399 *  \ntrail_z               0.001614   0.058715   0.027   0.9781    \nhiv_combHIV_Positive  0.161612   0.117706   1.373   0.1697    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2103.0  on 1519  degrees of freedom\nResidual deviance: 1724.5  on 1506  degrees of freedom\nAIC: 1752.5\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n17.7.6 Interaction Model: Biomarkers × HIV Status\nA logistic regression model is fitted to explore whether the effects of important biomarkers on mortality differ by HIV status. This tests if the prognostic value of biomarkers changes depending on whether a person is HIV-positive or HIV-negative. Significant interaction terms indicate that HIV status modifies the effect of the biomarker on mortality.\nThis includes:\n\nMain effects of mxa_z, il_8_z, and hiv_comb\nInteraction terms:\n\nmxa_z:hiv_comb\nil_8_z:hiv_comb\n\n\n\nmeta_model_marker_int_hiv &lt;- glm(factor(dead_or_alive) ~ \n                          mxa_z * hiv_comb+ \n                          il_8_z * hiv_comb+\n                          ch3l1_z * hiv_comb  ,\n                           \n                        family = binomial, data = df_wider, na.action = na.exclude)\n\nsummary(meta_model_marker_int_hiv)\n\n\nCall:\nglm(formula = factor(dead_or_alive) ~ mxa_z * hiv_comb + il_8_z * \n    hiv_comb + ch3l1_z * hiv_comb, family = binomial, data = df_wider, \n    na.action = na.exclude)\n\nCoefficients:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                   0.02702    0.10646   0.254 0.799625    \nmxa_z                         0.88036    0.11333   7.768 7.98e-15 ***\nhiv_combHIV_Positive         -0.02690    0.13606  -0.198 0.843293    \nil_8_z                        2.73653    0.19932  13.729  &lt; 2e-16 ***\nch3l1_z                       0.41338    0.10846   3.811 0.000138 ***\nmxa_z:hiv_combHIV_Positive    0.01381    0.15396   0.090 0.928531    \nhiv_combHIV_Positive:il_8_z  -2.71450    0.21513 -12.618  &lt; 2e-16 ***\nhiv_combHIV_Positive:ch3l1_z  0.34541    0.14589   2.368 0.017899 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2103.0  on 1519  degrees of freedom\nResidual deviance: 1446.3  on 1512  degrees of freedom\nAIC: 1462.3\n\nNumber of Fisher Scoring iterations: 6\n\n\nThe substantial drop in AIC from 1752 (without interaction) to 1462 (with interaction) suggests that including HIV interaction terms greatly improves the model fit and better explains the variance in the data.\nInterpretation:\n\nLower AIC indicates a better-fitting model, penalised for complexity.\nA decrease of &gt;10 is generally considered strong evidence in favour of the more complex model.\nHere, the reduction of around 300 points is very strong evidence that:\n\nThe prognostic effects of IL-8 and MXA differ significantly by HIV status.\n\n\nThis supports including interaction terms in subsequent modelling or stratified analyses.\n\n\n17.7.7 PPV/NPV charts\nThis code block generates Positive Predictive Value (PPV) and Negative Predictive Value (NPV) curves for the biomarker IL-8 across three groups, using plot_ppv() and combining the outputs with patchwork.\nThese plots allow visual comparison of diagnostic utility (PPV and NPV across thresholds) of IL-8:\n\nIn the full population\nStratified by HIV status\nBy conditioning on HIV, the analysis highlights whether predictive value changes by subgroup, supporting the interaction findings in the logistic models.\n\n\nplot_ppv(df_wider, \"dead_or_alive\", \"il_8_z\", title = \"IL-8\",failcode = \"Dead\")+\nplot_ppv(filter(df_wider,hiv_comb==\"HIV_Positive\"), \"dead_or_alive\", \"il_8_z\", title = \"IL-8 (HIV Positive)\",failcode = \"Dead\")+\n  plot_ppv(filter(df_wider,hiv_comb==\"HIV_Negative\"), \"dead_or_alive\", \"il_8_z\", title = \"IL-8 (HIV Negative)\",failcode = \"Dead\")\n\n\n\n\n\n\n\n\nIt’s clear in this simulation that HIV status is a very important factor with relation to the diagnostic utility of IL-8.\n\n\n17.7.8 Calculate confusion Matrix based on a chosen threshold\nThis line of code runs a confusion matrix analysis for the subset of participants who are HIV-negative, using a decision rule based on the PPV/NPV data for the IL-8 z-score\n\nFilters the data to include only HIV-negative individuals.\nApplies the rule: il_8_z &gt; 0.2 → Predicts “dead”, otherwise “alive”.\nCreates a synthetic classification variable (synthetic_risk) from that rule.\nCompares predictions to actual outcomes (dead_or_alive) using a confusion matrix.\nReturns a tibble of metrics:\n\nSensitivity, Specificity\nPositive Predictive Value (PPV), Negative Predictive Value (NPV)\nAccuracy and confidence bounds\nMcNemar’s test p-value\nTrue/false positive and negative counts\n\nThis lets you quantify performance of a rule-based classifier at a specific threshold, which complements the continuous-threshold analyses like ROC and PPV curves.\n\n\nkable(compute_conf_matrix_stats(data = filter(df_wider,hiv_comb==\"HIV_Negative\"),condition = \"il_8_z&gt;0.2\",outcome_col = \"dead_or_alive\"),digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncondition\nPPV\nNPV\nsensitivity\nspecificity\naccuracy\naccuracylower\naccuracyupper\nbalancedaccuracy\nmcnemarp\ntrue_neg\nfalse_neg\nfalse_pos\ntrue_pos\n\n\n\n\nil_8_z&gt;0.2\n0.83\n0.75\n0.65\n0.89\n0.78\n0.75\n0.81\n0.77\n0\n374\n46\n124\n230\n\n\n\n\n\n\n\n17.7.9 Identifying clusters via Principal Components Analysis\nThis section conducts a Principal Component Analysis (PCA) on the z-scored biomarker panel to explore the underlying structure of the data. It evaluates how much of the overall variation is captured by each principal component and assesses the potential for dimensionality reduction. While all biomarkers were already standardised, PCA was applied with additional scaling for consistency. The output provides insight into the dominant patterns across biomarkers and helps inform multivariate modelling strategies.\nFirst we will normalise all the assays using the median method. In the real world we might want to test this first for each assay as shown above. The summary shows how much of the total variance can be explained by the various principal components.\n\ndf.pca&lt;-prcomp(dplyr::select(df_wider,ang_1_z:trail_z),scale. = T)\ndf.pca.summary&lt;-summary(df.pca)\ndf.pca.summary\n\nImportance of components:\n                          PC1     PC2     PC3     PC4     PC5     PC6     PC7\nStandard deviation     1.2912 1.04619 1.02966 1.01153 1.00482 0.97864 0.96362\nProportion of Variance 0.1389 0.09121 0.08835 0.08527 0.08414 0.07981 0.07738\nCumulative Proportion  0.1389 0.23013 0.31848 0.40375 0.48789 0.56770 0.64508\n                           PC8     PC9    PC10    PC11    PC12\nStandard deviation     0.94969 0.93327 0.92116 0.91541 0.89422\nProportion of Variance 0.07516 0.07258 0.07071 0.06983 0.06664\nCumulative Proportion  0.72024 0.79282 0.86353 0.93336 1.00000\n\n\nThis can be visualised by plotting:\n\nProportion of variance explained by each principal component (PC), showing how much unique information each PC contributes.\nCumulative variance explained, helping to assess how many components are needed to retain most of the dataset’s variability.\n\nTogether, these plots inform decisions on dimensionality reduction—e.g., whether a smaller number of components could summarise the variance of the biomarker panel effectively.\n\ndf.importance&lt;-tibble(pc = 1:length(df.pca.summary$importance[1,]),\n                      standard.deviation = df.pca.summary$importance[1,],\n                      prop.of.variance = df.pca.summary$importance[2,],\n                      cumulative.variance = df.pca.summary$importance[3,]\n)\n\nggplot(df.importance,aes(pc,prop.of.variance))+geom_bar(stat=\"identity\") +\nggplot(df.importance,aes(pc,cumulative.variance))+geom_bar(stat=\"identity\")\n\n\n\n\n\n\n\n\nIt looks like only a little of the variance (~15%) is explained by the first principal component. This is probably unsurprising given that the data are simulated and don’t have any real patterns encoded. Further analysis can be made easier by adding the PC data back to the main data.\n\ndf_wider&lt;- bind_cols(df_wider,as.data.frame(df.pca$x))\n\nThis PCA biplot shows the distribution of specimens across the first two principal components (PC1 and PC2), with points coloured and shaped by outcome (dead_or_alive).\n\nPC1 explains 13.9% and PC2 explains 9% of the total variance, together capturing just 23% (See above)\nEach point represents a specimen based on its transformed cytokine profile (z-scores).\nEllipses represent the 95% confidence regions for each class.\nThere is substantial overlap between the alive and dead groups, though some separation is visible along both PC1, suggesting mild discriminatory power from the composite cytokine signature.\n\nThis view complements the univariate analyses by illustrating how cytokine expression patterns cluster across outcome groups in multivariate space.\n\nggplot(df_wider,aes(PC1,PC2,color=dead_or_alive,label=sample,pch=dead_or_alive))+\n  geom_point(alpha=0.4,size=1) +\n  stat_ellipse(geom=\"polygon\", aes(fill = dead_or_alive), alpha = 0.2, show.legend = FALSE, level = 0.95)+\n  xlab(label = str_c(\"PC1 (\",round(100*df.importance$prop.of.variance[1],2),\" %)\",sep = \"\"))+\n  ylab(label = str_c(\"PC2 (\",round(100*df.importance$prop.of.variance[2],2),\" %)\",sep = \"\"))+\n  theme(aspect.ratio=df.importance$prop.of.variance[2]/df.importance$prop.of.variance[1],\n                  legend.position = \"bottom\"\n)\n\n\n\n\n\n\n\n\n\n\n17.7.10 Linear Regression to identify prognostic Principal Components\nA logistic regression can be fitted using the first 12 principal components (PC1–PC12) as predictors of mortality (dead_or_alive), aiming to identify components carrying diagnostic or prognostic signal.\n\nsummary(\n  glm(data = df_wider,formula = dead_or_alive ~ PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+PC11+PC12,family = \"binomial\")\n)\n\n\nCall:\nglm(formula = dead_or_alive ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + \n    PC7 + PC8 + PC9 + PC10 + PC11 + PC12, family = \"binomial\", \n    data = df_wider)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.093126   0.058758  -1.585  0.11299    \nPC1          0.244995   0.046261   5.296 1.18e-07 ***\nPC2         -0.663058   0.062068 -10.683  &lt; 2e-16 ***\nPC3          0.139522   0.057400   2.431  0.01507 *  \nPC4          0.256308   0.058335   4.394 1.11e-05 ***\nPC5         -0.332554   0.059151  -5.622 1.89e-08 ***\nPC6         -0.721157   0.065909 -10.942  &lt; 2e-16 ***\nPC7          0.002681   0.061186   0.044  0.96506    \nPC8         -0.014150   0.062224  -0.227  0.82012    \nPC9         -0.174818   0.063749  -2.742  0.00610 ** \nPC10         0.037276   0.063781   0.584  0.55892    \nPC11        -0.207031   0.065107  -3.180  0.00147 ** \nPC12        -0.452560   0.068142  -6.641 3.11e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2103.0  on 1519  degrees of freedom\nResidual deviance: 1726.4  on 1507  degrees of freedom\nAIC: 1752.4\n\nNumber of Fisher Scoring iterations: 4\n\n\nModel findings:\n\nThe model explains substantial variation in the outcome (AIC = 2827.1, reduced from the null model’s 3100.8).\nStatistically significant PCs:\n\nPC1, PC2, PC4, PC5, PC6 and PC12 showed significant associations (p &lt; 1e-5).\n\nMost influential components:\n\nPC2 and PC6 show strong negative associations, potentially identifying protective biomarkers\n\n\n\nggplot(df_wider,aes(PC2,PC6,color=dead_or_alive,label=sample,pch=dead_or_alive))+\n  geom_point(alpha=0.4,size=1) +\n  stat_ellipse(geom=\"polygon\", aes(fill = dead_or_alive), alpha = 0.2, show.legend = FALSE, level = 0.95)+\n  xlab(label = str_c(\"PC2 (\",round(100*df.importance$prop.of.variance[2],2),\" %)\",sep = \"\"))+\n  ylab(label = str_c(\"PC6 (\",round(100*df.importance$prop.of.variance[6],2),\" %)\",sep = \"\"))+\n  theme(aspect.ratio=df.importance$prop.of.variance[2]/df.importance$prop.of.variance[1],\n                  legend.position = \"bottom\"\n)\n\n\n\n\n\n\n\n\nThese results suggest that multiple PCs contain diagnostically useful signal, and that unsupervised dimensionality reduction preserves meaningful information relevant to mortality classification.\n\n\n17.7.11 Interpreting PCs with loadings plots\nTo understand what each principal component represents, loadings plots are generated. These show how strongly each original biomarker contributes to a given principal component.\n\nPC1 Loadings: This component captures the dominant pattern of variance across the biomarker panel. Large positive or negative loadings indicate biomarkers that are highly correlated with this axis.\nPC4 Loadings: Although less dominant in variance explained, PC4 was strongly associated with mortality in the regression model. Loadings for PC4 help identify which specific biomarkers drive this mortality-associated axis.\n\nBy plotting the rotation matrix (PCA loadings), we visually inspect which biomarkers are most influential in each component. This guides interpretation of biological or diagnostic relevance.\n\ndf.pca %&gt;%\n    tidy(matrix = \"rotation\") %&gt;% \n    filter(PC==\"2\" | PC==\"6\"  ) %&gt;% \n    ggplot(aes(column,value)) +\n  geom_bar(stat=\"identity\")+\n    facet_grid(PC~.)+\n  coord_flip()\n\n\n\n\n\n\n\n\n\nThe bars pointing left or right show the relative contribution of that biomarker to either the positive (rightward) or negative (leftward) values of the PC.\nImportant to remember that PCA space you can flip the axis 180° without changing the underlying geometry, so “positive” vs “negative” loadings don’t carry any inherent meaning. What matters are the relative magnitudes of the loadings and the pattern of which variables move together or in opposition, not whether they’re plotted above or below zero.\nRemember that this is a simulated data set, so these patterns are also not real.\n\n\n\n17.7.12 ROC analysis of PC associations with outcomes\nYou can also use PCs as the input to a ROC analysis.\nIn this case, a multi-marker test fails to improve on a single marker test - Again please remember that this is a simulated clinical data set.\n\nROCit_plot(data=df_wider,score_col = \"PC1\",class_col = \"dead_or_alive\",color = \"#000000\")+ggtitle(\"PC1\") +\nROCit_plot(data=df_wider,score_col = \"PC4\",class_col = \"dead_or_alive\",color = \"#000000\")+ggtitle(\"PC4\") +\nROCit_plot(data=df_wider,score_col = \"PC8\",class_col = \"dead_or_alive\",color = \"#000000\")+ggtitle(\"PC8\") +\n  ROCit_plot(data=df_wider,score_col = \"PC5\",class_col = \"dead_or_alive\",color = \"#000000\",negate_score = T)+ggtitle(\"PC5\") +  \nROCit_plot(data=df_wider,score_col = \"PC9\",class_col = \"dead_or_alive\",color = \"#000000\",negate_score = T)+ggtitle(\"PC9\") +\n  ROCit_plot(data=df_wider,score_col = \"PC11\",class_col = \"dead_or_alive\",color = \"#000000\")+ggtitle(\"PC11\")\n\n\n\n\n\n\n\n\n\n\n17.7.13 Mahalanobis Distance for Outlier Detection or Risk Scoring\nThis approach explores profile-wide variance in the PCA space to identify individuals whose overall biomarker profile deviates from the “normal” (control) pattern.\nWe compute a Mahalanobis distance for each sample, quantifying how far its position in PCA space lies from the centroid of the “Alive” group (i.e., survivors). This reflects multivariate deviation across all principal components.\nMethod:\n\nControls: Used only the Alive group to compute:\n\nThe centroid (mean vector of PCs).\nThe covariance matrix of PCs.\n\nAll samples: Computed Mahalanobis distance from that centroid using:\n\\[D^2 = (x - \\mu)^\\top \\Sigma^{-1} (x - \\mu)\\]\nwhere:\nx is the PC vector for an individual sample,\nμ is the control (Alive) group mean vector\nΣ is the covariance matrix of controls.\nThis can now act as a multivariate anomaly score, potentially highlighting high-risk profiles.\n\n\n# Compute covariance matrix of controls\ncontrol_pca &lt;- df_wider %&gt;%\n  filter(dead_or_alive == \"Alive\") %&gt;%\n  select(starts_with(\"PC\"))\n\ncov_matrix &lt;- cov(control_pca, use = \"complete.obs\")\n\n# Compute Mahalanobis distance from control centroid\ndf_wider &lt;- df_wider %&gt;%\n  mutate(mahalanobis_distance = mahalanobis(select(., starts_with(\"PC\")), colMeans(control_pca, na.rm = TRUE), cov_matrix))\n\nggplot(df_wider, aes(x = log(mahalanobis_distance), fill = dead_or_alive)) +\n  geom_density(alpha = 0.5) +\n  ggtitle(\"Distance from Control Centroid in PCA Space\")\n\n\n\n\n\n\n\n\nTo assess its predictive utility, you might plot a ROC curve\n\nROCit_plot(data=df_wider,score_col = \"mahalanobis_distance\",class_col = \"dead_or_alive\",color = \"#000000\")+ggtitle(\"mahalanobis_distance\")\n\n\n\n\n\n\n\n\nand also fit a logistic regression\n\nsummary(glm(dead_or_alive ~ log(mahalanobis_distance), data = df_wider, family = \"binomial\"))\n\n\nCall:\nglm(formula = dead_or_alive ~ log(mahalanobis_distance), family = \"binomial\", \n    data = df_wider)\n\nCoefficients:\n                          Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)               -2.02252    0.23384  -8.649   &lt;2e-16 ***\nlog(mahalanobis_distance)  0.78761    0.09354   8.420   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2103.0  on 1519  degrees of freedom\nResidual deviance: 2025.9  on 1518  degrees of freedom\nAIC: 2029.9\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n17.7.14 Marker Importance and Selection\nSo far, we’ve explored both individual biomarker effects and composite multivariate structures (e.g. via PCA and Mahalanobis distance) for predicting mortality. While informative, these approaches do not explicitly rank biomarkers by their predictive relevance.\nTo refine the model and move toward a parsimonious and interpretable diagnostic signature, we next assess:\n\nWhich markers contribute most to predictive performance?\nWhich subset of markers can be used without sacrificing accuracy?\n\nThis step focuses on feature importance and selection, key concepts in diagnostic biomarker development and model generalisation.\n\n\n17.7.15 Variable Selection\nThe justification for a variable selection approach is that it:\n\nReduces overfitting and improves generalisability\nLowers cost and complexity for downstream assays\nEnhances interpretability and potential biological insight\n\nApproaches Used for variable selection\nWe apply two complementary techniques:\nBoruta Feature Selection\n\nA wrapper algorithm built around random forests.\nCompares original variables to their permuted (shadow) counterparts.\nRetains variables that show consistently higher importance than the best random feature.\nWell suited for highly-dimensional and noisy data.\n\nRecursive Feature Elimination (RFE)\n\nA greedy backward selection method.\nIteratively removes the least important features based on model weight (e.g., in logistic regression or random forest).\nEfficient in identifying a minimal optimal feature subset.\n\n\n\n17.7.16 Enhancing Clinical Relevance: Adding Demographic and Clinical Variables\nTo reflect more practical diagnostic settings, we extended the dataset to include additional demographic and clinical predictors:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nsex\nRandomly assigned binary variable (Male/Female), ~50:50 split\n\n\nage\nUniformly distributed between 18 and 87\n\n\ntemp\nSimulated body temperature, slightly elevated in patients who died\n\n\nrespiratory_rate\nSkewed towards higher values in the Dead group to reflect increased physiological stress\n\n\n\nThese variables complement the biomarker panels and allow exploration of combined models that integrate clinical indicators with molecular signatures.\nOne of the strengths of Boruta and Random Forest-based approaches lies in their ability to handle a plurality of variable types. This includes:\n\nContinuous variables (e.g. cytokine Z-scores, temperature, age)\nCategorical/factor variables (e.g. sex, HIV status)\n\nThis flexibility makes these methods particularly well-suited for real-world clinical data, where predictive models often need to integrate biological markers, demographic traits, and physiological indicators in a unified framework without requiring extensive pre-processing or transformation.\n\nset.seed(42)\n\ndf_wider &lt;- df_wider %&gt;%\n  mutate(\n    # Sex: 50/50 Male/Female\n    sex = sample(c(\"Male\", \"Female\"), n(), replace = TRUE),\n\n    # Age: uniformly between 18 and 87\n    age = sample(18:87, n(), replace = TRUE),\n\n    # Temperature: higher in Dead group\n    temp = case_when(\n      dead_or_alive == \"Alive\" ~ pmin(pmax(rnorm(n(), mean = 37.2, sd = 0.4), 36.2), 40.3),\n      dead_or_alive == \"Dead\"  ~ pmin(pmax(rnorm(n(), mean = 37.7, sd = 0.5), 36.2), 40.3)\n    ),\n\n    # Respiratory rate: skewed lower in Alive, higher but still rare in Dead\n    respiratory_rate = case_when(\n      dead_or_alive == \"Alive\" ~ round(pmin(rbeta(n(), 2, 10) * 45 + 25, 70)),\n      dead_or_alive == \"Dead\"  ~ round(pmin(rbeta(n(), 3, 11) * 45 + 25, 70))\n    )\n  )\n\n\n\n17.7.17 Boruta Analysis\nThis chunk initiates a Boruta variable selection process to identify important predictors of mortality (dead_or_alive) using a wrapper around random forests.\n\nIncluded variables: A mix of biomarkers (e.g. ang_1, il_8, trail), demographic (age, sex), and clinical measures (temp, respiratory_rate, hiv_comb).\nStrength: Boruta can handle both continuous and categorical predictors.\nOutcome: It returns a ranking of features as Confirmed, Tentative, or Rejected based on importance relative to shadow variables.\n\nThis sets the stage for rigorous feature importance analysis, considering both biological and clinical context.\n\n#BORUTA\nset.seed(1232131)\nboruta.train &lt;- Boruta(dead_or_alive ~\n  ang_1+\n  ang_2+\n  azu+\n  ch3l1+\n  il_10+\n  il_6+\n  il_8+\n  ip_10+\n  mxa+\n  stnf_r1+\n  strem1+\n  trail+\n  hiv_comb+\n  sex+\n  age+\n  temp+\n  respiratory_rate,\n        data = df_wider, doTrace = 2)\n\nThe output of print(boruta.train) will look something like this\n\nprint(boruta.train)\n\nBoruta performed 58 iterations in 26.99609 secs.\n 6 attributes confirmed important: ch3l1, hiv_comb, il_8, mxa,\nrespiratory_rate and 1 more;\n 11 attributes confirmed unimportant: age, ang_1, ang_2, azu, il_10 and\n6 more;\n\n\n\nConfirmed important: Variables that were consistently more important than the best shadow (random) variable, indicating strong predictive value.\nIncludes several cytokines and all added demographic/clinical variables.\nConfirmed unimportant: Variables with performance consistently worse than or comparable to noise—likely not informative in this model.\nTentative: (If present) variables that require further resolution using TentativeRoughFix() or similar post-processing.\n\nAfter running TentativeRoughFix(), Boruta finalises decisions for previously “tentative” variables by reassessing their importance using the median rather than the mean importance. This approach helps resolve ambiguous cases by reducing the influence of skewed distributions or outliers, often leading to a clearer classification as either confirmed or rejected.\n\nset.seed(1232131)\nfinal.boruta &lt;- TentativeRoughFix(boruta.train)\n\nWarning in TentativeRoughFix(boruta.train): There are no Tentative attributes!\nReturning original object.\n\nprint(final.boruta)\n\nBoruta performed 58 iterations in 26.99609 secs.\n 6 attributes confirmed important: ch3l1, hiv_comb, il_8, mxa,\nrespiratory_rate and 1 more;\n 11 attributes confirmed unimportant: age, ang_1, ang_2, azu, il_10 and\n6 more;\n\n\nThis chunk extracts and ranks the variable importance results from the finalised Boruta model.\n\nboruta.df &lt;- attStats(final.boruta)\nboruta.df %&gt;% mutate(marker = rownames(.)) %&gt;% select (marker, everything())  %&gt;% arrange(-meanImp)\n\n                           marker     meanImp   medianImp     minImp\ntemp                         temp 64.23040355 65.85575753 51.4601672\nil_8                         il_8 41.35344492 42.04428610 31.4291703\nmxa                           mxa 26.34929291 27.01609627 20.6327883\nhiv_comb                 hiv_comb 22.56907230 23.76874268 15.5292412\nrespiratory_rate respiratory_rate 18.98502149 19.08442753 14.8500932\nch3l1                       ch3l1 15.70375900 15.80021514 11.5464317\nstnf_r1                   stnf_r1  1.14679355  1.03330312 -1.3285477\nstrem1                     strem1  0.92215204  0.78664909 -1.7265029\nazu                           azu  0.89763240  0.94523612 -1.7968908\nang_2                       ang_2  0.75928496  0.72231259 -2.1193519\ntrail                       trail  0.54013142  0.25399909 -0.4974893\nage                           age  0.51412678  0.32117635 -0.7481246\nang_1                       ang_1  0.47594421  0.09520428 -1.9640355\nil_10                       il_10  0.16327495  0.34528929 -1.4862504\nip_10                       ip_10 -0.01707495 -0.12250408 -1.0176148\nsex                           sex -0.03927419 -0.10068697 -2.1891422\nil_6                         il_6 -1.07400295 -0.77405886 -2.4674168\n                       maxImp   normHits  decision\ntemp             73.489578810 1.00000000 Confirmed\nil_8             49.598603240 1.00000000 Confirmed\nmxa              29.312988700 1.00000000 Confirmed\nhiv_comb         28.393989871 1.00000000 Confirmed\nrespiratory_rate 23.952158193 1.00000000 Confirmed\nch3l1            19.039376151 1.00000000 Confirmed\nstnf_r1           3.196259969 0.22413793  Rejected\nstrem1            4.200867701 0.22413793  Rejected\nazu               3.419481523 0.27586207  Rejected\nang_2             3.009769641 0.06896552  Rejected\ntrail             2.014600507 0.00000000  Rejected\nage               1.777077005 0.00000000  Rejected\nang_1             4.221019066 0.01724138  Rejected\nil_10             1.404145906 0.00000000  Rejected\nip_10             2.164345250 0.00000000  Rejected\nsex               1.667814589 0.03448276  Rejected\nil_6              0.006263453 0.00000000  Rejected\n\nkable(boruta.df,digits = 2) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmeanImp\nmedianImp\nminImp\nmaxImp\nnormHits\ndecision\n\n\n\n\nrespiratory_rate\n18.99\n19.08\n14.85\n23.95\n1.00\nConfirmed\n\n\ntemp\n64.23\n65.86\n51.46\n73.49\n1.00\nConfirmed\n\n\nage\n0.51\n0.32\n-0.75\n1.78\n0.00\nRejected\n\n\nsex\n-0.04\n-0.10\n-2.19\n1.67\n0.03\nRejected\n\n\nhiv_comb\n22.57\n23.77\n15.53\n28.39\n1.00\nConfirmed\n\n\ntrail\n0.54\n0.25\n-0.50\n2.01\n0.00\nRejected\n\n\nstrem1\n0.92\n0.79\n-1.73\n4.20\n0.22\nRejected\n\n\nstnf_r1\n1.15\n1.03\n-1.33\n3.20\n0.22\nRejected\n\n\nmxa\n26.35\n27.02\n20.63\n29.31\n1.00\nConfirmed\n\n\nip_10\n-0.02\n-0.12\n-1.02\n2.16\n0.00\nRejected\n\n\nil_8\n41.35\n42.04\n31.43\n49.60\n1.00\nConfirmed\n\n\nil_6\n-1.07\n-0.77\n-2.47\n0.01\n0.00\nRejected\n\n\nil_10\n0.16\n0.35\n-1.49\n1.40\n0.00\nRejected\n\n\nch3l1\n15.70\n15.80\n11.55\n19.04\n1.00\nConfirmed\n\n\nazu\n0.90\n0.95\n-1.80\n3.42\n0.28\nRejected\n\n\nang_2\n0.76\n0.72\n-2.12\n3.01\n0.07\nRejected\n\n\nang_1\n0.48\n0.10\n-1.96\n4.22\n0.02\nRejected\n\n\n\n\n\n\nThe table includes:\n\nmeanImp: mean importance across iterations.\nmedianImp: median importance.\ndecision: final call by Boruta (Confirmed, Rejected, or previously Tentative).\n\n\nThis provides a clear and interpretable ranking of predictors contributing to classification performance.\n\n17.7.17.1 Boruta Variables Confirmed Chart\nThis chunk creates a visual summary of how consistently important each variable was across random forest iterations, with statistical robustness reflected in the spread and medians of their boxplots. This allows intuitive inspection of variable reliability and influence.\nSome calculations have to be done for this\n\nExtracts raw importance history from the Boruta model (ImpHistory), storing importance scores across iterations.\nTransforms data to long format using pivot_longer(), with one row per (marker, iteration) pair.\nAdds final decisions (Confirmed, Rejected, Tentative) by joining with finalDecision.\nCalculates marker-wise median importance to guide ordering in the plot.\nCreates a boxplot of importance scores per marker, coloured by Boruta’s decision.\n\n\nboruta.imp&lt;-as_tibble(final.boruta$ImpHistory, .name_repair = \"minimal\")\n\nboruta.imp&lt;-boruta.imp%&gt;% \n  pivot_longer(cols = 1:13,names_to = \"marker\",values_to = \"importance\")\n\nfinal_decision_tbl &lt;- tibble(\n  marker = names(final.boruta$finalDecision),\n  decision = final.boruta$finalDecision\n)\n\nboruta.imp &lt;- boruta.imp %&gt;%\n  left_join(final_decision_tbl, by = \"marker\")\n\nboruta.imp %&gt;%\n  group_by(marker) %&gt;%\n  mutate(median_imp = median(importance, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  mutate(marker = fct_reorder(marker, median_imp)) %&gt;%\n  ggplot(aes(x = marker, y = importance,fill=decision)) +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n17.7.18 Recursive Feature Elimination (RFE) on Boruta-selected variables\nThis chunk applies Recursive Feature Elimination (RFE) to the Boruta-confirmed variables to identify the most parsimonious subset of predictors for classifying mortality (dead_or_alive).\nThis step complements Boruta by ranking the predictive power of confirmed features and identifying a minimal, high-performing subset through repeated cross-validation, which ensures that feature selection is robust to sampling variation and generalises well to unseen data.\nHere, we also implement Parallel computing by dynamically detecting available CPU cores and registering a parallel backend to speed up RFE. It’s possible to run RFE without parallel approaches, but it will take longer.\n\nset.seed(1232131)\n\n# Get the confirmed variables list from Boruta\nconfirmed_vars &lt;- getSelectedAttributes(final.boruta, withTentative = FALSE)\n\n\n# Subset to only Boruta-confirmed vars\ndf_wider_rfe &lt;- df_wider %&gt;%\n  select(all_of(confirmed_vars),dead_or_alive)\n\n# Detect available cores and reserve 1–2 for the OS\nn_cores &lt;- parallel::detectCores() - 1\ncl &lt;- makeCluster(n_cores)\nregisterDoParallel(cl)\n\n# Set parameters for RFE\ncontrol &lt;- rfeControl(\n  functions = rfFuncs,\n  method = \"cv\",        # or \"repeatedcv\", \"boot\", etc.\n  number = 20,           # number of folds - increase this when using real data 10-15 minimum\n  verbose = FALSE,\n  allowParallel = TRUE\n)\n\n# Run your RFE\nrfe_result &lt;- rfe(\n  x = df_wider_rfe %&gt;% select(-all_of(\"dead_or_alive\")),\n  y = df_wider_rfe$dead_or_alive,\n  sizes = seq(1, length(confirmed_vars), by = 1),\n  rfeControl = control\n)\n\n# Always stop the cluster afterward\nstopCluster(cl)\n\n\n17.7.18.1 RFE Results - Charts\nThis plot visualises the relationship between the number of features selected and the model’s cross-validated accuracy. Each point represents a different subset size tested by RFE, helping to identify the smallest number of predictors that yields near-maximum performance.\n\nggplot(rfe_result, aes(Variables, Accuracy)) + geom_point(size = 2)\n\n\n\n\n\n\n\n\nThis plot illustrates how predictive accuracy varies with the number of selected features, using cross-validation.\n\nAccuracy peaks early (with just 3–4 variables), then fluctuates slightly as more features are added.\nThe maximum accuracy hovers around 0.8, suggesting diminishing returns beyond the top few variables.\n\nThis underscores the value of recursive feature elimination (RFE) in identifying a parsimonious biomarker set that performs nearly as well as the full set. This is critical for developing practical, cost-effective diagnostics.\nThe accuracy at each point in the RFE plot doesn’t reflect a single fixed model, but rather the average performance across many different combinations of variables of that size.\nSo when the plot shows a peak at 3 variables, it means that:\n\nThe best-performing 3-variable combinations achieved that level of accuracy.\nIt does not imply a single unique 3-marker model, rather it’s a summary of the cross-validated performance across all possible subsets of that size, as sampled during RFE.\n\nThis is especially useful for understanding the information density of the feature set:\n\nA few variables already carry most of the predictive power.\nAdding more may help a little, but with diminishing returns.\n\nTo identify which variables perform best in the three variable combinations, you can use this chunk :\n\nkable(rfe_result$variables %&gt;%\n     filter(Variables == 5) %&gt;%\n     count(var, sort = TRUE))\n\n\n\n\nvar\nn\n\n\n\n\nhiv_comb\n20\n\n\nil_8\n20\n\n\nmxa\n20\n\n\ntemp\n20\n\n\nrespiratory_rate\n17\n\n\nch3l1\n3\n\n\n\n\n\nThis result shows that when selecting 5 variables (just as an example), the RFE process consistently (in all 20 resampling iterations) selected hiv_comb, il_8, MxA and temp, which indicates that these four markers are robust predictors of the outcome when the model is constrained to five inputs. In 16 resamplings, the fifth marker was respiratory rate and in the remaining 4, that was replaced with CH3L1. This kind of trade-off can highlight how some markers behave less consistently and may therefore be less robust predictors.\nIn the model above we can achieve quite high accuracy with a three-marker model.\n\nkable(rfe_result$variables %&gt;%\n     filter(Variables == 3) %&gt;%\n     count(var, sort = TRUE)) \n\n\n\n\nvar\nn\n\n\n\n\nhiv_comb\n20\n\n\nil_8\n20\n\n\ntemp\n20\n\n\n\n\n\nTechnically this does not imply that this specific trio is the best model, but that they form a core signal under the RFE model.\nIt’s still highly likely that they will constitute the best model, but In production, you’d still want to evaluate this 3-variable model’s PPV, sensitivity, etc., and potentially validate it on external data. Note that the addition of MxA to create a four-marker model increases the overall accuracy (see RFE results) but how you choose the final model should be conditioned not only on accuracy. For many contexts it may be more useful to look at PPV or NPV.\n\n\n17.7.18.2 GLM to confirm performance using a different approach\nWe can use a logistic regression to model the three markers and their associations with the outcome.\n\nfinal_2var_model &lt;- glm(dead_or_alive ~ il_8 + hiv_comb + temp ,\n                    data = df_wider, \n                    family = binomial)\n \n summary(final_2var_model)\n\n\nCall:\nglm(formula = dead_or_alive ~ il_8 + hiv_comb + temp, family = binomial, \n    data = df_wider)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)          -90.4099     5.5341 -16.337   &lt;2e-16 ***\nil_8                   1.2382     0.1207  10.257   &lt;2e-16 ***\nhiv_combHIV_Positive   0.1648     0.1236   1.333    0.183    \ntemp                   2.3740     0.1474  16.110   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2103  on 1519  degrees of freedom\nResidual deviance: 1575  on 1516  degrees of freedom\nAIC: 1583\n\nNumber of Fisher Scoring iterations: 4\n\n\nThis confirms that all three variables are independently associated with the outcome.\nAs we previously highlighted the interaction with HIV status, let’s add that to the model…\n\nfinal_2var_model_int &lt;- glm(dead_or_alive ~ il_8 * hiv_comb + temp ,\n                    data = df_wider, \n                    family = binomial)\n \n summary(final_2var_model_int)\n\n\nCall:\nglm(formula = dead_or_alive ~ il_8 * hiv_comb + temp, family = binomial, \n    data = df_wider)\n\nCoefficients:\n                          Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)               -93.8962     5.9942  -15.66   &lt;2e-16 ***\nil_8                        4.0508     0.3193   12.69   &lt;2e-16 ***\nhiv_combHIV_Positive        4.5424     0.3975   11.43   &lt;2e-16 ***\ntemp                        2.3878     0.1586   15.06   &lt;2e-16 ***\nil_8:hiv_combHIV_Positive  -4.0720     0.3530  -11.53   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2103.0  on 1519  degrees of freedom\nResidual deviance: 1384.7  on 1515  degrees of freedom\nAIC: 1394.7\n\nNumber of Fisher Scoring iterations: 5\n\n\nHere, the lower AIC value in the interaction model (1394 cf. 1583) suggests a better fit. We can then use the predictions of this model to inform a ROC analysis.\n\n\n17.7.18.3 ROC Analysis of Boruta + RFE parsimony model\n\n# Add model predictions if not already done\ndf_wider$glm_prob &lt;- predict(final_2var_model, type = \"response\")\ndf_wider$glm_prob_int &lt;- predict(final_2var_model_int, type = \"response\")\n\n# Plot IL-8 alone\np1 &lt;- ROCit_plot(data = df_wider, score_col = \"il_8\", class_col = \"dead_or_alive\", color = \"#000000\") +\n  ggtitle(\"IL-8 Alone\")\n\n# Plot full logistic model\np2 &lt;- ROCit_plot(data = df_wider, score_col = \"glm_prob\", class_col = \"dead_or_alive\", color = \"#0072B2\") +\n  ggtitle(\"IL-8 + HIV + Temp\")\n\n# Plot full logistic model\np3 &lt;- ROCit_plot(data = df_wider, score_col = \"glm_prob_int\", class_col = \"dead_or_alive\", color = \"#0072B2\") +\n  ggtitle(\"IL-8 * HIV +  Temp\")\n\n# Combine using patchwork\np1 + p2 + p3\n\n\n\n\n\n\n\n\nThese side-by-side ROC plots make the contrast very clear:\n\nIL-8 alone achieves an AUC of 0.69 (0.66–0.71) — modest discrimination.\nIL-8 + HIV + Temp reaches an AUC of 0.82 (0.80–0.84) — very good discrimination.\nIL-8 * HIV + Temp reaches an AUC of 0.86 (0.84–0.88) — excellent discrimination\n\nThis demonstrates that:\n\nIL-8 is informative, but insufficient alone.\nSimple clinical and demographic factors like temperature and HIV status dramatically enhance predictive performance and these can be parsimoniously identified through Boruta and RFE.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Analysis</span>"
    ]
  },
  {
    "objectID": "Analysis_02.html#summary",
    "href": "Analysis_02.html#summary",
    "title": "17  Data Analysis",
    "section": "17.8 Summary",
    "text": "17.8 Summary\nThis analysis walks through a complete pipeline for biomarker evaluation, simulating what a robust approach might look like in real-world clinical research. It highlights best practices for handling, transforming, selecting, and modelling data — even though the data used here are synthetic.\n\n1. Data Import & Pre-processing\n\nRaw data representing biomarker values from assay plates (e.g., ELISA or multiplex formats) were loaded.\nBasic tidying included reshaping into wide format, handling missing data, and correcting formatting inconsistencies.\nZ-score normalisation was applied to place all markers on a common scale, controlling for magnitude differences across assays.\n\n\n2. Initial Outcome Assessment\n\nUnivariate ROC curves were plotted for individual biomarkers (e.g., IL-8) to evaluate crude discriminatory power.\nMetrics like AUC, positive predictive value (PPV), and logistic regression coefficients were calculated to get early performance estimates.\nA key point here: PPV or NPV are especially important in clinical decision-making where ruling in, or ruling-out disease can sometimes matter more than balanced accuracy.\n\n\n3. Multivariate Feature Profiling\n\nPrincipal Component Analysis (PCA) was used to explore latent structure across all biomarkers:\n\nIdentified major axes of variation.\nHelped visualise the relative spread of ‘Dead’ vs ‘Alive’ profiles.\n\nMahalanobis distance from control centroids was calculated to summarise overall biomarker deviation, capturing multivariate ‘anomaly’ signals.\n\n\n4. Adding Clinical Covariates\n\nDemographic and physiological variables (e.g., age, sex, temperature, respiratory rate) were added to mirror real clinical settings.\nThese included both continuous and categorical variables, showing the need for flexible models that accommodate mixed data types.\n\n\n5. Feature Selection via Boruta\n\nThe Boruta algorithm selected all relevant features using a robust wrapper method with a random forest backend.\nTentative variables were resolved using median-based rough fixing, and variable importance was visualised clearly.\nThe process retained both biomarkers and clinical indicators, showing that value can emerge from either domain.\n\n\n6. Feature Reduction with RFE\n\nRecursive Feature Elimination (RFE) was applied to the confirmed Boruta variables.\nThrough cross-validation, we identified a parsimonious 3-variable model (IL-8, HIV status, temperature) that achieved nearly optimal performance.\nThis step is critical in preventing overfitting and improving model portability.\n\n\n7. Multivariate Model Building & ROC Evaluation\n\nA logistic regression model using the top 3 features was fit and compared to IL-8 alone:\n\nAUC improved from 0.70 to 0.88,\nShowcasing the power of multi-dimensional predictive signatures over single markers.\n\nROC curves were visualised side-by-side to reinforce this.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Analysis</span>"
    ]
  },
  {
    "objectID": "Analysis_02.html#final-reflection",
    "href": "Analysis_02.html#final-reflection",
    "title": "17  Data Analysis",
    "section": "17.9 Final Reflection",
    "text": "17.9 Final Reflection\nThis approach exemplifies a best-practice pipeline for evaluating candidate biomarkers in biomedical research:\n\nIt starts with rigorous data preparation,\nProgresses through exploratory analysis, feature selection, and cross-validated modelling,\nAnd ends with performance evaluation tailored to clinical relevance.\n\nWhile simulated, this end-to-end workflow mirrors the decisions, trade-offs, and methods required in real-world biomarker discovery and translational modelling.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data Analysis</span>"
    ]
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "18  Funding & Declarations",
    "section": "",
    "text": "18.1 Funding\nThis work is part of the Mos-Def study. It was funded by GHLabs (https://www.ghlabs.org/).",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Funding & Declarations</span>"
    ]
  },
  {
    "objectID": "appendix.html#ethics-statement",
    "href": "appendix.html#ethics-statement",
    "title": "18  Funding & Declarations",
    "section": "18.2 Ethics statement",
    "text": "18.2 Ethics statement\nEthical approval for this study was granted by the ethics committee of the London School of Hygiene & Tropical Medicine.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Funding & Declarations</span>"
    ]
  },
  {
    "objectID": "appendix.html#mit-license",
    "href": "appendix.html#mit-license",
    "title": "18  Funding & Declarations",
    "section": "18.3 MIT License",
    "text": "18.3 MIT License\n(C) 2024, 2025, Chrissy h Roberts, Tegwen Marlais. LSHTM\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n18.3.1 Disclaimer\nThis project makes use of third-party R packages, which are dynamically linked. The licenses of these third-party packages are respected and their respective notices are included below. Please refer to the documentation of each package for more details about their licenses and terms of use.\n\n\n\n\n\n\n\n\n\n\npackage\nVersion\nLicense\n\n\n\n\nAnnotationDbi\n1.70.0\nArtistic-2.0\n\n\nBH\n1.87.0-1\nBSL-1.0\n\n\nBiasedUrn\n2.0.12\nGPL-3\n\n\nBiobase\n2.68.0\nArtistic-2.0\n\n\nBiocGenerics\n0.54.0\nArtistic-2.0\n\n\nBiocManager\n1.30.26\nArtistic-2.0\n\n\nBiocParallel\n1.42.1\nGPL-2 | GPL-3 | BSL-1.0\n\n\nBiocVersion\n3.21.1\nArtistic-2.0\n\n\nBiostrings\n2.76.0\nArtistic-2.0\n\n\nBoruta\n9.0.0\nGPL (&gt;= 2)\n\n\nDBI\n1.2.3\nLGPL (&gt;= 2.1)\n\n\nDeriv\n4.2.0\nGPL (&gt;= 3)\n\n\nFormula\n1.2-5\nGPL-2 | GPL-3\n\n\nGPArotation\n2025.3-1\nGPL (&gt;= 2)\n\n\nGenomeInfoDb\n1.44.1\nArtistic-2.0\n\n\nGenomeInfoDbData\n1.2.14\nArtistic-2.0\n\n\nIRanges\n2.42.0\nArtistic-2.0\n\n\nKEGGREST\n1.48.1\nArtistic-2.0\n\n\nKernSmooth\n2.23-26\nUnlimited\n\n\nMASS\n7.3-65\nGPL-2 | GPL-3\n\n\nMatrix\n1.7-3\nGPL (&gt;= 2) | file LICENCE\n\n\nMatrixGenerics\n1.20.0\nArtistic-2.0\n\n\nMatrixModels\n0.5-4\nGPL (&gt;= 2)\n\n\nModelMetrics\n1.2.2.2\nGPL (&gt;= 2)\n\n\nR6\n2.6.1\nMIT + file LICENSE\n\n\nRColorBrewer\n1.1-3\nApache License 2.0\n\n\nROCit\n2.1.2\nGPL-3\n\n\nRSQLite\n2.4.2\nLGPL (&gt;= 2.1)\n\n\nRcpp\n1.1.0\nGPL (&gt;= 2)\n\n\nRcppEigen\n0.3.4.0.2\nGPL (&gt;= 2) | file LICENSE\n\n\nRdpack\n2.6.4\nGPL (&gt;= 2)\n\n\nS4Vectors\n0.46.0\nArtistic-2.0\n\n\nSQUAREM\n2021.1\nGPL (&gt;= 2)\n\n\nSparseM\n1.84-2\nGPL (&gt;= 2)\n\n\nTH.data\n1.1-3\nGPL-3\n\n\nUCSC.utils\n1.4.0\nArtistic-2.0\n\n\nXML\n3.99-0.18\nBSD_3_clause + file LICENSE\n\n\nXVector\n0.48.0\nArtistic-2.0\n\n\nabind\n1.4-8\nMIT + file LICENSE\n\n\nannotate\n1.86.1\nArtistic-2.0\n\n\naskpass\n1.2.1\nMIT + file LICENSE\n\n\nbackports\n1.5.0\nGPL-2 | GPL-3\n\n\nbase64enc\n0.1-3\nGPL-2 | GPL-3\n\n\nbit\n4.6.0\nGPL-2 | GPL-3\n\n\nbit64\n4.6.0-1\nGPL-2 | GPL-3\n\n\nblob\n1.2.4\nMIT + file LICENSE\n\n\nboot\n1.3-31\nUnlimited\n\n\nbroom\n1.0.9\nMIT + file LICENSE\n\n\nbslib\n0.9.0\nMIT + file LICENSE\n\n\ncachem\n1.1.0\nMIT + file LICENSE\n\n\ncallr\n3.7.6\nMIT + file LICENSE\n\n\ncar\n3.1-3\nGPL (&gt;= 2)\n\n\ncarData\n3.0-5\nGPL (&gt;= 2)\n\n\ncaret\n7.0-1\nGPL (&gt;= 2)\n\n\ncellranger\n1.1.0\nMIT + file LICENSE\n\n\nclass\n7.3-23\nGPL-2 | GPL-3\n\n\nclassInt\n0.4-11\nGPL (&gt;= 2)\n\n\ncli\n3.6.5\nMIT + file LICENSE\n\n\nclipr\n0.8.0\nGPL-3\n\n\nclock\n0.7.3\nMIT + file LICENSE\n\n\ncodetools\n0.2-20\nGPL\n\n\ncommonmark\n2.0.0\nBSD_2_clause + file LICENSE\n\n\nconflicted\n1.2.0\nMIT + file LICENSE\n\n\ncowplot\n1.2.0\nGPL-2\n\n\ncpp11\n0.5.2\nMIT + file LICENSE\n\n\ncrayon\n1.5.3\nMIT + file LICENSE\n\n\ncrosstalk\n1.2.1\nMIT + file LICENSE\n\n\ncurl\n6.4.0\nMIT + file LICENSE\n\n\ndata.table\n1.17.8\nMPL-2.0 | file LICENSE\n\n\ndbplyr\n2.5.0\nMIT + file LICENSE\n\n\ndiagram\n1.6.5\nGPL (&gt;= 2)\n\n\ndigest\n0.6.37\nGPL (&gt;= 2)\n\n\ndoBy\n4.7.0\nGPL (&gt;= 2)\n\n\ndoParallel\n1.0.17\nGPL-2\n\n\ndplyr\n1.1.4\nMIT + file LICENSE\n\n\ndrc\n3.0-1\nGPL-2 | file LICENCE\n\n\ndtplyr\n1.3.1\nMIT + file LICENSE\n\n\ne1071\n1.7-16\nGPL-2 | GPL-3\n\n\nedgeR\n4.6.3\nGPL (&gt;=2)\n\n\nepiR\n2.0.85\nGPL (&gt;= 2)\n\n\nevaluate\n1.0.4\nMIT + file LICENSE\n\n\nfarver\n2.1.2\nMIT + file LICENSE\n\n\nfastmap\n1.2.0\nMIT + file LICENSE\n\n\nflextable\n0.9.9\nGPL-3\n\n\nfontBitstreamVera\n0.1.1\nfile LICENCE\n\n\nfontLiberation\n0.1.0\nfile LICENSE\n\n\nfontawesome\n0.5.3\nMIT + file LICENSE\n\n\nfontquiver\n0.2.1\nGPL-3 | file LICENSE\n\n\nforcats\n1.0.0\nMIT + file LICENSE\n\n\nforeach\n1.5.2\nApache License (== 2.0)\n\n\nformatR\n1.14\nGPL\n\n\nfs\n1.6.6\nMIT + file LICENSE\n\n\nfutile.logger\n1.4.3\nLGPL-3\n\n\nfutile.options\n1.0.1\nLGPL-3\n\n\nfuture\n1.67.0\nLGPL (&gt;= 2.1)\n\n\nfuture.apply\n1.20.0\nGPL (&gt;= 2)\n\n\ngargle\n1.5.2\nMIT + file LICENSE\n\n\ngdtools\n0.4.2\nGPL-3 | file LICENSE\n\n\ngenefilter\n1.90.0\nArtistic-2.0\n\n\ngenerics\n0.1.4\nMIT + file LICENSE\n\n\nggplot2\n3.5.2\nMIT + file LICENSE\n\n\nggtext\n0.1.2\nGPL-2\n\n\nglobals\n0.18.0\nLGPL (&gt;= 2.1)\n\n\nglue\n1.8.0\nMIT + file LICENSE\n\n\ngoogledrive\n2.1.1\nMIT + file LICENSE\n\n\ngooglesheets4\n1.1.1\nMIT + file LICENSE\n\n\ngower\n1.0.2\nGPL-3\n\n\ngridtext\n0.1.5\nMIT + file LICENSE\n\n\ngtable\n0.3.6\nMIT + file LICENSE\n\n\ngtools\n3.9.5\nGPL-2\n\n\nhardhat\n1.4.1\nMIT + file LICENSE\n\n\nhaven\n2.5.5\nMIT + file LICENSE\n\n\nhighr\n0.11\nGPL\n\n\nhms\n1.1.3\nMIT + file LICENSE\n\n\nhtmltools\n0.5.8.1\nGPL (&gt;= 2)\n\n\nhtmlwidgets\n1.6.4\nMIT + file LICENSE\n\n\nhttr\n1.4.7\nMIT + file LICENSE\n\n\nids\n1.0.1\nMIT + file LICENSE\n\n\nipred\n0.9-15\nGPL (&gt;= 2)\n\n\nisoband\n0.2.7\nMIT + file LICENSE\n\n\niterators\n1.0.14\nApache License (== 2.0)\n\n\njpeg\n0.1-11\nGPL-2 | GPL-3\n\n\njquerylib\n0.1.4\nMIT + file LICENSE\n\n\njsonlite\n2.0.0\nMIT + file LICENSE\n\n\nkableExtra\n1.4.0\nMIT + file LICENSE\n\n\nkernlab\n0.9-33\nGPL-2\n\n\nknitr\n1.50\nGPL\n\n\nlabeling\n0.4.3\nMIT + file LICENSE | Unlimited\n\n\nlambda.r\n1.2.4\nLGPL-3\n\n\nlater\n1.4.2\nMIT + file LICENSE\n\n\nlattice\n0.22-7\nGPL (&gt;= 2)\n\n\nlava\n1.8.1\nGPL-3\n\n\nlazyeval\n0.2.2\nGPL-3\n\n\nlifecycle\n1.0.4\nMIT + file LICENSE\n\n\nlimma\n3.64.3\nGPL (&gt;=2)\n\n\nlistenv\n0.9.1\nLGPL (&gt;= 2.1)\n\n\nlitedown\n0.7\nMIT + file LICENSE\n\n\nlme4\n1.1-37\nGPL (&gt;= 2)\n\n\nlocfit\n1.5-9.12\nGPL (&gt;= 2)\n\n\nlubridate\n1.9.4\nGPL (&gt;= 2)\n\n\nmagrittr\n2.0.3\nMIT + file LICENSE\n\n\nmarkdown\n2.0\nMIT + file LICENSE\n\n\nmatrixStats\n1.5.0\nArtistic-2.0\n\n\nmemoise\n2.0.1\nMIT + file LICENSE\n\n\nmgcv\n1.9-3\nGPL (&gt;= 2)\n\n\nmicrobenchmark\n1.5.0\nBSD_2_clause + file LICENSE\n\n\nmime\n0.13\nGPL\n\n\nminpack.lm\n1.2-4\nGPL-3\n\n\nminqa\n1.2.8\nGPL-2\n\n\nmixtools\n2.0.0.1\nGPL (&gt;= 2)\n\n\nmnormt\n2.1.1\nGPL-2 | GPL-3\n\n\nmodelr\n0.1.11\nGPL-3\n\n\nmoments\n0.14.1\nGPL (&gt;= 2)\n\n\nmultcomp\n1.4-28\nGPL-2\n\n\nmvtnorm\n1.3-3\nGPL-2\n\n\nnlme\n3.1-168\nGPL (&gt;= 2)\n\n\nnloptr\n2.2.1\nLGPL (&gt;= 3)\n\n\nnnet\n7.3-20\nGPL-2 | GPL-3\n\n\nnumDeriv\n2016.8-1.1\nGPL-2\n\n\nofficer\n0.6.10\nMIT + file LICENSE\n\n\nopenssl\n2.3.3\nMIT + file LICENSE\n\n\npROC\n1.19.0.1\nGPL (&gt;= 3)\n\n\npackrat\n0.9.3\nGPL-2\n\n\npander\n0.6.6\nAGPL-3 | file LICENSE\n\n\nparallelly\n1.45.1\nLGPL (&gt;= 2.1)\n\n\npatchwork\n1.3.1\nMIT + file LICENSE\n\n\npbkrtest\n0.5.5\nGPL (&gt;= 2)\n\n\npillar\n1.11.0\nMIT + file LICENSE\n\n\npkgconfig\n2.0.3\nMIT + file LICENSE\n\n\nplogr\n0.2.0\nMIT + file LICENSE\n\n\nplotly\n4.11.0\nMIT + file LICENSE\n\n\nplotrix\n3.8-4\nGPL (&gt;= 2)\n\n\nplyr\n1.8.9\nMIT + file LICENSE\n\n\npng\n0.1-8\nGPL-2 | GPL-3\n\n\nprettyunits\n1.2.0\nMIT + file LICENSE\n\n\nprocessx\n3.8.6\nMIT + file LICENSE\n\n\nprodlim\n2025.04.28\nGPL (&gt;= 2)\n\n\nprogress\n1.2.3\nMIT + file LICENSE\n\n\nprogressr\n0.15.1\nGPL (&gt;= 3)\n\n\npromises\n1.3.3\nMIT + file LICENSE\n\n\nproxy\n0.4-27\nGPL-2\n\n\nps\n1.9.1\nMIT + file LICENSE\n\n\npsych\n2.5.6\nGPL (&gt;= 2)\n\n\npurrr\n1.1.0\nMIT + file LICENSE\n\n\nquantreg\n6.1\nGPL (&gt;= 2)\n\n\nragg\n1.4.0\nMIT + file LICENSE\n\n\nrandomForest\n4.7-1.2\nGPL (&gt;= 2)\n\n\nranger\n0.17.0\nGPL-3\n\n\nrappdirs\n0.3.3\nMIT + file LICENSE\n\n\nrbibutils\n2.3\nGPL-2\n\n\nreadr\n2.1.5\nMIT + file LICENSE\n\n\nreadxl\n1.4.5\nMIT + file LICENSE\n\n\nrecipes\n1.3.1\nMIT + file LICENSE\n\n\nreformulas\n0.4.1\nGPL-3\n\n\nrematch\n2.0.0\nMIT + file LICENSE\n\n\nrematch2\n2.1.2\nMIT + file LICENSE\n\n\nrenv\n1.1.5\nMIT + file LICENSE\n\n\nreprex\n2.1.1\nMIT + file LICENSE\n\n\nreshape2\n1.4.4\nMIT + file LICENSE\n\n\nrlang\n1.1.6\nMIT + file LICENSE\n\n\nrmarkdown\n2.29\nGPL-3\n\n\nrpart\n4.1.24\nGPL-2 | GPL-3\n\n\nrstudioapi\n0.17.1\nMIT + file LICENSE\n\n\nrvest\n1.0.4\nMIT + file LICENSE\n\n\ns2\n1.1.9\nApache License (== 2.0)\n\n\nsandwich\n3.1-1\nGPL-2 | GPL-3\n\n\nsass\n0.4.10\nMIT + file LICENSE\n\n\nscales\n1.4.0\nMIT + file LICENSE\n\n\nsegmented\n2.1-4\nGPL\n\n\nselectr\n0.4-2\nBSD_3_clause + file LICENCE\n\n\nsf\n1.0-21\nGPL-2 | MIT + file LICENSE\n\n\nshape\n1.4.6.1\nGPL (&gt;= 3)\n\n\nsnow\n0.4-4\nGPL\n\n\nsparsevctrs\n0.3.4\nMIT + file LICENSE\n\n\nstatmod\n1.5.0\nGPL-2 | GPL-3\n\n\nstringi\n1.8.7\nfile LICENSE\n\n\nstringr\n1.5.1\nMIT + file LICENSE\n\n\nsurvival\n3.8-3\nLGPL (&gt;= 2)\n\n\nsva\n3.56.0\nArtistic-2.0\n\n\nsvglite\n2.2.1\nGPL (&gt;= 2)\n\n\nsys\n3.4.3\nMIT + file LICENSE\n\n\nsystemfonts\n1.2.3\nMIT + file LICENSE\n\n\ntextshaping\n1.0.1\nMIT + file LICENSE\n\n\ntibble\n3.3.0\nMIT + file LICENSE\n\n\ntidyr\n1.3.1\nMIT + file LICENSE\n\n\ntidyselect\n1.2.1\nMIT + file LICENSE\n\n\ntidyverse\n2.0.0\nMIT + file LICENSE\n\n\ntimeDate\n4041.110\nGPL (&gt;= 2)\n\n\ntimechange\n0.3.0\nGPL (&gt;= 3)\n\n\ntinytex\n0.57\nMIT + file LICENSE\n\n\ntzdb\n0.5.0\nMIT + file LICENSE\n\n\nunits\n0.8-7\nGPL-2\n\n\nutf8\n1.2.6\nApache License (== 2.0) | file LICENSE\n\n\nuuid\n1.2-1\nMIT + file LICENSE\n\n\nvctrs\n0.6.5\nMIT + file LICENSE\n\n\nviridisLite\n0.4.2\nMIT + file LICENSE\n\n\nvroom\n1.6.5\nMIT + file LICENSE\n\n\nwithr\n3.0.2\nMIT + file LICENSE\n\n\nwk\n0.9.4\nMIT + file LICENSE\n\n\nxfun\n0.52\nMIT + file LICENSE\n\n\nxml2\n1.3.8\nMIT + file LICENSE\n\n\nxtable\n1.8-4\nGPL (&gt;= 2)\n\n\nyaml\n2.3.10\nBSD_3_clause + file LICENSE\n\n\nzip\n2.3.3\nMIT + file LICENSE\n\n\nzoo\n1.8-14\nGPL-2 | GPL-3\n\n\n\n\n\nPlease respect the licenses of the code originators.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Funding & Declarations</span>"
    ]
  },
  {
    "objectID": "CRediT.html",
    "href": "CRediT.html",
    "title": "19  CRediT Framework",
    "section": "",
    "text": "19.1 Conceptualization\nIdeas; formulation or evolution of overarching research goals and aims\nTegwen Marlais, Heidi Hopkins, David Mabey, Chris Drakeley, Liz Ashley, Mayfong Mayxay, David Lalloo, Nick Feasey, Quique Bassat, Katharina Kranzer, Paul Newton, John Crump, David Bell, Yoel Lubell, Arjun Chandna and Chrissy h Roberts",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>CRediT Framework</span>"
    ]
  },
  {
    "objectID": "CRediT.html#methodology",
    "href": "CRediT.html#methodology",
    "title": "19  CRediT Framework",
    "section": "19.2 Methodology",
    "text": "19.2 Methodology\nDevelopment or design of methodology; creation of models\nTegwen Marlais, Chris Drakeley, Chrissy h Roberts",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>CRediT Framework</span>"
    ]
  },
  {
    "objectID": "CRediT.html#software",
    "href": "CRediT.html#software",
    "title": "19  CRediT Framework",
    "section": "19.3 Software",
    "text": "19.3 Software\nProgramming, software development; designing computer programs; implementation of the computer code and supporting algorithms; testing of existing code components\nChrissy h Roberts, Tegwen Marlais",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>CRediT Framework</span>"
    ]
  },
  {
    "objectID": "CRediT.html#validation",
    "href": "CRediT.html#validation",
    "title": "19  CRediT Framework",
    "section": "19.4 Validation",
    "text": "19.4 Validation\nVerification, whether as a part of the activity or separate, of the overall replication/ reproducibility of results/experiments and other research outputs\nChrissy h Roberts, Tegwen Marlais",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>CRediT Framework</span>"
    ]
  },
  {
    "objectID": "CRediT.html#formal-analysis",
    "href": "CRediT.html#formal-analysis",
    "title": "19  CRediT Framework",
    "section": "19.5 Formal Analysis",
    "text": "19.5 Formal Analysis\nApplication of statistical, mathematical, computational, or other formal techniques to analyze or synthesize study data\nChrissy h Roberts, Tegwen Marlais",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>CRediT Framework</span>"
    ]
  },
  {
    "objectID": "CRediT.html#investigation",
    "href": "CRediT.html#investigation",
    "title": "19  CRediT Framework",
    "section": "19.6 Investigation",
    "text": "19.6 Investigation\nConducting a research and investigation process, specifically performing the experiments, or data/evidence collection\nTegwen Marlais, Becca Handley, Hira Tanvir",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>CRediT Framework</span>"
    ]
  },
  {
    "objectID": "CRediT.html#resources",
    "href": "CRediT.html#resources",
    "title": "19  CRediT Framework",
    "section": "19.7 Resources",
    "text": "19.7 Resources\nProvision of study materials, reagents, materials, patients, laboratory samples, animals, instrumentation, computing resources, or other analysis tools\nChrissy h Roberts, Tegwen Marlais",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>CRediT Framework</span>"
    ]
  },
  {
    "objectID": "CRediT.html#data-curation",
    "href": "CRediT.html#data-curation",
    "title": "19  CRediT Framework",
    "section": "19.8 Data curation",
    "text": "19.8 Data curation\nManagement activities to annotate (produce metadata), scrub data and maintain research data (including software code, where it is necessary for interpreting the data itself) for initial use and later reuse\nChrissy h Roberts, Tegwen Marlais",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>CRediT Framework</span>"
    ]
  },
  {
    "objectID": "CRediT.html#writing-original-draft",
    "href": "CRediT.html#writing-original-draft",
    "title": "19  CRediT Framework",
    "section": "19.9 Writing – Original Draft",
    "text": "19.9 Writing – Original Draft\nPreparation, creation and/or presentation of the published work, specifically writing the initial draft (including substantive translation)\nChrissy h Roberts, Tegwen Marlais",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>CRediT Framework</span>"
    ]
  },
  {
    "objectID": "CRediT.html#writing-review-editing",
    "href": "CRediT.html#writing-review-editing",
    "title": "19  CRediT Framework",
    "section": "19.10 Writing – Review & Editing",
    "text": "19.10 Writing – Review & Editing\nPreparation, creation and/or presentation of the published work by those from the original research group, specifically critical review, commentary or revision – including pre- or postpublication stages\nChrissy h Roberts, Tegwen Marlais, Chris Drakeley",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>CRediT Framework</span>"
    ]
  },
  {
    "objectID": "CRediT.html#visualization",
    "href": "CRediT.html#visualization",
    "title": "19  CRediT Framework",
    "section": "19.11 Visualization",
    "text": "19.11 Visualization\nPreparation, creation and/or presentation of the published work, specifically visualization/ data presentation\nChrissy h Roberts, Tegwen Marlais",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>CRediT Framework</span>"
    ]
  },
  {
    "objectID": "CRediT.html#supervision",
    "href": "CRediT.html#supervision",
    "title": "19  CRediT Framework",
    "section": "19.12 Supervision",
    "text": "19.12 Supervision\nOversight and leadership responsibility for the research activity planning and execution, including mentorship external to the core team\nChrissy h Roberts, David Mabey, Chris Drakeley",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>CRediT Framework</span>"
    ]
  },
  {
    "objectID": "CRediT.html#project-administration",
    "href": "CRediT.html#project-administration",
    "title": "19  CRediT Framework",
    "section": "19.13 Project Administration",
    "text": "19.13 Project Administration\nManagement and coordination responsibility for the research activity planning and execution\nBecca Handley, Esther Amon",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>CRediT Framework</span>"
    ]
  },
  {
    "objectID": "CRediT.html#funding-acquisition",
    "href": "CRediT.html#funding-acquisition",
    "title": "19  CRediT Framework",
    "section": "19.14 Funding acquisition",
    "text": "19.14 Funding acquisition\nAcquisition of the financial support for the project leading to this publication.\nChrissy h Roberts, Heidi Hopkins, David Mabey, Chris Drakeley\n\n\n\n\nBrand, Amy, Liz Allen, Micah Altman, Marjorie Hlava, and Jo Scott. 2015. “Beyond Authorship: Attribution, Contribution, Collaboration, and Credit.” Learned Publishing 28 (2): 151–55. https://doi.org/10.1087/20150211.",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>CRediT Framework</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Al-Lamki, Rafia S., and Tanya N. Mayadas. 2015. “TNF Receptors:\nSignaling Pathways and Contribution to Renal Dysfunction.”\nKidney International 87 (2): 281–96. https://doi.org/10.1038/ki.2014.285.\n\n\nBemelmans, M. H. A., L. J. H. van Tits, and W. A. Buurman. 2017.\n“Tumor Necrosis Factor: Function, Release and Clearance.”\nCritical Reviews in Immunology 37 (2–6): 249–59. https://doi.org/10.1615/critrevimmunol.v37.i2-6.50.\n\n\nBrand, Amy, Liz Allen, Micah Altman, Marjorie Hlava, and Jo Scott. 2015.\n“Beyond Authorship: Attribution, Contribution, Collaboration, and\nCredit.” Learned Publishing 28 (2): 151–55. https://doi.org/10.1087/20150211.\n\n\nBrouwers, Judith, Rintis Noviyanti, Rob Fijnheer, Philip G. de Groot,\nLeily Trianty, Siti Mudaliana, Mark Roest, Din Syafruddin, Andre van der\nVen, and Quirijn de Mast. 2013. “Platelet Activation Determines\nAngiopoietin-1 and VEGF Levels in Malaria: Implications for Their Use as\nBiomarkers.” Edited by Ana Paula Arez. PLoS ONE 8 (6):\ne64850. https://doi.org/10.1371/journal.pone.0064850.\n\n\nDavies, Julie. 2015. “Procalcitonin.” Journal of\nClinical Pathology 68 (9): 675–79. https://doi.org/10.1136/jclinpath-2014-202807.\n\n\nFisher, J., and A. Linder. 2017. “Heparin-Binding\nProtein: A Key Player in the Pathophysiology of Organ Dysfunction in\nSepsis.” Journal of Internal Medicine 281 (6): 562–74.\nhttps://doi.org/10.1111/joim.12604.\n\n\nGreco, Marilena, Claudio Palumbo, Fernando Sicuro, and Giambattista\nLobreglio. 2018. “Soluble Fms-Like Tyrosine Kinase-1 Is a Marker\nof Endothelial Dysfunction During Sepsis.” Journal of\nClinical Medicine Research 10 (9): 700–706. https://doi.org/10.14740/jocmr3505w.\n\n\nGyurkovska, Valeriya, and Nina Ivanovska. 2016. “Distinct Roles of\nTNF-Related Apoptosis-Inducing Ligand (TRAIL) in Viral and Bacterial\nInfections: From Pathogenesis to Pathogen Clearance.”\nInflammation Research 65 (6): 427–37. https://doi.org/10.1007/s00011-016-0934-1.\n\n\nHaller, Otto, and Georg Kochs. 2019. “Mx Genes: Host Determinants\nControlling Influenza Virus Infection and Trans-Species\nTransmission.” Human Genetics 139 (6–7): 695–705. https://doi.org/10.1007/s00439-019-02092-8.\n\n\nHayney, Mary S., Kelsey M. Henriquez, Jodi H. Barnet, Tola Ewers,\nHeather M. Champion, Sean Flannery, and Bruce Barrett. 2017.\n“Serum IFN-γ-Induced Protein 10 (IP-10) as a Biomarker for\nSeverity of Acute Respiratory Infection in Healthy Adults.”\nJournal of Clinical Virology 90 (May): 32–37. https://doi.org/10.1016/j.jcv.2017.03.003.\n\n\nKang, Sujin, and Tadamitsu Kishimoto. 2021. “Interplay Between\nInterleukin-6 Signaling and the Vascular Endothelium in Cytokine\nStorms.” Experimental &Amp; Molecular Medicine 53\n(7): 1116–23. https://doi.org/10.1038/s12276-021-00649-0.\n\n\nKim, Minah, Breanna Allen, Emilia A. Korhonen, Maximilian Nitschké, Hee\nWon Yang, Peter Baluk, Pipsa Saharinen, et al. 2016. “Opposing\nActions of Angiopoietin-2 on Tie2 Signaling and FOXO1\nActivation.” Journal of Clinical Investigation 126 (9):\n3511–25. https://doi.org/10.1172/jci84871.\n\n\nLei, Jie, Xiaowan Yin, Hong Shang, and Yongjun Jiang. 2019. “IP-10\nIs Highly Involved in HIV Infection.” Cytokine 115\n(March): 97–103. https://doi.org/10.1016/j.cyto.2018.11.018.\n\n\nLeligdowicz, Aleksandra, Melissa Richard-Greenblatt, Julie Wright,\nValerie M. Crowley, and Kevin C. Kain. 2018. “Endothelial\nActivation: The Ang/Tie Axis in Sepsis.” Frontiers in\nImmunology 9 (April). https://doi.org/10.3389/fimmu.2018.00838.\n\n\nMatsushima, Kouji, De Yang, and Joost J. Oppenheim. 2022.\n“Interleukin-8: An Evolving Chemokine.” Cytokine\n153 (May): 155828. https://doi.org/10.1016/j.cyto.2022.155828.\n\n\nRuiz, Andy, Yadira Palacios, Irene Garcia, and Leslie Chavez-Galan.\n2021. “Transmembrane TNF and Its Receptors TNFR1 and TNFR2 in\nMycobacterial Infections.” International Journal of Molecular\nSciences 22 (11): 5461. https://doi.org/10.3390/ijms22115461.\n\n\nSaraiva, Margarida, Paulo Vieira, and Anne O’Garra. 2019. “Biology\nand Therapeutic Potential of Interleukin-10.” Journal of\nExperimental Medicine 217 (1). https://doi.org/10.1084/jem.20190418.\n\n\nSproston, Nicola R., and Jason J. Ashworth. 2018. “Role of\nc-Reactive Protein at Sites of Inflammation and Infection.”\nFrontiers in Immunology 9 (April). https://doi.org/10.3389/fimmu.2018.00754.\n\n\nTanaka, T., M. Narazaki, and T. Kishimoto. 2014. “IL-6 in\nInflammation, Immunity, and Disease.” Cold Spring Harbor\nPerspectives in Biology 6 (10): a016295–95. https://doi.org/10.1101/cshperspect.a016295.\n\n\nTheobald, Vivienne, Felix Carl Fabian Schmitt, Chiara Simone Middel,\nLena Gaissmaier, Thorsten Brenner, and Markus Alexander Weigand. 2024.\n“Triggering Receptor Expressed on Myeloid Cells-1 in Sepsis, and\nCurrent Insights into Clinical Studies.” Critical Care\n28 (1). https://doi.org/10.1186/s13054-024-04798-2.\n\n\nUgalde, Miguel Javier, Alberto Caballero, Marta Martín Fernández,\nEduardo Tamayo, and Olga de la Varga-Martínez. 2024. “Valor Del\nBiomarcador Tirosina Quinasa 1 Soluble Tipo Fms (sFLT-1) En El\nDiagnóstico y Pronóstico de La Sepsis: Una Revisión Sistemática.”\nMedicina Clínica 163 (5): 224–31. https://doi.org/10.1016/j.medcli.2024.03.027.\n\n\nWazan, Layal EI, Ariel Widhibrata, and Guei-Sheung Liu. 2024.\n“Soluble FLT-1 in Angiogenesis: Pathophysiological Roles and\nTherapeutic Implications.” Angiogenesis 27 (4): 641–61.\nhttps://doi.org/10.1007/s10456-024-09942-8.\n\n\nZhao, Ting, Zhongping Su, Yingchang Li, Xiaoren Zhang, and Qiang You.\n2020. “Chitinase-3 Like-Protein-1 Function and Its Role in\nDiseases.” Signal Transduction and Targeted Therapy 5\n(1). https://doi.org/10.1038/s41392-020-00303-7.",
    "crumbs": [
      "References"
    ]
  }
]